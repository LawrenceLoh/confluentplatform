[2016-09-20 12:17:29,434] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-20 12:17:29,596] INFO starting (kafka.server.KafkaServer)
[2016-09-20 12:17:29,631] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-20 12:17:37,200] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 6000
	at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:1232)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:156)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:130)
	at kafka.utils.ZkUtils$.createZkClientAndConnection(ZkUtils.scala:75)
	at kafka.utils.ZkUtils$.apply(ZkUtils.scala:57)
	at kafka.server.KafkaServer.initZk(KafkaServer.scala:294)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:180)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2016-09-20 12:17:37,204] INFO shutting down (kafka.server.KafkaServer)
[2016-09-20 12:17:37,219] INFO shut down completed (kafka.server.KafkaServer)
[2016-09-20 12:17:37,221] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 6000
	at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:1232)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:156)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:130)
	at kafka.utils.ZkUtils$.createZkClientAndConnection(ZkUtils.scala:75)
	at kafka.utils.ZkUtils$.apply(ZkUtils.scala:57)
	at kafka.server.KafkaServer.initZk(KafkaServer.scala:294)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:180)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2016-09-20 12:17:37,226] INFO shutting down (kafka.server.KafkaServer)
[2016-09-26 12:57:00,223] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 12:57:00,303] INFO starting (kafka.server.KafkaServer)
[2016-09-26 12:57:00,313] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 12:57:00,573] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-26 12:57:00,583] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 12:57:00,593] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 12:57:00,673] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 12:57:00,683] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 12:57:00,693] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 12:57:00,773] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-26 12:57:00,773] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 12:57:00,813] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:00,813] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:00,923] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:00,933] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:00,933] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-26 12:57:01,003] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:01,043] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:01,053] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 12:57:01,053] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 12:57:01,073] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 12:57:01,083] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 12:57:01,093] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 12:57:01,093] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-26 12:57:01,093] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 12:57:01,123] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:01,123] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:01,133] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 12:57:01,133] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 12:57:01,153] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-26 12:57:23,516] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9093
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs1
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 1
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 12:57:23,596] INFO starting (kafka.server.KafkaServer)
[2016-09-26 12:57:23,606] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 12:57:23,816] INFO Log directory 'D:\tmp\kafka-logs1' not found, creating it. (kafka.log.LogManager)
[2016-09-26 12:57:23,816] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 12:57:23,826] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 12:57:23,886] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 12:57:23,886] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 12:57:23,896] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 12:57:23,946] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2016-09-26 12:57:23,956] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 12:57:23,976] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:23,976] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:24,136] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:24,146] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 12:57:24,146] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:24,146] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 12:57:24,156] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 12:57:24,166] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 12:57:24,166] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 12:57:24,176] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 12:57:24,196] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:24,216] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:24,216] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 12:57:24,216] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 12:57:24,266] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2016-09-26 12:57:54,716] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9094
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs2
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 2
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 12:57:54,796] INFO starting (kafka.server.KafkaServer)
[2016-09-26 12:57:54,806] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 12:57:54,976] INFO Log directory 'D:\tmp\kafka-logs2' not found, creating it. (kafka.log.LogManager)
[2016-09-26 12:57:54,986] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 12:57:54,996] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 12:57:55,056] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 12:57:55,056] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 12:57:55,066] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 12:57:55,126] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2016-09-26 12:57:55,136] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 12:57:55,156] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:55,156] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:55,303] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:55,303] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 12:57:55,323] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 12:57:55,323] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 12:57:55,333] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 12:57:55,343] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 12:57:55,343] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 12:57:55,353] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 12:57:55,383] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:55,393] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 12:57:55,393] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9094,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 12:57:55,393] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 12:57:55,443] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2016-09-26 12:58:58,686] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 12:58:58,776] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 12:58:58,781] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 12:58:58,783] INFO Partition [_schemas,0] on broker 1: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 12:58:58,791] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 12:58:58,795] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 12:58:58,845] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 12:58:58,856] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 12:58:58,860] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 12:58:58,882] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 12:58:58,885] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 12:58:58,953] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 12:58:58,971] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 12:58:58,973] INFO Partition [_schemas,0] on broker 2: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 12:58:58,981] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 12:58:58,987] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 12:58:59,063] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 12:58:59,085] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 13:07:01,061] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:07:24,153] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:07:55,337] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:17:01,072] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:17:24,164] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:17:55,348] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:27:01,084] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:27:24,177] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:27:55,360] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:37:01,097] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:37:24,189] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:37:55,373] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:47:01,109] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:47:24,201] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:47:55,385] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:46,189] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 13:50:46,201] INFO [KafkaApi-0] Auto creation of topic topic2 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 13:50:46,299] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 13:50:46,302] INFO [KafkaApi-0] Auto creation of topic topic3 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 13:50:46,348] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 13:50:46,352] INFO [KafkaApi-0] Auto creation of topic Text with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 13:50:46,492] INFO Topic creation {"version":1,"partitions":{"45":[0,2,1],"34":[1,0,2],"12":[0,1,2],"8":[2,0,1],"19":[1,2,0],"23":[2,1,0],"4":[1,0,2],"40":[1,0,2],"15":[0,2,1],"11":[2,1,0],"9":[0,2,1],"44":[2,0,1],"33":[0,2,1],"22":[1,0,2],"26":[2,0,1],"37":[1,2,0],"13":[1,2,0],"46":[1,0,2],"24":[0,1,2],"35":[2,1,0],"16":[1,0,2],"5":[2,1,0],"10":[1,0,2],"48":[0,1,2],"21":[0,2,1],"43":[1,2,0],"32":[2,0,1],"49":[1,2,0],"6":[0,1,2],"36":[0,1,2],"1":[1,2,0],"39":[0,2,1],"17":[2,1,0],"25":[1,2,0],"14":[2,0,1],"47":[2,1,0],"31":[1,2,0],"42":[0,1,2],"0":[0,1,2],"20":[2,0,1],"27":[0,2,1],"2":[2,0,1],"38":[2,0,1],"18":[0,1,2],"30":[0,1,2],"7":[1,2,0],"29":[2,1,0],"41":[2,1,0],"3":[0,2,1],"28":[1,0,2]}} (kafka.admin.AdminUtils$)
[2016-09-26 13:50:46,504] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 3 is successful (kafka.server.KafkaApis)
[2016-09-26 13:50:46,716] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [topic2,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:46,773] INFO Completed load of log topic2-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:46,793] INFO Created log for partition [topic2,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:46,798] INFO Partition [topic2,0] on broker 0: No checkpointed highwatermark is found for partition [topic2,0] (kafka.cluster.Partition)
[2016-09-26 13:50:46,812] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [topic3,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:46,822] INFO Completed load of log topic3-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:46,823] INFO Created log for partition [topic3,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:46,826] INFO Partition [topic3,0] on broker 0: No checkpointed highwatermark is found for partition [topic3,0] (kafka.cluster.Partition)
[2016-09-26 13:50:46,842] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:46,875] INFO Completed load of log Text-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:46,896] INFO Created log for partition [Text,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:46,898] INFO Partition [Text,0] on broker 0: No checkpointed highwatermark is found for partition [Text,0] (kafka.cluster.Partition)
[2016-09-26 13:50:47,812] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:47,874] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,0],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,9],[__consumer_offsets,42],[__consumer_offsets,48],[__consumer_offsets,18],[__consumer_offsets,12],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:47,890] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:47,898] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,28],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,13],[__consumer_offsets,40],[__consumer_offsets,37],[__consumer_offsets,34],[__consumer_offsets,22],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:47,901] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:47,907] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:47,909] INFO Partition [__consumer_offsets,29] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 13:50:47,938] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:47,942] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:47,944] INFO Partition [__consumer_offsets,10] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 13:50:47,948] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:47,955] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:47,958] INFO Partition [__consumer_offsets,26] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 13:50:47,970] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:47,989] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:47,991] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:47,991] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 13:50:47,994] INFO Partition [__consumer_offsets,7] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 13:50:48,016] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,022] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,037] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,043] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,043] INFO Partition [__consumer_offsets,23] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 13:50:48,053] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,054] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,054] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 13:50:48,059] INFO Partition [__consumer_offsets,4] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 13:50:48,088] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,089] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,100] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 13:50:48,102] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,374] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,376] INFO Partition [__consumer_offsets,1] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 13:50:48,402] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,411] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,413] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,413] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 13:50:48,440] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,455] INFO Partition [__consumer_offsets,20] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 13:50:48,456] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,456] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,461] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,463] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,464] INFO Partition [__consumer_offsets,49] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 13:50:48,467] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 13:50:48,482] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,489] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,491] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,501] INFO Partition [__consumer_offsets,46] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 13:50:48,510] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,512] INFO Partition [__consumer_offsets,17] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 13:50:48,520] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,525] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,528] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 13:50:48,534] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,542] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,544] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,545] INFO Partition [__consumer_offsets,43] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 13:50:48,548] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,549] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 13:50:48,552] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,558] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,564] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,564] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,566] INFO Partition [__consumer_offsets,14] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 13:50:48,566] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,568] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,569] INFO Partition [__consumer_offsets,40] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 13:50:48,570] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 13:50:48,584] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,587] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,597] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,598] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,598] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 13:50:48,603] INFO Partition [__consumer_offsets,37] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 13:50:48,610] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,614] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,613] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,615] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,618] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 13:50:48,619] INFO Partition [__consumer_offsets,11] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 13:50:48,625] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,633] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,635] INFO Partition [__consumer_offsets,34] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 13:50:48,640] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,647] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,648] INFO Partition [__consumer_offsets,8] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 13:50:48,649] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,652] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,657] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,658] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 13:50:48,667] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,669] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,669] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 13:50:48,679] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,680] INFO Partition [__consumer_offsets,31] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 13:50:48,684] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,686] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,690] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 13:50:48,692] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,694] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,696] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,698] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,698] INFO Partition [__consumer_offsets,5] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 13:50:48,704] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,706] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,707] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 13:50:48,708] INFO Partition [__consumer_offsets,19] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 13:50:48,728] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,732] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,734] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,738] INFO Partition [__consumer_offsets,28] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 13:50:48,743] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,744] INFO Partition [__consumer_offsets,2] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 13:50:48,745] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,747] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,748] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 13:50:48,765] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,767] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,768] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,769] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,769] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 13:50:48,771] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,773] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,775] INFO Partition [__consumer_offsets,16] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 13:50:48,775] INFO Partition [__consumer_offsets,47] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 13:50:48,790] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,802] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,804] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 13:50:48,825] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,835] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,836] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,836] INFO Partition [__consumer_offsets,25] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 13:50:48,842] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,852] INFO Partition [__consumer_offsets,38] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 13:50:48,854] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,863] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,870] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 13:50:48,870] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,872] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,872] INFO Partition [__consumer_offsets,22] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 13:50:48,889] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,892] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,895] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,896] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 13:50:48,897] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,897] INFO Partition [__consumer_offsets,13] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 13:50:48,914] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,918] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,919] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 13:50:48,921] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,933] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,936] INFO Partition [__consumer_offsets,35] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 13:50:48,955] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,958] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,961] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,966] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:48,969] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:48,975] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,004] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 13:50:49,008] INFO Partition [__consumer_offsets,0] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 13:50:49,012] INFO Partition [__consumer_offsets,44] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 13:50:49,020] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,027] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,028] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,029] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 13:50:49,036] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,045] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,049] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,051] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,052] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 13:50:49,054] INFO Partition [__consumer_offsets,29] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 13:50:49,055] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,057] INFO Partition [__consumer_offsets,32] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 13:50:49,069] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,072] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,072] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,074] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,083] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 13:50:49,084] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,086] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,093] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,094] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,096] INFO Partition [__consumer_offsets,48] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 13:50:49,100] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 13:50:49,105] INFO Partition [__consumer_offsets,41] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 13:50:49,111] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,112] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,118] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 13:50:49,125] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,131] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,136] INFO Partition [__consumer_offsets,45] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 13:50:49,138] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,140] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,142] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 13:50:49,208] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,210] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,212] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,212] INFO Partition [__consumer_offsets,26] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 13:50:49,212] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,214] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,215] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 13:50:49,217] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,222] INFO Partition [__consumer_offsets,0] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 13:50:49,223] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,225] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,227] INFO Partition [__consumer_offsets,42] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 13:50:49,227] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,228] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,229] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 13:50:49,235] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,244] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,248] INFO Partition [__consumer_offsets,48] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 13:50:49,249] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,251] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,252] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,254] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,254] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 13:50:49,255] INFO Partition [__consumer_offsets,23] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 13:50:49,261] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,265] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,277] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,278] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,278] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,279] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 13:50:49,282] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,283] INFO Partition [__consumer_offsets,20] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 13:50:49,286] INFO Partition [__consumer_offsets,10] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 13:50:49,295] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,297] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,308] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,309] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,310] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 13:50:49,311] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,317] INFO Partition [__consumer_offsets,39] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 13:50:49,319] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,320] INFO Partition [__consumer_offsets,45] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 13:50:49,327] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,333] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,334] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,339] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,340] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 13:50:49,340] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,342] INFO Partition [__consumer_offsets,17] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 13:50:49,345] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,347] INFO Partition [__consumer_offsets,7] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 13:50:49,352] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,354] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,355] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 13:50:49,357] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,360] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,360] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,362] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,363] INFO Partition [__consumer_offsets,36] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 13:50:49,364] INFO Partition [__consumer_offsets,42] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 13:50:49,370] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,371] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,373] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 13:50:49,373] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,374] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,377] INFO Partition [__consumer_offsets,14] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 13:50:49,378] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,386] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,389] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,393] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,394] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,396] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 13:50:49,402] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,407] INFO Partition [__consumer_offsets,4] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 13:50:49,412] INFO Partition [__consumer_offsets,33] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 13:50:49,421] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,422] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,425] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 13:50:49,435] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,438] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,447] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,446] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,448] INFO Partition [__consumer_offsets,11] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 13:50:49,451] INFO Partition [__consumer_offsets,1] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 13:50:49,455] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,458] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,463] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,465] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,466] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 13:50:49,466] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,470] INFO Partition [__consumer_offsets,39] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 13:50:49,473] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,479] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,480] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,481] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 13:50:49,485] INFO Partition [__consumer_offsets,30] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 13:50:49,498] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,499] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,503] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,505] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,509] INFO Partition [__consumer_offsets,36] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 13:50:49,510] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 13:50:49,520] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,521] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,523] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 13:50:49,531] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,544] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,547] INFO Partition [__consumer_offsets,33] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 13:50:49,551] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,556] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,556] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,559] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,560] INFO Partition [__consumer_offsets,27] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 13:50:49,561] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 13:50:49,588] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,589] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,589] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,591] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,591] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,592] INFO Partition [__consumer_offsets,8] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 13:50:49,594] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 13:50:49,598] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,606] INFO Partition [__consumer_offsets,49] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 13:50:49,626] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,626] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,627] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,628] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,628] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 13:50:49,629] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,630] INFO Partition [__consumer_offsets,30] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 13:50:49,631] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,633] INFO Partition [__consumer_offsets,24] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 13:50:49,637] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,638] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,640] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 13:50:49,645] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,647] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,649] INFO Partition [__consumer_offsets,5] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 13:50:49,653] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,654] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,655] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 13:50:49,663] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,674] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,682] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,686] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,687] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 13:50:49,689] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,696] INFO Partition [__consumer_offsets,46] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 13:50:49,699] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,701] INFO Partition [__consumer_offsets,21] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 13:50:49,713] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,714] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,715] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 13:50:49,733] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,739] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,739] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,740] INFO Partition [__consumer_offsets,27] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 13:50:49,742] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,743] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,744] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,744] INFO Partition [__consumer_offsets,2] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 13:50:49,745] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 13:50:49,766] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,771] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,772] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,773] INFO Partition [__consumer_offsets,18] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 13:50:49,774] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,775] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,776] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 13:50:49,779] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,2],[__consumer_offsets,7],[__consumer_offsets,38],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,11],[__consumer_offsets,22],[__consumer_offsets,26],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,40],[__consumer_offsets,47],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,5],[__consumer_offsets,14],[__consumer_offsets,41],[__consumer_offsets,4],[__consumer_offsets,1],[__consumer_offsets,32],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:49,783] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,784] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,786] INFO Partition [__consumer_offsets,15] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 13:50:49,789] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,790] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,796] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,797] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,798] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,799] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,799] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,800] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,801] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,801] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,802] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,803] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,807] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,808] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,809] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,810] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,811] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,813] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,814] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,815] INFO Partition [__consumer_offsets,24] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 13:50:49,816] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,817] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,818] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,819] INFO Partition [__consumer_offsets,12] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 13:50:49,820] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,820] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,820] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,822] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,822] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,823] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,823] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,823] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,823] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,823] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,825] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,825] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,827] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,827] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:49,838] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,840] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,841] INFO Partition [__consumer_offsets,9] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 13:50:49,847] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,849] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,854] INFO Partition [__consumer_offsets,43] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 13:50:49,868] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,879] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,880] INFO Partition [__consumer_offsets,47] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 13:50:49,879] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 13:50:49,890] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,894] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,899] INFO Partition [__consumer_offsets,21] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 13:50:49,901] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,903] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,906] INFO Partition [__consumer_offsets,38] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 13:50:49,916] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 13:50:49,923] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,929] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:49,933] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,933] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:49,946] INFO Partition [__consumer_offsets,35] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 13:50:49,947] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,959] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,959] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,961] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,964] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,970] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,970] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,971] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:49,979] INFO Partition [__consumer_offsets,40] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 13:50:49,979] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,980] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,982] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,983] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,988] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,989] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,996] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:49,996] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,014] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 18 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,023] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,027] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,030] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,036] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,036] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,042] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,043] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,043] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,045] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,051] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,053] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,060] INFO Partition [__consumer_offsets,44] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 13:50:50,064] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,066] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,066] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,073] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,073] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,078] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,083] INFO Partition [__consumer_offsets,37] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 13:50:50,085] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,086] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,087] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,087] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,090] INFO Partition [__consumer_offsets,6] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 13:50:50,095] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,096] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,103] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,106] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,108] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,110] INFO Partition [__consumer_offsets,18] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 13:50:50,113] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,115] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,116] INFO Partition [__consumer_offsets,41] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 13:50:50,127] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,131] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,139] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,142] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,145] INFO Partition [__consumer_offsets,32] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 13:50:50,145] INFO Partition [__consumer_offsets,34] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 13:50:50,158] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,158] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,160] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,161] INFO Partition [__consumer_offsets,3] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 13:50:50,162] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,163] INFO Partition [__consumer_offsets,15] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 13:50:50,165] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,2],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,38],[__consumer_offsets,9],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,11],[__consumer_offsets,26],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,36],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,47],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,6],[__consumer_offsets,5],[__consumer_offsets,3],[__consumer_offsets,14],[__consumer_offsets,18],[__consumer_offsets,41],[__consumer_offsets,42],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,32],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,0],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:50,170] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,172] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,173] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,174] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,176] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,176] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,178] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,179] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,179] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,179] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,180] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,181] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,182] INFO Partition [__consumer_offsets,12] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 13:50:50,182] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,183] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,183] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,184] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,184] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,186] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,186] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,187] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,188] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,188] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,189] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,189] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,190] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,190] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,191] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,192] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,192] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,193] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,193] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,195] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,196] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,196] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,197] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,198] INFO Partition [__consumer_offsets,31] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 13:50:50,198] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,200] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,213] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,215] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,217] INFO Partition [__consumer_offsets,9] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 13:50:50,234] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:50,229] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 13:50:50,241] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,242] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,246] INFO Partition [__consumer_offsets,19] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 13:50:50,250] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,256] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,267] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,22] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,274] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,278] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,279] INFO Partition [__consumer_offsets,28] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 13:50:50,280] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,25] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,280] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,286] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,28] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,292] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,302] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,31] in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,303] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,308] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,34] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,310] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,313] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,316] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,37] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,317] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,317] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,322] INFO Partition [__consumer_offsets,6] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 13:50:50,322] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,40] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,324] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,328] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,43] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,330] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,337] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,337] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,46] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,338] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,338] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,340] INFO Partition [__consumer_offsets,25] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 13:50:50,343] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,49] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,345] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,351] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,1] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,354] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,357] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,362] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,4] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,364] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,366] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,368] INFO Partition [__consumer_offsets,16] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 13:50:50,370] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,7] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,370] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,375] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,10] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,376] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,379] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,382] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,383] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,13] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,384] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,386] INFO Partition [__consumer_offsets,22] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 13:50:50,389] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,16] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,392] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,394] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,395] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,397] INFO Partition [__consumer_offsets,3] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 13:50:50,398] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,19] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,407] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 13:50:50,409] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 13:50:50,410] INFO Partition [__consumer_offsets,13] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 13:50:50,412] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,31],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,19],[__consumer_offsets,22],[__consumer_offsets,10],[__consumer_offsets,36],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,40],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,3],[__consumer_offsets,18],[__consumer_offsets,42],[__consumer_offsets,4],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,1],[__consumer_offsets,13],[__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:50,418] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,418] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,419] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,419] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,420] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,421] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,422] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,423] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,424] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,424] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,425] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,426] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,427] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,427] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,428] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,428] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,429] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,429] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,430] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,430] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,431] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,432] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,433] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,434] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,434] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,435] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,436] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,437] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,441] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,442] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,442] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,443] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,443] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,444] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 13:50:50,448] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 13:50:50,468] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 13:50:50,471] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 13:50:50,482] INFO [GroupCoordinator 1]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 13:50:50,505] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 13:50:50,509] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,530] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,2] in 13 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,556] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,573] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,5] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,575] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,580] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,8] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,580] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,586] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,11] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,587] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,609] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,14] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,610] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,619] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,17] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,620] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,628] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,20] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,637] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,647] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,23] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,648] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,659] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,26] in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,677] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,695] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,29] in 14 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,710] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,728] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,32] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,734] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,745] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,35] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,746] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,751] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,38] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,759] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,763] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,41] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,764] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,772] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,44] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,774] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:50:50,779] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,47] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:52:34,514] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 13:52:34,520] INFO [GroupCoordinator 1]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 13:57:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:57:24,214] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 13:57:55,397] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:07:01,133] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:07:24,226] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:07:55,410] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:09:46,501] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:09:46,501] INFO [GroupCoordinator 1]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:09:46,520] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:09:46,638] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:09:46,643] INFO [GroupCoordinator 1]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:10:11,624] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:10:11,625] INFO [GroupCoordinator 1]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:10:11,632] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:10:11,906] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:10:11,909] INFO [GroupCoordinator 1]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:17:01,145] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:17:24,238] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:17:55,422] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:20:21,014] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:20:21,016] INFO [GroupCoordinator 1]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:20:21,026] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:20:21,161] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:20:21,163] INFO [GroupCoordinator 1]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:22:56,173] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:56,205] INFO Property auto.offset.reset is overridden to smallest (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:56,205] INFO Property group.id is overridden to console-consumer-71567 (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:56,206] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:56,252] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Connecting to zookeeper instance at localhost:2181 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,273] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], starting auto committer every 60000 ms (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,301] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], begin registering consumer console-consumer-71567_MSSPAD370-1474879976250-4185eb40 in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,339] INFO Creating /consumers/console-consumer-71567/ids/console-consumer-71567_MSSPAD370-1474879976250-4185eb40 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:22:56,349] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:22:56,350] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], end registering consumer console-consumer-71567_MSSPAD370-1474879976250-4185eb40 in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,357] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], starting watcher executor thread for consumer console-consumer-71567_MSSPAD370-1474879976250-4185eb40 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,387] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], begin rebalancing consumer console-consumer-71567_MSSPAD370-1474879976250-4185eb40 try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,586] INFO [ConsumerFetcherManager-1474879976270] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 14:22:56,587] INFO [ConsumerFetcherManager-1474879976270] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 14:22:56,590] INFO [ConsumerFetcherManager-1474879976270] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 14:22:56,592] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Cleared all relevant queues for this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,595] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Cleared the data chunks in all the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,596] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Committing all offsets after clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,599] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Releasing partition ownership (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:56,656] INFO Consumer console-consumer-71567_MSSPAD370-1474879976250-4185eb40 rebalancing the following partitions: ArrayBuffer(0) for topic Text with consumers: List(console-consumer-71567_MSSPAD370-1474879976250-4185eb40-0) (kafka.consumer.RangeAssignor)
[2016-09-26 14:22:56,661] INFO console-consumer-71567_MSSPAD370-1474879976250-4185eb40-0 attempting to claim partition 0 (kafka.consumer.RangeAssignor)
[2016-09-26 14:22:56,984] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], console-consumer-71567_MSSPAD370-1474879976250-4185eb40-0 successfully owned partition 0 for topic Text (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:57,022] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Consumer console-consumer-71567_MSSPAD370-1474879976250-4185eb40 selected partitions : Text:0: fetched offset = -1: consumed offset = -1 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:57,027] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40-leader-finder-thread], Starting  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-26 14:22:57,028] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], end rebalancing consumer console-consumer-71567_MSSPAD370-1474879976250-4185eb40 try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:57,032] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Creating topic event watcher for topics Text (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:57,075] INFO [console-consumer-71567_MSSPAD370-1474879976250-4185eb40], Topics to consume = List(Text) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 14:22:57,083] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:57,083] INFO Property client.id is overridden to console-consumer-71567 (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:57,084] INFO Property metadata.broker.list is overridden to localhost:9092,localhost:9093,localhost:9094 (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:57,085] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-26 14:22:57,102] INFO Fetching metadata from broker BrokerEndPoint(2,localhost,9094) with correlation id 0 for 1 topic(s) Set(Text) (kafka.client.ClientUtils$)
[2016-09-26 14:22:57,371] INFO Connected to localhost:9094 for producing (kafka.producer.SyncProducer)
[2016-09-26 14:22:57,417] INFO Disconnecting from localhost:9094 (kafka.producer.SyncProducer)
[2016-09-26 14:22:57,445] INFO [ConsumerFetcherThread-console-consumer-71567_MSSPAD370-1474879976250-4185eb40-0-0], Starting  (kafka.consumer.ConsumerFetcherThread)
[2016-09-26 14:22:57,465] INFO [ConsumerFetcherManager-1474879976270] Added fetcher for partitions ArrayBuffer([[Text,0], initOffset -1 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 14:26:12,810] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:26:12,811] INFO [GroupCoordinator 1]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:26:12,815] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:26:17,703] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:26:17,709] INFO [GroupCoordinator 1]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:27:01,157] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:27:24,251] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:28:59,486] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9094
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs2
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 2
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 14:28:59,558] INFO starting (kafka.server.KafkaServer)
[2016-09-26 14:28:59,566] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 14:28:59,872] INFO Log directory 'D:\tmp\kafka-logs2' not found, creating it. (kafka.log.LogManager)
[2016-09-26 14:28:59,881] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 14:28:59,888] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 14:28:59,965] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 14:28:59,968] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 14:28:59,974] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 14:29:00,040] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2016-09-26 14:29:00,044] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 14:29:00,067] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:00,068] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:00,130] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:00,140] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:00,141] INFO 2 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-26 14:29:00,214] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:00,215] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:00,232] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:29:00,233] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:29:00,241] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:29:00,261] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 14:29:00,262] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 14:29:00,269] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 14:29:00,299] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:00,320] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:00,323] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9094,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 14:29:00,324] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 14:29:00,329] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-26 14:29:00,374] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2016-09-26 14:29:25,284] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9093
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs1
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 1
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 14:29:25,359] INFO starting (kafka.server.KafkaServer)
[2016-09-26 14:29:25,366] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 14:29:25,574] INFO Log directory 'D:\tmp\kafka-logs1' not found, creating it. (kafka.log.LogManager)
[2016-09-26 14:29:25,582] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 14:29:25,590] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 14:29:25,649] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 14:29:25,652] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 14:29:25,657] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 14:29:25,719] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2016-09-26 14:29:25,727] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 14:29:25,749] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:25,750] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:25,908] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:25,909] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:25,915] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:29:25,917] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:29:25,923] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:29:25,933] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 14:29:25,934] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 14:29:25,941] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 14:29:25,970] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:25,989] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:25,991] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 14:29:25,994] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 14:29:26,040] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2016-09-26 14:29:45,736] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 14:29:45,810] INFO starting (kafka.server.KafkaServer)
[2016-09-26 14:29:45,817] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 14:29:46,013] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-26 14:29:46,022] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 14:29:46,030] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 14:29:46,096] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 14:29:46,099] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 14:29:46,105] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 14:29:46,164] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-26 14:29:46,169] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 14:29:46,191] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:46,192] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:46,340] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:46,343] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 14:29:46,365] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:29:46,366] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:29:46,370] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:29:46,384] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 14:29:46,386] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 14:29:46,393] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 14:29:46,422] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:46,438] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 14:29:46,441] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 14:29:46,442] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 14:29:46,516] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-26 14:30:05,043] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:30:05,141] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:30:05,150] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:30:05,154] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:30:05,157] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 14:30:05,173] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:30:05,178] INFO Partition [_schemas,0] on broker 1: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 14:30:05,210] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:30:05,215] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 14:30:05,232] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:30:05,236] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:30:05,238] INFO Partition [_schemas,0] on broker 2: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 14:30:05,246] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:30:05,252] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 14:30:05,265] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 14:30:05,270] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:30:05,347] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 14:30:05,354] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:53,024] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 14:35:53,028] INFO [KafkaApi-0] Auto creation of topic topic2 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 14:35:53,124] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 14:35:53,139] INFO [KafkaApi-0] Auto creation of topic topic3 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 14:35:53,151] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [topic2,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:53,253] INFO Completed load of log topic2-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:53,259] INFO Created log for partition [topic2,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:53,262] INFO Partition [topic2,0] on broker 0: No checkpointed highwatermark is found for partition [topic2,0] (kafka.cluster.Partition)
[2016-09-26 14:35:53,289] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 14:35:53,307] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [topic3,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:53,314] INFO [KafkaApi-0] Auto creation of topic Text with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 14:35:53,318] INFO Completed load of log topic3-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:53,327] INFO Created log for partition [topic3,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:53,331] INFO Partition [topic3,0] on broker 0: No checkpointed highwatermark is found for partition [topic3,0] (kafka.cluster.Partition)
[2016-09-26 14:35:53,415] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:53,416] INFO Topic creation {"version":1,"partitions":{"45":[1,0,2],"34":[2,1,0],"12":[1,2,0],"8":[0,1,2],"19":[2,0,1],"23":[0,2,1],"4":[2,1,0],"40":[2,1,0],"15":[1,0,2],"11":[0,2,1],"9":[1,0,2],"44":[0,1,2],"33":[1,0,2],"22":[2,1,0],"26":[0,1,2],"37":[2,0,1],"13":[2,0,1],"46":[2,1,0],"24":[1,2,0],"35":[0,2,1],"16":[2,1,0],"5":[0,2,1],"10":[2,1,0],"48":[1,2,0],"21":[1,0,2],"43":[2,0,1],"32":[0,1,2],"49":[2,0,1],"6":[1,2,0],"36":[1,2,0],"1":[2,0,1],"39":[1,0,2],"17":[0,2,1],"25":[2,0,1],"14":[0,1,2],"47":[0,2,1],"31":[2,0,1],"42":[1,2,0],"0":[1,2,0],"20":[0,1,2],"27":[1,0,2],"2":[0,1,2],"38":[0,1,2],"18":[1,2,0],"30":[1,2,0],"7":[2,0,1],"29":[0,2,1],"41":[0,2,1],"3":[1,0,2],"28":[2,1,0]}} (kafka.admin.AdminUtils$)
[2016-09-26 14:35:53,430] INFO Completed load of log Text-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:53,432] INFO Created log for partition [Text,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:53,435] INFO Partition [Text,0] on broker 0: No checkpointed highwatermark is found for partition [Text,0] (kafka.cluster.Partition)
[2016-09-26 14:35:53,436] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 3 is successful (kafka.server.KafkaApis)
[2016-09-26 14:35:54,534] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,0],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,9],[__consumer_offsets,42],[__consumer_offsets,48],[__consumer_offsets,18],[__consumer_offsets,12],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:54,569] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,574] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,581] INFO Partition [__consumer_offsets,0] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 14:35:54,632] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,637] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,639] INFO Partition [__consumer_offsets,48] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 14:35:54,659] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,664] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,668] INFO Partition [__consumer_offsets,45] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 14:35:54,736] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,792] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,798] INFO Partition [__consumer_offsets,42] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 14:35:54,820] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:54,506] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,28],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,13],[__consumer_offsets,40],[__consumer_offsets,37],[__consumer_offsets,34],[__consumer_offsets,22],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:54,859] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,868] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,870] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,872] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 14:35:54,901] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,915] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,918] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,919] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 14:35:54,937] INFO Partition [__consumer_offsets,39] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 14:35:54,981] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:54,983] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:54,985] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 14:35:55,001] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,022] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,043] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,059] INFO Partition [__consumer_offsets,36] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 14:35:55,080] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,086] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,089] INFO Partition [__consumer_offsets,33] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 14:35:55,091] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,118] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,120] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,134] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 14:35:55,151] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,155] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,166] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,169] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,170] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 14:35:55,177] INFO Partition [__consumer_offsets,30] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 14:35:55,214] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,124] INFO Partition [__consumer_offsets,10] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 14:35:55,245] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,247] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 14:35:55,365] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,366] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,368] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,378] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,384] INFO Partition [__consumer_offsets,27] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 14:35:55,385] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 14:35:55,390] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,393] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,396] INFO Partition [__consumer_offsets,7] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 14:35:55,404] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,409] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,412] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 14:35:55,428] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,429] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,436] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,438] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,440] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 14:35:55,441] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,443] INFO Partition [__consumer_offsets,24] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 14:35:55,448] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,457] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,462] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,470] INFO Partition [__consumer_offsets,21] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 14:35:55,475] INFO Partition [__consumer_offsets,4] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 14:35:55,478] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,481] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,482] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 14:35:55,496] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,498] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,503] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,505] INFO Partition [__consumer_offsets,18] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 14:35:55,507] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,509] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,509] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,510] INFO Partition [__consumer_offsets,1] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 14:35:55,511] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 14:35:55,522] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,524] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,531] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,534] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,534] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,542] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,543] INFO Partition [__consumer_offsets,49] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 14:35:55,544] INFO Partition [__consumer_offsets,15] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 14:35:55,548] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 14:35:55,560] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,564] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,565] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,567] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,572] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 14:35:55,582] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,588] INFO Partition [__consumer_offsets,12] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 14:35:55,591] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,594] INFO Partition [__consumer_offsets,46] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 14:35:55,602] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,606] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,609] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 14:35:55,621] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,627] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,630] INFO Partition [__consumer_offsets,9] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 14:35:55,660] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,652] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,671] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,672] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,673] INFO Partition [__consumer_offsets,43] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 14:35:55,676] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,680] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,684] INFO Partition [__consumer_offsets,6] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 14:35:55,689] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 14:35:55,708] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,710] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,712] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 14:35:55,714] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,726] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,740] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,741] INFO Partition [__consumer_offsets,40] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 14:35:55,753] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,756] INFO Partition [__consumer_offsets,3] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 14:35:55,773] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,775] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,780] INFO Partition [__consumer_offsets,37] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 14:35:55,800] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,802] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,810] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,814] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,815] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 14:35:55,816] INFO Partition [__consumer_offsets,34] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 14:35:55,832] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,833] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,839] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,840] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,841] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,847] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,848] INFO Partition [__consumer_offsets,31] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 14:35:55,854] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 14:35:55,855] INFO Partition [__consumer_offsets,29] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 14:35:55,877] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,880] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,881] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 14:35:55,886] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,896] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,898] INFO Partition [__consumer_offsets,10] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 14:35:55,904] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,914] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,925] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,926] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,927] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 14:35:55,931] INFO Partition [__consumer_offsets,19] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 14:35:55,933] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,939] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,941] INFO Partition [__consumer_offsets,26] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 14:35:55,942] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,944] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,945] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,947] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 14:35:55,956] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,959] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,959] INFO Partition [__consumer_offsets,28] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 14:35:55,965] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,968] INFO Partition [__consumer_offsets,7] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 14:35:55,975] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,980] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,980] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,982] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 14:35:55,983] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:55,995] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:55,995] INFO Partition [__consumer_offsets,16] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 14:35:56,000] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,003] INFO Partition [__consumer_offsets,4] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 14:35:56,003] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,007] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,009] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 14:35:56,019] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,023] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,026] INFO Partition [__consumer_offsets,23] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 14:35:56,038] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,040] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,041] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,042] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,044] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,044] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 14:35:56,046] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,050] INFO Partition [__consumer_offsets,25] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 14:35:56,052] INFO Partition [__consumer_offsets,1] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 14:35:56,065] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,068] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,075] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,078] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 14:35:56,089] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,098] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,101] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,104] INFO Partition [__consumer_offsets,20] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 14:35:56,115] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,117] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,130] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,143] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 14:35:56,142] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,146] INFO Partition [__consumer_offsets,17] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 14:35:56,150] INFO Partition [__consumer_offsets,22] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 14:35:56,182] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,182] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,185] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,190] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 14:35:56,195] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,198] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,204] INFO Partition [__consumer_offsets,14] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 14:35:56,209] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,212] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,214] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 14:35:56,220] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,225] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,230] INFO Partition [__consumer_offsets,49] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 14:35:56,238] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,242] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,245] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 14:35:56,246] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,255] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,257] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,260] INFO Partition [__consumer_offsets,11] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 14:35:56,262] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,265] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,267] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 14:35:56,278] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,281] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,283] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 14:35:56,288] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,293] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,296] INFO Partition [__consumer_offsets,46] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 14:35:56,299] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,301] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,303] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 14:35:56,314] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,316] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,330] INFO Partition [__consumer_offsets,8] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 14:35:56,330] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,332] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,342] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 14:35:56,352] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,357] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,362] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,365] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,366] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 14:35:56,377] INFO Partition [__consumer_offsets,43] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 14:35:56,393] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,394] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,396] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 14:35:56,404] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,413] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,415] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 14:35:56,428] INFO Partition [__consumer_offsets,13] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 14:35:56,437] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,442] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,454] INFO Partition [__consumer_offsets,5] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 14:35:56,458] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,461] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,462] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 14:35:56,467] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,471] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,475] INFO Partition [__consumer_offsets,2] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 14:35:56,488] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,493] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,496] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,497] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,499] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 14:35:56,504] INFO Partition [__consumer_offsets,40] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 14:35:56,519] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,519] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,530] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,531] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,532] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 14:35:56,536] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,540] INFO Partition [__consumer_offsets,37] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 14:35:56,542] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,551] INFO Partition [__consumer_offsets,0] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 14:35:56,563] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,566] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,569] INFO Partition [__consumer_offsets,34] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 14:35:56,573] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,580] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,582] INFO Partition [__consumer_offsets,29] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 14:35:56,596] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,598] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,600] INFO Partition [__consumer_offsets,48] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 14:35:56,609] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,611] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,613] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,615] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,617] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,619] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 14:35:56,628] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,631] INFO Partition [__consumer_offsets,31] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 14:35:56,632] INFO Partition [__consumer_offsets,45] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 14:35:56,636] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,642] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,644] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 14:35:56,667] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,674] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,679] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,680] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 14:35:56,693] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,696] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,698] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,701] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,703] INFO Partition [__consumer_offsets,47] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 14:35:56,703] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,705] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 14:35:56,712] INFO Partition [__consumer_offsets,26] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 14:35:56,721] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,723] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,724] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 14:35:56,733] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,735] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,766] INFO Partition [__consumer_offsets,19] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 14:35:56,815] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,815] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,816] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,817] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,817] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,819] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,821] INFO Partition [__consumer_offsets,42] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 14:35:56,829] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 14:35:56,829] INFO Partition [__consumer_offsets,28] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 14:35:56,842] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,845] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,847] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 14:35:56,854] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,863] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,867] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,870] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,871] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,877] INFO Partition [__consumer_offsets,23] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 14:35:56,878] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,896] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 14:35:56,896] INFO Partition [__consumer_offsets,38] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 14:35:56,907] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,918] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,926] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,934] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,939] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,940] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 14:35:56,954] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,961] INFO Partition [__consumer_offsets,35] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 14:35:56,975] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:56,983] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:56,985] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 14:35:57,002] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,004] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,005] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 14:35:57,007] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,31],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,19],[__consumer_offsets,22],[__consumer_offsets,10],[__consumer_offsets,36],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,40],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,3],[__consumer_offsets,18],[__consumer_offsets,42],[__consumer_offsets,4],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,1],[__consumer_offsets,13],[__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:57,011] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,013] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,013] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,015] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,017] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,020] INFO Partition [__consumer_offsets,44] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 14:35:57,020] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,021] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,026] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,028] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,029] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,032] INFO Partition [__consumer_offsets,20] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 14:35:57,033] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,035] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,037] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,038] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,040] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,041] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,048] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,049] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,052] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,053] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,055] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,055] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,061] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,061] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,065] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,066] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,067] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,070] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,071] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,073] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,075] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,075] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,075] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,077] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,078] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,078] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,086] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,090] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,096] INFO Partition [__consumer_offsets,25] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 14:35:57,125] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,129] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,132] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:57,146] INFO Partition [__consumer_offsets,39] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 14:35:57,142] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,147] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 14:35:57,160] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,162] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,169] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,171] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,173] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,176] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,178] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,182] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,184] INFO Partition [__consumer_offsets,16] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 14:35:57,186] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,187] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,194] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,199] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,201] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,207] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,217] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,221] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,223] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,226] INFO Partition [__consumer_offsets,22] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 14:35:57,231] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,235] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,239] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,248] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,249] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,251] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,252] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,254] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,256] INFO Partition [__consumer_offsets,41] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 14:35:57,258] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,260] INFO Partition [__consumer_offsets,17] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 14:35:57,265] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,272] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,280] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,280] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,287] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,289] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,291] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,298] INFO Partition [__consumer_offsets,36] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 14:35:57,298] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,300] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,312] INFO Partition [__consumer_offsets,32] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 14:35:57,323] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,327] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,329] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,333] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,340] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,341] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,344] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,348] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,348] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,350] INFO Partition [__consumer_offsets,13] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 14:35:57,352] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,355] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,2],[__consumer_offsets,7],[__consumer_offsets,38],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,11],[__consumer_offsets,22],[__consumer_offsets,26],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,40],[__consumer_offsets,47],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,5],[__consumer_offsets,14],[__consumer_offsets,41],[__consumer_offsets,4],[__consumer_offsets,1],[__consumer_offsets,32],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:57,372] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,377] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,381] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,383] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,384] INFO Partition [__consumer_offsets,14] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 14:35:57,386] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,389] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,390] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,393] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,396] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,397] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,404] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,405] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,406] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,408] INFO Partition [__consumer_offsets,33] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 14:35:57,412] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,419] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,422] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,423] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,426] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,427] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,430] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,431] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,437] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,439] INFO Partition [__consumer_offsets,11] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 14:35:57,440] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,443] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,444] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,446] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,447] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,448] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,454] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,455] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,455] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,456] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,457] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,458] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,459] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,460] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,461] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,462] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,464] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,485] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,487] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,490] INFO Partition [__consumer_offsets,30] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 14:35:57,505] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,506] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,508] INFO Partition [__consumer_offsets,27] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 14:35:57,518] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,521] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,523] INFO Partition [__consumer_offsets,8] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 14:35:57,536] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 14:35:57,547] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:57,549] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,552] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,555] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 14:35:57,555] INFO Partition [__consumer_offsets,24] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 14:35:57,572] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,594] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,0] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,605] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,609] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,3] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,612] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,613] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,615] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,617] INFO Partition [__consumer_offsets,5] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 14:35:57,618] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,6] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,621] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,627] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,628] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,630] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,632] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,12] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,632] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,637] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,638] INFO Partition [__consumer_offsets,21] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 14:35:57,641] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,15] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,644] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,648] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,18] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,650] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,651] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,652] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,656] INFO Partition [__consumer_offsets,2] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 14:35:57,657] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,21] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,658] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,663] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,24] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,664] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,666] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,667] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,27] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,670] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,671] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,674] INFO Partition [__consumer_offsets,18] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 14:35:57,675] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,30] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,676] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,682] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,33] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,683] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,685] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,688] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,690] INFO Partition [__consumer_offsets,15] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 14:35:57,690] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,36] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,692] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,697] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,39] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,699] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,704] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,42] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,705] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,708] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,711] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,45] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,711] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,712] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,714] INFO Partition [__consumer_offsets,12] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 14:35:57,717] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,48] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:57,737] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,739] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,740] INFO Partition [__consumer_offsets,9] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 14:35:57,747] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,748] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,749] INFO Partition [__consumer_offsets,47] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 14:35:57,758] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,760] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,761] INFO Partition [__consumer_offsets,38] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 14:35:57,785] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,786] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,787] INFO Partition [__consumer_offsets,35] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 14:35:57,795] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,803] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,805] INFO Partition [__consumer_offsets,44] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 14:35:57,824] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,827] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,834] INFO Partition [__consumer_offsets,6] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 14:35:57,855] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,856] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,857] INFO Partition [__consumer_offsets,41] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 14:35:57,879] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,882] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,883] INFO Partition [__consumer_offsets,32] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 14:35:57,893] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 14:35:57,897] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 14:35:57,899] INFO Partition [__consumer_offsets,3] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 14:35:57,901] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,2],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,38],[__consumer_offsets,9],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,11],[__consumer_offsets,26],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,36],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,47],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,6],[__consumer_offsets,5],[__consumer_offsets,3],[__consumer_offsets,14],[__consumer_offsets,18],[__consumer_offsets,41],[__consumer_offsets,42],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,32],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,0],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:57,910] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,912] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,915] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,915] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,917] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,923] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,924] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,926] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,936] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,938] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,938] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,940] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,941] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,942] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,943] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,947] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,949] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,950] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,956] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,957] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,958] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,959] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,960] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,961] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,962] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,964] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,965] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,966] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,974] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,975] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,976] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,978] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:57,980] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 14:35:58,001] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 14:35:58,017] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,035] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 14:35:58,044] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,22] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,054] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,059] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,25] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,061] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,069] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,28] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,075] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,078] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,31] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,083] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,089] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,34] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,089] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,093] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,37] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,094] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,100] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,40] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,102] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,112] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,43] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,116] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,121] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,46] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,122] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,126] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,49] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,150] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,156] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,1] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,173] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,184] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,4] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,223] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,227] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,7] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,228] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,232] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,10] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,232] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,237] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,13] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,237] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,241] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,16] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,242] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,246] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,19] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:35:58,289] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:35:58,297] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:35:58,318] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:36:27,909] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:36:27,917] INFO [GroupCoordinator 2]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:36:54,253] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:36:54,253] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:36:54,262] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:38:21,129] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:38:21,137] INFO [GroupCoordinator 2]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 14:39:00,235] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:39:25,922] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:39:46,372] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:49:00,248] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:49:25,934] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:49:46,384] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:59:00,260] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:59:25,946] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 14:59:46,397] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:02:51,336] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:02:51,351] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:02:51,373] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:02:51,587] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:02:51,591] INFO [GroupCoordinator 2]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:09:00,272] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:09:25,959] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:09:46,409] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:14:30,329] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 15:14:30,402] INFO starting (kafka.server.KafkaServer)
[2016-09-26 15:14:30,410] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 15:14:30,777] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-26 15:14:30,805] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 15:14:30,812] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 15:14:30,871] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 15:14:30,873] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 15:14:30,883] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 15:14:30,964] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-26 15:14:30,972] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 15:14:31,008] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:31,010] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:31,071] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:14:31,080] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:14:31,082] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-26 15:14:31,168] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:31,169] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:31,183] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:14:31,185] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:14:31,196] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:14:31,209] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 15:14:31,212] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 15:14:31,221] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 15:14:31,251] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:14:31,286] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-26 15:14:31,289] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:14:31,292] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 15:14:31,293] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 15:14:31,337] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-26 15:14:52,459] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9093
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs1
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 1
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 15:14:52,563] INFO starting (kafka.server.KafkaServer)
[2016-09-26 15:14:52,575] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 15:14:52,862] INFO Log directory 'D:\tmp\kafka-logs1' not found, creating it. (kafka.log.LogManager)
[2016-09-26 15:14:52,870] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 15:14:52,878] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 15:14:52,937] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 15:14:52,939] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 15:14:52,945] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 15:14:53,005] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2016-09-26 15:14:53,013] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 15:14:53,034] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:53,035] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:53,178] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:53,180] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:14:53,203] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:14:53,205] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:14:53,219] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:14:53,222] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 15:14:53,226] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 15:14:53,230] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 15:14:53,260] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:14:53,320] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:14:53,326] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 15:14:53,329] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 15:14:53,365] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2016-09-26 15:15:11,074] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9094
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs2
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 2
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 15:15:11,149] INFO starting (kafka.server.KafkaServer)
[2016-09-26 15:15:11,156] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 15:15:11,351] INFO Log directory 'D:\tmp\kafka-logs2' not found, creating it. (kafka.log.LogManager)
[2016-09-26 15:15:11,361] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 15:15:11,368] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 15:15:11,442] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 15:15:11,445] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 15:15:11,450] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 15:15:11,514] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2016-09-26 15:15:11,522] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 15:15:11,543] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:15:11,548] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:15:11,686] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:15:11,689] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 15:15:11,715] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:15:11,716] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:15:11,725] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:15:11,734] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 15:15:11,735] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 15:15:11,743] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 15:15:11,771] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:15:11,781] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 15:15:11,784] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9094,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 15:15:11,786] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 15:15:11,882] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2016-09-26 15:15:30,362] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:15:30,490] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:15:30,492] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:15:30,497] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:15:30,499] INFO Partition [_schemas,0] on broker 2: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 15:15:30,499] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:15:30,503] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 15:15:30,510] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:15:30,513] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:15:30,520] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 15:15:30,520] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 15:15:30,557] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:15:30,582] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:15:30,584] INFO Partition [_schemas,0] on broker 1: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 15:15:30,605] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 15:15:30,634] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 15:15:30,635] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:15:30,642] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:09,945] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 15:16:09,950] INFO [KafkaApi-0] Auto creation of topic topic2 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 15:16:10,154] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 15:16:10,173] INFO [KafkaApi-0] Auto creation of topic topic3 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 15:16:10,192] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [topic2,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:10,218] INFO Completed load of log topic2-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:10,221] INFO Created log for partition [topic2,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:10,224] INFO Partition [topic2,0] on broker 0: No checkpointed highwatermark is found for partition [topic2,0] (kafka.cluster.Partition)
[2016-09-26 15:16:10,248] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 15:16:10,253] INFO [KafkaApi-0] Auto creation of topic Text with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 15:16:10,286] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [topic3,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:10,312] INFO Completed load of log topic3-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:10,315] INFO Created log for partition [topic3,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:10,316] INFO Partition [topic3,0] on broker 0: No checkpointed highwatermark is found for partition [topic3,0] (kafka.cluster.Partition)
[2016-09-26 15:16:10,347] INFO Topic creation {"version":1,"partitions":{"45":[1,0,2],"34":[2,1,0],"12":[1,2,0],"8":[0,1,2],"19":[2,0,1],"23":[0,2,1],"4":[2,1,0],"40":[2,1,0],"15":[1,0,2],"11":[0,2,1],"9":[1,0,2],"44":[0,1,2],"33":[1,0,2],"22":[2,1,0],"26":[0,1,2],"37":[2,0,1],"13":[2,0,1],"46":[2,1,0],"24":[1,2,0],"35":[0,2,1],"16":[2,1,0],"5":[0,2,1],"10":[2,1,0],"48":[1,2,0],"21":[1,0,2],"43":[2,0,1],"32":[0,1,2],"49":[2,0,1],"6":[1,2,0],"36":[1,2,0],"1":[2,0,1],"39":[1,0,2],"17":[0,2,1],"25":[2,0,1],"14":[0,1,2],"47":[0,2,1],"31":[2,0,1],"42":[1,2,0],"0":[1,2,0],"20":[0,1,2],"27":[1,0,2],"2":[0,1,2],"38":[0,1,2],"18":[1,2,0],"30":[1,2,0],"7":[2,0,1],"29":[0,2,1],"41":[0,2,1],"3":[1,0,2],"28":[2,1,0]}} (kafka.admin.AdminUtils$)
[2016-09-26 15:16:10,352] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 3 is successful (kafka.server.KafkaApis)
[2016-09-26 15:16:10,378] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:10,459] INFO Completed load of log Text-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:10,464] INFO Created log for partition [Text,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:10,469] INFO Partition [Text,0] on broker 0: No checkpointed highwatermark is found for partition [Text,0] (kafka.cluster.Partition)
[2016-09-26 15:16:11,515] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,0],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,9],[__consumer_offsets,42],[__consumer_offsets,48],[__consumer_offsets,18],[__consumer_offsets,12],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:11,539] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,28],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,13],[__consumer_offsets,40],[__consumer_offsets,37],[__consumer_offsets,34],[__consumer_offsets,22],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:11,618] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:11,662] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:11,668] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:11,671] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:11,674] INFO Partition [__consumer_offsets,10] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 15:16:11,675] INFO Partition [__consumer_offsets,0] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 15:16:11,587] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:11,842] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:11,859] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:11,869] INFO Partition [__consumer_offsets,7] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 15:16:11,879] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:11,927] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:11,929] INFO Partition [__consumer_offsets,48] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 15:16:11,993] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,015] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,017] INFO Partition [__consumer_offsets,4] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 15:16:12,098] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,101] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,102] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 15:16:12,104] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,110] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,112] INFO Partition [__consumer_offsets,45] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 15:16:12,140] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,145] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,154] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,155] INFO Partition [__consumer_offsets,42] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 15:16:12,165] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,184] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,185] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,187] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,189] INFO Partition [__consumer_offsets,39] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 15:16:12,196] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,202] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 15:16:12,216] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,220] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,222] INFO Partition [__consumer_offsets,36] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 15:16:12,237] INFO Partition [__consumer_offsets,1] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 15:16:12,243] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,272] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,276] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,278] INFO Partition [__consumer_offsets,33] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 15:16:12,280] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,316] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,319] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,321] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 15:16:12,329] INFO Partition [__consumer_offsets,30] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 15:16:12,349] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,386] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,389] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,390] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,391] INFO Partition [__consumer_offsets,49] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 15:16:12,394] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,395] INFO Partition [__consumer_offsets,27] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 15:16:12,399] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,402] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 15:16:12,423] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,439] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,446] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,451] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,476] INFO Partition [__consumer_offsets,24] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 15:16:12,493] INFO Partition [__consumer_offsets,46] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 15:16:12,516] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,530] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,534] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,535] INFO Partition [__consumer_offsets,21] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 15:16:12,540] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,552] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,560] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,561] INFO Partition [__consumer_offsets,43] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 15:16:12,564] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,567] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,568] INFO Partition [__consumer_offsets,18] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 15:16:12,572] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 15:16:12,590] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,605] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,615] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,621] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,622] INFO Partition [__consumer_offsets,15] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 15:16:12,637] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,640] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,645] INFO Partition [__consumer_offsets,12] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 15:16:12,648] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,650] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 15:16:12,661] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,664] INFO Partition [__consumer_offsets,40] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 15:16:12,676] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,685] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,687] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,694] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,695] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 15:16:12,698] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,700] INFO Partition [__consumer_offsets,9] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 15:16:12,707] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,719] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,719] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,722] INFO Partition [__consumer_offsets,37] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 15:16:12,722] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,728] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,738] INFO Partition [__consumer_offsets,6] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 15:16:12,740] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 15:16:12,752] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,753] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,754] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,756] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,758] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,759] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,760] INFO Partition [__consumer_offsets,3] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 15:16:12,762] INFO Partition [__consumer_offsets,34] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 15:16:12,764] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 15:16:12,781] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,796] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,796] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,798] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 15:16:12,807] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,808] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,808] INFO Partition [__consumer_offsets,31] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 15:16:12,811] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,813] INFO Partition [__consumer_offsets,29] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 15:16:12,825] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,828] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,838] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,840] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,843] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,843] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,847] INFO Partition [__consumer_offsets,19] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 15:16:12,858] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 15:16:12,859] INFO Partition [__consumer_offsets,10] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 15:16:12,876] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,882] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,888] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,888] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,890] INFO Partition [__consumer_offsets,28] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 15:16:12,891] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,893] INFO Partition [__consumer_offsets,26] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 15:16:12,894] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,899] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 15:16:12,911] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,913] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,915] INFO Partition [__consumer_offsets,7] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 15:16:12,917] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,929] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,932] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,942] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,946] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,947] INFO Partition [__consumer_offsets,4] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 15:16:12,947] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,954] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 15:16:12,957] INFO Partition [__consumer_offsets,16] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 15:16:12,970] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,974] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,977] INFO Partition [__consumer_offsets,23] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 15:16:12,984] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,989] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:12,994] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,996] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:12,998] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 15:16:12,998] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,000] INFO Partition [__consumer_offsets,25] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 15:16:13,001] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,006] INFO Partition [__consumer_offsets,1] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 15:16:13,021] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,029] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,030] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,034] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 15:16:13,034] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,036] INFO Partition [__consumer_offsets,22] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 15:16:13,044] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,056] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,057] INFO Partition [__consumer_offsets,20] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 15:16:13,058] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,058] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,061] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,064] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,065] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 15:16:13,066] INFO Partition [__consumer_offsets,13] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 15:16:13,069] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,076] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,082] INFO Partition [__consumer_offsets,17] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 15:16:13,112] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,116] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,118] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,121] INFO Partition [__consumer_offsets,0] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 15:16:13,121] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,125] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,127] INFO Partition [__consumer_offsets,14] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 15:16:13,129] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,136] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 15:16:13,153] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,157] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,158] INFO Partition [__consumer_offsets,49] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 15:16:13,159] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,168] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,168] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,174] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,177] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,180] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,181] INFO Partition [__consumer_offsets,11] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 15:16:13,182] INFO Partition [__consumer_offsets,29] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 15:16:13,185] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 15:16:13,199] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,199] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,204] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,205] INFO Partition [__consumer_offsets,46] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 15:16:13,211] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,214] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,220] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,221] INFO Partition [__consumer_offsets,48] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 15:16:13,221] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 15:16:13,278] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,279] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,279] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,281] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,284] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,284] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,286] INFO Partition [__consumer_offsets,8] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 15:16:13,287] INFO Partition [__consumer_offsets,45] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 15:16:13,288] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 15:16:13,312] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,321] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,325] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,327] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,329] INFO Partition [__consumer_offsets,43] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 15:16:13,332] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,334] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,338] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 15:16:13,342] INFO Partition [__consumer_offsets,26] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 15:16:13,349] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,361] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,364] INFO Partition [__consumer_offsets,5] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 15:16:13,373] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,380] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,384] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 15:16:13,392] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,395] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,396] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,398] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,400] INFO Partition [__consumer_offsets,2] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 15:16:13,402] INFO Partition [__consumer_offsets,42] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 15:16:13,410] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,412] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,415] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,417] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,418] INFO Partition [__consumer_offsets,40] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 15:16:13,429] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 15:16:13,439] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,442] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,446] INFO Partition [__consumer_offsets,37] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 15:16:13,460] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,463] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,465] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,465] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,467] INFO Partition [__consumer_offsets,34] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 15:16:13,470] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 15:16:13,474] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,479] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,481] INFO Partition [__consumer_offsets,23] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 15:16:13,483] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,494] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,496] INFO Partition [__consumer_offsets,31] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 15:16:13,516] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,517] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,521] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,523] INFO Partition [__consumer_offsets,47] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 15:16:13,523] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,525] INFO Partition [__consumer_offsets,20] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 15:16:13,531] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,534] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,536] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 15:16:13,543] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,546] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,552] INFO Partition [__consumer_offsets,19] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 15:16:13,564] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,575] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,584] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,587] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,587] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 15:16:13,592] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,594] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,595] INFO Partition [__consumer_offsets,28] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 15:16:13,602] INFO Partition [__consumer_offsets,39] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 15:16:13,607] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,612] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,614] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 15:16:13,627] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,628] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,630] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,631] INFO Partition [__consumer_offsets,38] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 15:16:13,636] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,647] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,648] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,649] INFO Partition [__consumer_offsets,17] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 15:16:13,652] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 15:16:13,661] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,663] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,668] INFO Partition [__consumer_offsets,35] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 15:16:13,669] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,674] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,678] INFO Partition [__consumer_offsets,36] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 15:16:13,680] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,684] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,685] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,687] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,688] INFO Partition [__consumer_offsets,44] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 15:16:13,690] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 15:16:13,706] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,711] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,712] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,715] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,716] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,718] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,721] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 15:16:13,723] INFO Partition [__consumer_offsets,25] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 15:16:13,726] INFO Partition [__consumer_offsets,14] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 15:16:13,738] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,742] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,744] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 15:16:13,746] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,751] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,755] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,758] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,761] INFO Partition [__consumer_offsets,16] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 15:16:13,761] INFO Partition [__consumer_offsets,33] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 15:16:13,766] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,769] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,773] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,777] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,780] INFO Partition [__consumer_offsets,22] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 15:16:13,786] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 15:16:13,797] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,800] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,802] INFO Partition [__consumer_offsets,11] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 15:16:13,805] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,813] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,818] INFO Partition [__consumer_offsets,41] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 15:16:13,827] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,836] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,839] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,841] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 15:16:13,844] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,847] INFO Partition [__consumer_offsets,30] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 15:16:13,848] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,851] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,854] INFO Partition [__consumer_offsets,32] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 15:16:13,861] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,862] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,869] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 15:16:13,887] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,896] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,898] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,902] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,910] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,916] INFO Partition [__consumer_offsets,13] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 15:16:13,917] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,919] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,2],[__consumer_offsets,7],[__consumer_offsets,38],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,11],[__consumer_offsets,22],[__consumer_offsets,26],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,40],[__consumer_offsets,47],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,5],[__consumer_offsets,14],[__consumer_offsets,41],[__consumer_offsets,4],[__consumer_offsets,1],[__consumer_offsets,32],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:13,920] INFO Partition [__consumer_offsets,27] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 15:16:13,920] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 15:16:13,940] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,944] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,946] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,948] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,951] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,951] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 15:16:13,952] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,952] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,955] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,955] INFO Partition [__consumer_offsets,8] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 15:16:13,955] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,958] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,962] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,963] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,965] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,967] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,971] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,978] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,980] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,982] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,983] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:13,983] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,984] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,985] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:13,985] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:13,995] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,004] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 15:16:14,009] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,012] INFO Partition [__consumer_offsets,24] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 15:16:14,022] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,028] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,038] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,049] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,050] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,051] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,052] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,055] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,060] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,063] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,065] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 15:16:14,069] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,070] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,079] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,081] INFO Partition [__consumer_offsets,5] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 15:16:14,082] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,086] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,089] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,093] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,097] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,099] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,100] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,102] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,104] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,108] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 15:16:14,110] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,113] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,122] INFO Partition [__consumer_offsets,21] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 15:16:14,137] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,141] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,145] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,146] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,149] INFO Partition [__consumer_offsets,2] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 15:16:14,151] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 15:16:14,167] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,169] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,173] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,181] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 15:16:14,183] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,184] INFO Partition [__consumer_offsets,18] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 15:16:14,187] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 15:16:14,197] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,197] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:14,198] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 15:16:14,215] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,217] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,222] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 15:16:14,228] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,229] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,242] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,247] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,0] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,251] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,256] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,3] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,257] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,261] INFO Partition [__consumer_offsets,15] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 15:16:14,262] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,6] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,264] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,271] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,9] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,273] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,273] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,283] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 15:16:14,287] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,12] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,289] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,295] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,15] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,296] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,301] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,18] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,306] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,312] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,320] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,21] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,321] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,325] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,24] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,326] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,328] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,333] INFO Partition [__consumer_offsets,12] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 15:16:14,333] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,27] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,334] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,336] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,338] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,349] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 15:16:14,350] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,30] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,357] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,357] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,366] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,373] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,373] INFO Partition [__consumer_offsets,9] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 15:16:14,375] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,377] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,33] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,379] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 15:16:14,381] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,388] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,36] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,389] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,399] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,407] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,39] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,407] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,413] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,416] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,42] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,419] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,420] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,421] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,421] INFO Partition [__consumer_offsets,47] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 15:16:14,424] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,45] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,425] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 15:16:14,427] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,431] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,48] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,452] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,454] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,457] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 15:16:14,467] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,471] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,474] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,476] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,479] INFO Partition [__consumer_offsets,38] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 15:16:14,481] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 15:16:14,494] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,500] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,502] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,505] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,505] INFO Partition [__consumer_offsets,35] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 15:16:14,506] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 15:16:14,519] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,522] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,523] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,523] INFO Partition [__consumer_offsets,44] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 15:16:14,526] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,527] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 15:16:14,533] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,31],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,19],[__consumer_offsets,22],[__consumer_offsets,10],[__consumer_offsets,36],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,40],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,3],[__consumer_offsets,18],[__consumer_offsets,42],[__consumer_offsets,4],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,1],[__consumer_offsets,13],[__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:14,548] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,558] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,559] INFO Partition [__consumer_offsets,6] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 15:16:14,573] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,576] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,581] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,584] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,587] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,592] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,593] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,593] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,596] INFO Partition [__consumer_offsets,41] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 15:16:14,598] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,600] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,605] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,618] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,623] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,623] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,625] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,626] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,631] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,632] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,634] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,636] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,637] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,639] INFO Partition [__consumer_offsets,32] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 15:16:14,639] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,642] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,648] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,650] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,653] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,655] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,657] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:16:14,658] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,661] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:16:14,662] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,663] INFO Partition [__consumer_offsets,3] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 15:16:14,665] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,666] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,669] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,2],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,38],[__consumer_offsets,9],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,11],[__consumer_offsets,26],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,36],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,47],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,6],[__consumer_offsets,5],[__consumer_offsets,3],[__consumer_offsets,14],[__consumer_offsets,18],[__consumer_offsets,41],[__consumer_offsets,42],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,32],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,0],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:14,673] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,673] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,677] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,679] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,681] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,682] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,683] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,687] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,687] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,689] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,691] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,698] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,702] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,709] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,711] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,715] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,717] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:14,718] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,718] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 15:16:14,721] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,748] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,748] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,758] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,759] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,769] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,769] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,774] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,775] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,775] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,778] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,786] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,805] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,809] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,819] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,821] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,825] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,831] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,835] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,842] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,843] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,849] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,853] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,855] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,855] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,860] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,862] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,863] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,867] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,868] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,869] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,873] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,877] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,881] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,882] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,883] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,886] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,891] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,904] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,915] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,918] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,919] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,924] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,926] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,926] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,934] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,934] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,945] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,945] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,949] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 15:16:14,951] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,961] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,965] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,966] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:14,969] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,006] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:16:15,008] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 15:16:15,015] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,038] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,22] in 14 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,042] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,044] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,25] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,044] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,047] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,28] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,048] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,052] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,31] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,060] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,063] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,34] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,066] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,076] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,37] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,077] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,079] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,40] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,080] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,083] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,085] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,115] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,46] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,115] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,118] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,49] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,119] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,121] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,122] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,125] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,4] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,125] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,128] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,128] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,132] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,10] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,137] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,140] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,141] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,143] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,16] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,145] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,147] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,19] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:16:15,190] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:16:15,199] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:16:15,221] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:17:11,333] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:17:11,343] INFO [GroupCoordinator 2]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:18:34,267] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:18:34,269] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:18:34,277] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:18:34,399] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:18:34,405] INFO [GroupCoordinator 2]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:24:31,191] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:24:53,209] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:25:11,726] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:27:32,159] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:27:32,160] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:27:32,167] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:27:32,308] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:27:32,312] INFO [GroupCoordinator 2]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:34:31,203] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:34:53,221] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:35:11,732] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:44:31,224] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:44:53,236] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:45:11,752] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:47:12,127] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[2016-09-26 15:47:12,142] INFO [KafkaApi-0] Auto creation of topic test-elasticsearch-sink with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 15:47:12,179] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:47:12,181] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:47:12,194] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:47:12,692] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [test-elasticsearch-sink,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 15:47:12,702] INFO Completed load of log test-elasticsearch-sink-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 15:47:12,712] INFO Created log for partition [test-elasticsearch-sink,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 15:47:12,727] INFO Partition [test-elasticsearch-sink,0] on broker 1: No checkpointed highwatermark is found for partition [test-elasticsearch-sink,0] (kafka.cluster.Partition)
[2016-09-26 15:52:12,160] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:52:12,160] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-sink generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:52:12,160] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-sink for generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:52:42,332] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:52:42,332] INFO [GroupCoordinator 2]: Group connect-elasticsearch-sink generation 2 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 15:54:31,230] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:54:53,253] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 15:55:11,758] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:03:32,744] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:03:32,926] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:03:32,936] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:03:33,780] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:03:33,790] INFO [GroupCoordinator 2]: Group connect-elasticsearch-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:04:31,240] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:04:53,263] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:05:11,773] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:07:24,563] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:07:24,581] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:07:24,606] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:07:24,970] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:07:24,980] INFO [GroupCoordinator 2]: Group connect-elasticsearch-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:13:26,845] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9094
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs2
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 2
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 16:13:26,952] INFO starting (kafka.server.KafkaServer)
[2016-09-26 16:13:26,963] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 16:13:27,379] INFO Log directory 'D:\tmp\kafka-logs2' not found, creating it. (kafka.log.LogManager)
[2016-09-26 16:13:27,394] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 16:13:27,403] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 16:13:27,485] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 16:13:27,489] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 16:13:27,497] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 16:13:27,601] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2016-09-26 16:13:27,613] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 16:13:27,664] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:27,665] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:27,747] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:13:27,770] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:13:27,771] INFO 2 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-26 16:13:27,902] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:27,904] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:27,929] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:13:27,932] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:13:27,945] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 24 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:13:27,981] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 16:13:27,982] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 16:13:27,987] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 16:13:28,040] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:13:28,054] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:13:28,056] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9094,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 16:13:28,059] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-26 16:13:28,059] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 16:13:28,089] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2016-09-26 16:13:48,386] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9093
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs1
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 1
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 16:13:48,500] INFO starting (kafka.server.KafkaServer)
[2016-09-26 16:13:48,512] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 16:13:48,790] INFO Log directory 'D:\tmp\kafka-logs1' not found, creating it. (kafka.log.LogManager)
[2016-09-26 16:13:48,798] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 16:13:48,809] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 16:13:48,875] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 16:13:48,878] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 16:13:48,884] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 16:13:48,959] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2016-09-26 16:13:48,964] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 16:13:49,010] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:49,012] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:49,187] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:49,189] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:13:49,213] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:13:49,213] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:13:49,219] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:13:49,239] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 16:13:49,242] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 16:13:49,249] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 16:13:49,284] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:13:49,297] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:13:49,300] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 16:13:49,301] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 16:13:49,362] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2016-09-26 16:15:14,027] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 16:15:14,110] INFO starting (kafka.server.KafkaServer)
[2016-09-26 16:15:14,119] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 16:15:14,382] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-26 16:15:14,392] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 16:15:14,402] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 16:15:14,496] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 16:15:14,503] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 16:15:14,511] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 16:15:14,588] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-26 16:15:14,592] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 16:15:14,615] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:15:14,617] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:15:14,807] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:15:14,809] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 16:15:14,835] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:15:14,839] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:15:14,842] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:15:14,864] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 16:15:14,867] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 16:15:14,878] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 16:15:14,929] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:15:14,993] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 16:15:14,993] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 16:15:14,993] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 16:15:15,093] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-26 16:15:57,461] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:15:57,482] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:15:57,493] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:15:57,504] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 16:15:57,516] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:15:57,538] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 16:15:57,564] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:15:57,574] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:15:57,581] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:15:57,583] INFO Partition [_schemas,0] on broker 1: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 16:15:57,602] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:15:57,605] INFO Partition [_schemas,0] on broker 2: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 16:15:57,611] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:15:57,661] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[2016-09-26 16:15:57,708] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:15:57,714] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 16:15:57,738] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[_schemas,0], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:15:57,758] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 16:17:14,439] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 16:17:14,445] INFO [KafkaApi-0] Auto creation of topic test-elasticsearch-sink with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 16:17:14,768] INFO Topic creation {"version":1,"partitions":{"45":[1,0,2],"34":[2,1,0],"12":[1,2,0],"8":[0,1,2],"19":[2,0,1],"23":[0,2,1],"4":[2,1,0],"40":[2,1,0],"15":[1,0,2],"11":[0,2,1],"9":[1,0,2],"44":[0,1,2],"33":[1,0,2],"22":[2,1,0],"26":[0,1,2],"37":[2,0,1],"13":[2,0,1],"46":[2,1,0],"24":[1,2,0],"35":[0,2,1],"16":[2,1,0],"5":[0,2,1],"10":[2,1,0],"48":[1,2,0],"21":[1,0,2],"43":[2,0,1],"32":[0,1,2],"49":[2,0,1],"6":[1,2,0],"36":[1,2,0],"1":[2,0,1],"39":[1,0,2],"17":[0,2,1],"25":[2,0,1],"14":[0,1,2],"47":[0,2,1],"31":[2,0,1],"42":[1,2,0],"0":[1,2,0],"20":[0,1,2],"27":[1,0,2],"2":[0,1,2],"38":[0,1,2],"18":[1,2,0],"30":[1,2,0],"7":[2,0,1],"29":[0,2,1],"41":[0,2,1],"3":[1,0,2],"28":[2,1,0]}} (kafka.admin.AdminUtils$)
[2016-09-26 16:17:14,831] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 3 is successful (kafka.server.KafkaApis)
[2016-09-26 16:17:14,847] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [test-elasticsearch-sink,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:14,863] INFO Completed load of log test-elasticsearch-sink-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:14,873] INFO Created log for partition [test-elasticsearch-sink,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:14,875] INFO Partition [test-elasticsearch-sink,0] on broker 0: No checkpointed highwatermark is found for partition [test-elasticsearch-sink,0] (kafka.cluster.Partition)
[2016-09-26 16:17:16,866] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,28],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,13],[__consumer_offsets,40],[__consumer_offsets,37],[__consumer_offsets,34],[__consumer_offsets,22],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:16,994] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,050] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,056] INFO Partition [__consumer_offsets,10] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 16:17:17,087] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,104] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,113] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,0],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,9],[__consumer_offsets,42],[__consumer_offsets,48],[__consumer_offsets,18],[__consumer_offsets,12],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:17,115] INFO Partition [__consumer_offsets,7] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 16:17:17,129] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,135] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,143] INFO Partition [__consumer_offsets,4] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 16:17:17,094] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:17,164] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,170] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,177] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,180] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,182] INFO Partition [__consumer_offsets,0] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 16:17:17,183] INFO Partition [__consumer_offsets,1] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 16:17:17,195] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,198] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,199] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 16:17:17,222] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,225] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,233] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 16:17:17,247] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,249] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,252] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,254] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 16:17:17,262] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,268] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,274] INFO Partition [__consumer_offsets,48] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 16:17:17,275] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,277] INFO Partition [__consumer_offsets,49] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 16:17:17,290] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,294] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,295] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 16:17:17,304] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,307] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,309] INFO Partition [__consumer_offsets,45] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 16:17:17,334] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,339] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,341] INFO Partition [__consumer_offsets,46] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 16:17:17,342] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,350] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,352] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,358] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,363] INFO Partition [__consumer_offsets,42] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 16:17:17,365] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 16:17:17,387] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,402] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,405] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,407] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,409] INFO Partition [__consumer_offsets,39] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 16:17:17,418] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,421] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,423] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 16:17:17,432] INFO Partition [__consumer_offsets,43] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 16:17:17,481] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,483] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,484] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 16:17:17,543] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,554] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,577] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,577] INFO Partition [__consumer_offsets,36] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 16:17:17,589] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,591] INFO Partition [__consumer_offsets,40] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 16:17:17,637] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,644] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,647] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,647] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,648] INFO Partition [__consumer_offsets,33] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 16:17:17,654] INFO Partition [__consumer_offsets,37] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 16:17:17,673] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,677] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,678] INFO Partition [__consumer_offsets,34] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 16:17:17,972] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:17,989] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:17,990] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 16:17:18,011] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,018] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,020] INFO Partition [__consumer_offsets,30] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 16:17:18,051] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,055] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,057] INFO Partition [__consumer_offsets,31] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 16:17:18,073] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,077] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,080] INFO Partition [__consumer_offsets,27] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 16:17:18,088] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,095] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,098] INFO Partition [__consumer_offsets,19] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 16:17:18,105] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,108] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,110] INFO Partition [__consumer_offsets,24] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 16:17:18,142] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,145] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,152] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,158] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,161] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,163] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 16:17:18,169] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,168] INFO Partition [__consumer_offsets,21] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 16:17:18,173] INFO Partition [__consumer_offsets,28] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 16:17:18,200] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,219] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,220] INFO Partition [__consumer_offsets,16] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 16:17:18,241] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,243] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,243] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,244] INFO Partition [__consumer_offsets,25] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 16:17:18,248] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,249] INFO Partition [__consumer_offsets,18] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 16:17:18,261] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,278] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,279] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,282] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,283] INFO Partition [__consumer_offsets,22] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 16:17:18,284] INFO Partition [__consumer_offsets,15] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 16:17:18,322] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,328] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,329] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,331] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,333] INFO Partition [__consumer_offsets,12] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 16:17:18,334] INFO Partition [__consumer_offsets,13] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 16:17:18,446] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,448] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,468] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,469] INFO Partition [__consumer_offsets,9] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 16:17:18,495] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,498] INFO Partition [__consumer_offsets,0] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 16:17:18,525] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,528] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,530] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,533] INFO Partition [__consumer_offsets,6] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 16:17:18,534] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,539] INFO Partition [__consumer_offsets,29] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 16:17:18,556] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,558] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,560] INFO Partition [__consumer_offsets,3] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 16:17:18,568] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,632] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,633] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,635] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,637] INFO Partition [__consumer_offsets,48] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 16:17:18,700] INFO Partition [__consumer_offsets,29] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 16:17:18,749] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,762] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,764] INFO Partition [__consumer_offsets,10] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 16:17:18,770] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,784] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,788] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,792] INFO Partition [__consumer_offsets,45] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 16:17:18,795] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,796] INFO Partition [__consumer_offsets,26] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 16:17:18,805] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,807] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,819] INFO Partition [__consumer_offsets,26] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 16:17:18,818] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,824] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,825] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 16:17:18,837] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,839] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,848] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,852] INFO Partition [__consumer_offsets,42] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 16:17:18,855] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,880] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,881] INFO Partition [__consumer_offsets,7] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 16:17:18,887] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,889] INFO Partition [__consumer_offsets,23] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 16:17:18,894] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,898] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,905] INFO Partition [__consumer_offsets,4] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 16:17:18,911] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,921] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,923] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,934] INFO Partition [__consumer_offsets,23] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 16:17:18,935] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,946] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,948] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,967] INFO Partition [__consumer_offsets,20] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 16:17:18,975] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 16:17:18,984] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,985] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:18,987] INFO Partition [__consumer_offsets,1] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 16:17:18,996] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:18,999] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,000] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 16:17:19,010] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,014] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,017] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,018] INFO Partition [__consumer_offsets,39] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 16:17:19,019] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,021] INFO Partition [__consumer_offsets,20] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 16:17:19,028] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,032] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,033] INFO Partition [__consumer_offsets,17] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 16:17:19,036] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,039] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,040] INFO Partition [__consumer_offsets,17] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 16:17:19,054] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,057] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,059] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,059] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,067] INFO Partition [__consumer_offsets,36] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 16:17:19,070] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,072] INFO Partition [__consumer_offsets,14] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 16:17:19,072] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,074] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 16:17:19,087] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,094] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,095] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,097] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,097] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,098] INFO Partition [__consumer_offsets,14] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 16:17:19,105] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,107] INFO Partition [__consumer_offsets,49] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 16:17:19,109] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 16:17:19,132] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,134] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,135] INFO Partition [__consumer_offsets,11] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 16:17:19,136] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,138] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,139] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,142] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 16:17:19,146] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,151] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,153] INFO Partition [__consumer_offsets,46] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 16:17:19,156] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,165] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,168] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,170] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 16:17:19,177] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,178] INFO Partition [__consumer_offsets,33] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 16:17:19,182] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,184] INFO Partition [__consumer_offsets,8] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 16:17:19,207] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,209] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,210] INFO Partition [__consumer_offsets,43] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 16:17:19,225] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,238] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,241] INFO Partition [__consumer_offsets,11] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 16:17:19,241] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,242] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,244] INFO Partition [__consumer_offsets,5] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 16:17:19,244] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,250] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,259] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,264] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,268] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,270] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,271] INFO Partition [__consumer_offsets,2] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 16:17:19,271] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 16:17:19,271] INFO Partition [__consumer_offsets,30] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 16:17:19,281] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,291] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,291] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,291] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,291] INFO Partition [__consumer_offsets,40] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 16:17:19,291] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 16:17:19,301] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,312] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,314] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,319] INFO Partition [__consumer_offsets,27] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 16:17:19,322] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,324] INFO Partition [__consumer_offsets,37] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 16:17:19,335] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,338] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,339] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 16:17:19,340] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,343] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,346] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,351] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,351] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,353] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,359] INFO Partition [__consumer_offsets,34] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 16:17:19,363] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 16:17:19,363] INFO Partition [__consumer_offsets,8] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 16:17:19,399] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,400] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,401] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,403] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 16:17:19,406] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,408] INFO Partition [__consumer_offsets,31] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 16:17:19,408] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,414] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,417] INFO Partition [__consumer_offsets,24] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 16:17:19,419] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,421] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,421] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 16:17:19,421] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,431] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,431] INFO Partition [__consumer_offsets,47] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 16:17:19,441] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,441] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,441] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 16:17:19,441] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,454] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,458] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,458] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,460] INFO Partition [__consumer_offsets,5] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 16:17:19,469] INFO Partition [__consumer_offsets,19] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 16:17:19,482] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,485] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,487] INFO Partition [__consumer_offsets,21] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 16:17:19,495] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,497] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,498] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 16:17:19,500] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,510] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,518] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,521] INFO Partition [__consumer_offsets,28] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 16:17:19,522] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,524] INFO Partition [__consumer_offsets,2] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 16:17:19,532] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,555] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,556] INFO Partition [__consumer_offsets,38] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 16:17:19,568] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,573] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,575] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,575] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,577] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,578] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,578] INFO Partition [__consumer_offsets,18] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 16:17:19,579] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 16:17:19,579] INFO Partition [__consumer_offsets,35] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 16:17:19,595] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,599] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,602] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,606] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 16:17:19,607] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,610] INFO Partition [__consumer_offsets,15] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 16:17:19,615] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,617] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,619] INFO Partition [__consumer_offsets,44] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 16:17:19,631] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,633] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,635] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 16:17:19,642] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,653] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,655] INFO Partition [__consumer_offsets,12] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 16:17:19,669] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,672] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,674] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,676] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 16:17:19,677] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,680] INFO Partition [__consumer_offsets,25] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 16:17:19,698] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,701] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,702] INFO Partition [__consumer_offsets,9] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 16:17:19,723] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,726] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,727] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,728] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,729] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 16:17:19,735] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,740] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,741] INFO Partition [__consumer_offsets,16] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 16:17:19,744] INFO Partition [__consumer_offsets,47] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 16:17:19,755] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,757] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,767] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,768] INFO Partition [__consumer_offsets,22] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 16:17:19,774] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,777] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 16:17:19,792] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,792] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,793] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,794] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,796] INFO Partition [__consumer_offsets,38] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 16:17:19,797] INFO Partition [__consumer_offsets,41] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 16:17:19,806] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,818] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,828] INFO Partition [__consumer_offsets,35] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 16:17:19,829] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,830] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,832] INFO Partition [__consumer_offsets,32] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 16:17:19,840] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,845] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,856] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,858] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 16:17:19,876] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,877] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,878] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,879] INFO Partition [__consumer_offsets,13] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 16:17:19,880] INFO Partition [__consumer_offsets,44] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 16:17:19,883] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,2],[__consumer_offsets,7],[__consumer_offsets,38],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,11],[__consumer_offsets,22],[__consumer_offsets,26],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,40],[__consumer_offsets,47],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,5],[__consumer_offsets,14],[__consumer_offsets,41],[__consumer_offsets,4],[__consumer_offsets,1],[__consumer_offsets,32],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:19,887] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,889] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,890] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 16:17:19,902] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,904] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,907] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,907] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,908] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,911] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,913] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,914] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 16:17:19,925] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,926] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,926] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,927] INFO Partition [__consumer_offsets,6] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 16:17:19,928] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,936] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,941] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,948] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,949] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,950] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,951] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,953] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,954] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,957] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,958] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,959] INFO Partition [__consumer_offsets,41] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 16:17:19,959] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,962] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,963] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:19,964] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,973] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,974] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:19,975] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,978] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 16:17:19,981] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,981] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,982] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,982] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,984] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,984] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:19,995] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,014] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,014] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,014] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,015] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 16:17:20,021] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,022] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,024] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,027] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,028] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,032] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,035] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,036] INFO Partition [__consumer_offsets,32] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 16:17:20,037] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 16:17:20,040] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,051] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,053] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,056] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,057] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 16:17:20,078] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,080] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:20,087] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,090] INFO Partition [__consumer_offsets,3] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 16:17:20,092] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,2],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,38],[__consumer_offsets,9],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,11],[__consumer_offsets,26],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,36],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,47],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,6],[__consumer_offsets,5],[__consumer_offsets,3],[__consumer_offsets,14],[__consumer_offsets,18],[__consumer_offsets,41],[__consumer_offsets,42],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,32],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,0],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:20,096] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,098] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,103] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 16:17:20,128] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,106] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,135] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,136] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 16:17:20,131] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 16:17:20,152] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,160] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,162] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,163] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 16:17:20,177] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,0] in 38 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,193] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,196] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,201] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,204] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,3] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,208] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,220] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,221] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,222] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,226] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,227] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,6] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,227] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,228] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,229] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,229] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,233] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,238] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,239] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 16:17:20,245] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,246] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,246] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,9] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,248] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,249] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,250] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,254] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,253] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,254] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,255] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,255] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,256] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,259] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,12] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,259] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,261] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,261] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,266] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,268] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,269] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,270] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,270] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,273] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,15] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,275] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,276] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,277] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,279] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,285] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,286] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,287] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,18] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,288] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,291] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,291] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,292] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 16:17:20,297] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,301] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,21] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,303] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,310] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,24] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,324] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,328] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,27] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,329] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,340] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,30] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,341] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,346] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,33] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,346] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,352] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,346] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 16:17:20,357] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,36] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,359] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,362] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:20,365] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,39] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,367] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,371] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,42] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,373] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,377] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,45] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,379] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,380] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,381] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 16:17:20,386] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 16:17:20,394] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,48] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,427] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,429] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,430] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 16:17:20,454] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,486] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,487] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,489] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 16:17:20,498] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,22] in 23 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,499] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,510] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,25] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,502] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,513] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,515] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,516] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,28] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,518] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 16:17:20,520] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,524] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,31] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,526] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,529] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,34] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,530] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,532] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,37] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,534] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,537] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,40] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,540] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,547] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,547] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,548] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,549] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,551] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 16:17:20,557] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,46] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,561] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,562] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,563] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,49] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,564] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,568] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,568] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,569] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,571] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 16:17:20,573] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,4] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,575] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,579] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,580] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,583] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,10] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,583] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,584] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,586] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,588] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,593] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,593] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 16:17:20,597] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,16] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,599] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,602] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 16:17:20,603] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,19] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,607] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 16:17:20,611] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 16:17:20,613] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,31],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,19],[__consumer_offsets,22],[__consumer_offsets,10],[__consumer_offsets,36],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,40],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,3],[__consumer_offsets,18],[__consumer_offsets,42],[__consumer_offsets,4],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,1],[__consumer_offsets,13],[__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:20,618] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,618] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,625] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,626] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,627] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,629] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,630] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,631] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,632] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,633] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,634] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,637] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,638] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,639] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,643] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,644] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,645] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,646] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,648] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,682] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,692] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,710] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,710] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,713] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,713] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,714] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,715] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,717] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,717] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,718] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,719] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,728] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,730] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,730] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-26 16:17:20,753] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-26 16:17:20,756] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-26 16:17:20,777] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,785] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,786] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,823] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,838] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,845] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,846] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,849] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,854] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,873] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,882] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,885] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,885] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,888] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,895] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,911] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:17:20,954] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:20,979] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:17:21,051] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,058] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,064] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,074] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,078] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,081] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,081] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,086] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,087] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,092] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:17:21,094] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,098] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,101] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,102] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,107] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,109] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:17:21,113] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:18:52,347] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:18:52,354] INFO [GroupCoordinator 2]: Group connect-elasticsearch-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:23:27,932] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:23:49,218] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:25:14,850] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:25:52,452] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:25:52,453] INFO [GroupCoordinator 2]: Stabilized group connect-elasticsearch-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:25:52,467] INFO [GroupCoordinator 2]: Assignment received from leader for group connect-elasticsearch-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:26:22,775] INFO [GroupCoordinator 2]: Preparing to restabilize group connect-elasticsearch-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:26:22,782] INFO [GroupCoordinator 2]: Group connect-elasticsearch-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 16:33:27,953] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:33:49,231] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:35:14,857] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:43:27,957] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:43:49,244] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:45:14,866] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:53:27,968] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:53:49,258] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 16:55:14,879] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:14:38,526] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 17:14:39,514] INFO starting (kafka.server.KafkaServer)
[2016-09-26 17:14:39,524] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 17:14:40,634] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-26 17:14:40,696] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 17:14:40,776] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 17:14:40,946] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 17:14:40,986] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 17:14:41,026] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 17:14:41,566] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-26 17:14:41,586] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 17:14:41,948] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 17:14:41,948] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 17:14:42,428] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 17:14:42,448] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 17:14:42,498] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-26 17:14:42,948] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 17:14:42,948] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 17:14:43,238] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:14:43,238] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:14:43,628] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 17:14:43,638] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 17:14:43,658] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 17:14:43,668] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 490 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:14:43,958] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 17:14:44,018] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 17:14:44,088] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 17:14:44,098] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 17:14:44,278] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-26 17:14:44,368] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-26 17:24:43,181] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:24:43,815] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 17:24:44,005] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:24:44,005] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:24:44,015] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 17:26:05,876] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 17:26:05,936] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 17:26:05,946] INFO Completed load of log Text-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:26:05,946] INFO Created log for partition [Text,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:26:05,946] INFO Partition [Text,0] on broker 0: No checkpointed highwatermark is found for partition [Text,0] (kafka.cluster.Partition)
[2016-09-26 17:29:28,346] INFO Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 17:29:28,505] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 17:29:29,619] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-26 17:29:29,630] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,640] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,640] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 17:29:29,650] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,650] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,650] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 17:29:29,660] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,660] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,660] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 17:29:29,680] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,680] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,680] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 17:29:29,760] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,764] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,766] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 17:29:29,834] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,840] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,846] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 17:29:29,855] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,861] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,862] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 17:29:29,872] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,872] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,892] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 17:29:29,919] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,920] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,924] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 17:29:29,934] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,944] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,944] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 17:29:29,954] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,954] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,954] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 17:29:29,984] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,984] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:29,984] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 17:29:29,994] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:29,994] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,004] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 17:29:30,014] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,014] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,014] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 17:29:30,024] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,024] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,024] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 17:29:30,034] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,034] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,044] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 17:29:30,054] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,054] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,054] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 17:29:30,064] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,064] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,074] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 17:29:30,084] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,094] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,094] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 17:29:30,104] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,104] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,114] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 17:29:30,154] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,165] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,168] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 17:29:30,194] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,200] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,201] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 17:29:30,206] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,206] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,206] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 17:29:30,216] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,226] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,226] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 17:29:30,236] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,246] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,246] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 17:29:30,256] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,256] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,256] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 17:29:30,266] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,276] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,276] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 17:29:30,286] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,286] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,286] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 17:29:30,296] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,296] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,296] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 17:29:30,306] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,316] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,316] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 17:29:30,336] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,346] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,357] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 17:29:30,371] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,376] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,381] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 17:29:30,393] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,395] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,396] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 17:29:30,407] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,409] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,410] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 17:29:30,422] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,423] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,425] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 17:29:30,428] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,428] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,438] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 17:29:30,448] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,458] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,458] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 17:29:30,468] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,468] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,468] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 17:29:30,478] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,478] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,488] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 17:29:30,498] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,498] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,508] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 17:29:30,521] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,522] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,524] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 17:29:30,556] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,563] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,567] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 17:29:30,583] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,585] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,587] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 17:29:30,600] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,600] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,600] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 17:29:30,620] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,620] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,620] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 17:29:30,640] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,640] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,640] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 17:29:30,660] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,660] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,660] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 17:29:30,680] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,680] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,680] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 17:29:30,690] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,700] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,700] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 17:29:30,710] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 17:29:30,720] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 17:29:30,720] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 17:29:30,754] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,766] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,767] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,771] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,773] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,776] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,782] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,782] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,782] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,792] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,792] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,802] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,802] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,802] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,812] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,812] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,822] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,832] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,832] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,844] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,851] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,865] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,868] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,872] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,874] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,884] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,889] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,892] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,898] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,902] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,904] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,907] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,909] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,914] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,914] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,914] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,914] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,924] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,924] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,924] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,924] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,934] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,934] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,944] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,944] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,954] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,954] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,954] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,964] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,964] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,964] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,974] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,974] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,974] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,974] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,974] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,984] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:30,994] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:29:31,005] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,021] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:29:31,036] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:29:31,066] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,069] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,069] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,071] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,072] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,098] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 26 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,105] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,109] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,109] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,112] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,112] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,114] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,115] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,118] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,118] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,121] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,122] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,138] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 15 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,141] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,142] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,144] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,145] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,146] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,146] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,156] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,166] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,166] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,166] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,166] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,186] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,186] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,186] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,186] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,196] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,196] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,196] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,206] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,206] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,206] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,206] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,206] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:29:31,206] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:30:06,275] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:30:06,275] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:31:25,001] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,031] INFO Property auto.offset.reset is overridden to smallest (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,031] INFO Property group.id is overridden to console-consumer-413 (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,031] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,091] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Connecting to zookeeper instance at localhost:2181 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,111] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], starting auto committer every 60000 ms (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,141] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], begin registering consumer console-consumer-413_MSSPAD370-1474891285091-45109976 in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,181] INFO Creating /consumers/console-consumer-413/ids/console-consumer-413_MSSPAD370-1474891285091-45109976 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 17:31:25,191] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 17:31:25,191] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], end registering consumer console-consumer-413_MSSPAD370-1474891285091-45109976 in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,191] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], starting watcher executor thread for consumer console-consumer-413_MSSPAD370-1474891285091-45109976 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,221] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], begin rebalancing consumer console-consumer-413_MSSPAD370-1474891285091-45109976 try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,381] INFO [ConsumerFetcherManager-1474891285101] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 17:31:25,381] INFO [ConsumerFetcherManager-1474891285101] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 17:31:25,381] INFO [ConsumerFetcherManager-1474891285101] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 17:31:25,381] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Cleared all relevant queues for this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,381] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Cleared the data chunks in all the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,381] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Committing all offsets after clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,391] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Releasing partition ownership (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,421] INFO Consumer console-consumer-413_MSSPAD370-1474891285091-45109976 rebalancing the following partitions: ArrayBuffer(0) for topic Text with consumers: List(console-consumer-413_MSSPAD370-1474891285091-45109976-0) (kafka.consumer.RangeAssignor)
[2016-09-26 17:31:25,431] INFO console-consumer-413_MSSPAD370-1474891285091-45109976-0 attempting to claim partition 0 (kafka.consumer.RangeAssignor)
[2016-09-26 17:31:25,491] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], console-consumer-413_MSSPAD370-1474891285091-45109976-0 successfully owned partition 0 for topic Text (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,511] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Consumer console-consumer-413_MSSPAD370-1474891285091-45109976 selected partitions : Text:0: fetched offset = -1: consumed offset = -1 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,521] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976-leader-finder-thread], Starting  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-26 17:31:25,521] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], end rebalancing consumer console-consumer-413_MSSPAD370-1474891285091-45109976 try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,521] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Creating topic event watcher for topics Text (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,561] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,561] INFO Property client.id is overridden to console-consumer-413 (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,561] INFO Property metadata.broker.list is overridden to localhost:9092 (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,571] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-26 17:31:25,576] INFO [console-consumer-413_MSSPAD370-1474891285091-45109976], Topics to consume = List(Text) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-26 17:31:25,593] INFO Fetching metadata from broker BrokerEndPoint(0,localhost,9092) with correlation id 0 for 1 topic(s) Set(Text) (kafka.client.ClientUtils$)
[2016-09-26 17:31:25,613] INFO Connected to localhost:9092 for producing (kafka.producer.SyncProducer)
[2016-09-26 17:31:25,643] INFO Disconnecting from localhost:9092 (kafka.producer.SyncProducer)
[2016-09-26 17:31:25,673] INFO [ConsumerFetcherThread-console-consumer-413_MSSPAD370-1474891285091-45109976-0-0], Starting  (kafka.consumer.ConsumerFetcherThread)
[2016-09-26 17:31:25,723] INFO [ConsumerFetcherManager-1474891285101] Added fetcher for partitions ArrayBuffer([[Text,0], initOffset -1 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.consumer.ConsumerFetcherManager)
[2016-09-26 17:34:43,191] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:37:30,266] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:37:30,267] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:37:30,273] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:37:30,420] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:37:30,420] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:44:43,208] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:50:36,953] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:50:36,954] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:50:36,966] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:54:43,220] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 17:56:40,002] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:56:40,002] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:58:01,494] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:58:01,494] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 17:58:01,504] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:03:58,157] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:03:58,169] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:04:43,143] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:04:43,144] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:04:43,150] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:04:43,226] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:07:35,977] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:07:35,978] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:07:50,786] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:07:50,795] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:07:50,809] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:11:40,731] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:11:40,732] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:12:04,625] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:12:04,625] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:12:04,643] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:14:07,467] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 18:14:07,591] INFO starting (kafka.server.KafkaServer)
[2016-09-26 18:14:07,599] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 18:14:07,910] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-26 18:14:07,923] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 18:14:07,930] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 18:14:07,990] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 18:14:07,993] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 18:14:08,002] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 18:14:08,082] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-26 18:14:08,090] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 18:14:08,151] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:14:08,153] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:14:08,216] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:14:08,227] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:14:08,228] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-26 18:14:08,311] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:14:08,317] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:14:08,324] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:14:08,326] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:14:08,351] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:14:08,367] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:14:08,369] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:14:08,377] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 18:14:08,411] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:14:08,418] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:14:08,420] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 18:14:08,422] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 18:14:08,434] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-26 18:14:08,462] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-26 18:14:25,406] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 18:14:25,511] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:14:25,558] INFO Completed load of log Text-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:14:25,563] INFO Created log for partition [Text,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:14:25,565] INFO Partition [Text,0] on broker 0: No checkpointed highwatermark is found for partition [Text,0] (kafka.cluster.Partition)
[2016-09-26 18:14:42,591] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:14:42,613] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:14:42,616] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:14:42,619] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 18:17:07,222] INFO Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 18:17:07,229] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 18:17:08,474] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:17:08,484] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,486] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,487] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 18:17:08,495] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,497] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,498] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 18:17:08,506] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,509] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,511] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 18:17:08,542] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,544] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,545] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 18:17:08,553] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,555] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,556] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 18:17:08,564] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,566] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,566] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 18:17:08,574] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,576] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,577] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 18:17:08,586] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,588] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,589] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 18:17:08,602] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,604] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,610] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 18:17:08,624] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,633] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,650] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 18:17:08,660] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,663] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,668] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 18:17:08,688] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,698] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,699] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 18:17:08,709] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,712] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,713] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 18:17:08,733] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,744] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,745] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 18:17:08,760] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,772] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,785] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 18:17:08,812] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,814] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,815] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 18:17:08,826] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,828] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,831] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 18:17:08,867] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,869] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,870] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 18:17:08,879] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,881] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,882] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 18:17:08,893] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,895] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,900] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 18:17:08,909] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,911] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,913] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 18:17:08,925] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,929] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,930] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 18:17:08,968] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,970] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,971] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 18:17:08,979] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,982] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,983] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 18:17:08,991] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:08,994] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:08,995] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 18:17:09,009] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,012] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,013] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 18:17:09,025] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,027] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,028] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 18:17:09,039] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,041] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,043] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 18:17:09,055] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,057] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,063] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 18:17:09,078] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,080] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,081] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 18:17:09,152] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,154] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,155] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 18:17:09,191] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,198] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,199] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 18:17:09,209] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,213] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,215] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 18:17:09,231] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,236] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,238] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 18:17:09,253] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,255] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,260] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 18:17:09,274] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,275] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,281] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 18:17:09,297] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,299] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,301] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 18:17:09,319] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,321] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,322] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 18:17:09,337] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,338] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,340] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 18:17:09,352] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,353] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,354] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 18:17:09,377] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,379] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,382] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 18:17:09,397] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,399] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,400] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 18:17:09,409] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,413] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,414] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 18:17:09,423] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,424] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,428] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 18:17:09,437] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,439] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,440] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 18:17:09,450] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,452] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,453] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 18:17:09,468] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,470] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,471] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 18:17:09,489] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,493] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,494] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 18:17:09,505] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,506] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,507] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 18:17:09,523] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:17:09,526] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:17:09,531] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 18:17:09,563] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,576] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,576] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,579] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,579] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,617] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 37 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,617] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,620] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,620] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,624] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,625] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,628] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,628] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,633] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,641] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,650] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,650] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,655] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,656] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,658] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,659] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,663] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,663] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,667] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,672] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,675] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,675] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,680] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,681] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,690] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,690] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,694] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,697] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,701] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,705] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,708] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,714] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,717] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,718] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,722] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,722] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,730] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,731] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,740] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,741] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,744] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,747] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,750] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,751] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,757] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,758] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,761] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,765] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,773] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,775] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,780] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:17:09,783] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,789] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,792] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:17:09,792] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,794] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,797] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,799] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,808] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,808] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,812] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,814] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:17:09,815] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,819] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,832] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,835] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,836] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,839] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,839] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,842] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,843] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,846] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,851] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,860] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,902] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,903] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,903] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,904] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,905] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,905] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,906] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,907] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,908] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,909] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,909] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,910] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,911] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,912] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,912] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,913] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,914] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,915] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,916] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,917] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,917] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,919] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,919] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:17:09,920] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:24:08,333] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:32:01,628] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:32:01,632] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:33:54,001] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:33:54,002] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:33:54,008] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:34:08,345] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:34:43,595] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:34:43,596] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:37:01,971] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:37:01,972] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:37:01,980] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:37:10,704] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:37:10,706] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:40:23,168] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:40:23,169] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:40:23,175] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:41:40,903] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:41:40,905] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:41:56,954] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-26 18:41:56,979] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-26 18:41:57,022] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2016-09-26 18:41:57,025] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2016-09-26 18:41:57,035] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2016-09-26 18:41:57,036] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2016-09-26 18:41:57,039] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2016-09-26 18:41:57,044] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:41:57,443] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:41:57,443] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:41:57,445] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:41:58,409] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:41:58,409] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:41:58,412] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2016-09-26 18:41:58,417] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2016-09-26 18:41:58,418] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:41:58,422] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:41:58,422] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:41:58,477] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:41:58,477] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:41:58,479] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:41:58,588] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:41:58,588] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:41:58,594] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2016-09-26 18:41:58,596] INFO Shutting down. (kafka.log.LogManager)
[2016-09-26 18:45:22,476] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-26 18:45:22,596] INFO starting (kafka.server.KafkaServer)
[2016-09-26 18:45:22,606] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-26 18:45:22,857] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-26 18:45:22,867] INFO Loading logs. (kafka.log.LogManager)
[2016-09-26 18:45:22,877] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-26 18:45:22,939] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-26 18:45:22,939] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-26 18:45:22,949] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 18:45:23,010] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-26 18:45:23,020] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-26 18:45:23,040] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:45:23,040] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:45:23,100] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:45:23,110] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:45:23,110] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-26 18:45:23,190] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:45:23,190] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-26 18:45:23,210] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:45:23,210] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:45:23,210] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:23,230] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:45:23,240] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-26 18:45:23,240] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-26 18:45:23,270] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:45:23,280] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-26 18:45:23,280] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-26 18:45:23,280] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-26 18:45:23,297] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-26 18:45:23,317] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-26 18:45:31,963] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 18:45:32,043] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:45:32,092] INFO Completed load of log Text-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:32,092] INFO Created log for partition [Text,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:32,092] INFO Partition [Text,0] on broker 0: No checkpointed highwatermark is found for partition [Text,0] (kafka.cluster.Partition)
[2016-09-26 18:45:44,076] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:45:44,096] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:44,096] INFO Created log for partition [_schemas,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:44,096] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[2016-09-26 18:45:55,830] INFO Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}} (kafka.admin.AdminUtils$)
[2016-09-26 18:45:55,840] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-26 18:45:57,281] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-26 18:45:57,293] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,299] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,300] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-26 18:45:57,309] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,309] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,309] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-26 18:45:57,319] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,319] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,319] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-26 18:45:57,339] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,339] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,339] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-26 18:45:57,349] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,362] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,373] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-26 18:45:57,399] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,401] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,406] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-26 18:45:57,412] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,422] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,422] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-26 18:45:57,452] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,452] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,452] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-26 18:45:57,472] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,472] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,472] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-26 18:45:57,492] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,492] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,492] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-26 18:45:57,502] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,512] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,512] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-26 18:45:57,522] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,532] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,532] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-26 18:45:57,542] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,562] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,562] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-26 18:45:57,572] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,572] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,572] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-26 18:45:57,582] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,592] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,592] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-26 18:45:57,622] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,622] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,622] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-26 18:45:57,644] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,652] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,666] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-26 18:45:57,687] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,690] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,692] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-26 18:45:57,721] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,723] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,724] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-26 18:45:57,732] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,732] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,732] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-26 18:45:57,742] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,752] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,752] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-26 18:45:57,772] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,772] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,772] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-26 18:45:57,782] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,782] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,782] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-26 18:45:57,792] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,792] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,802] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-26 18:45:57,812] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,812] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,812] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-26 18:45:57,822] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,822] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,832] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-26 18:45:57,832] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,842] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,842] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-26 18:45:57,852] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,852] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,852] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-26 18:45:57,862] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,872] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,872] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-26 18:45:57,872] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,882] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,892] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-26 18:45:57,902] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,902] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,902] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-26 18:45:57,922] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,922] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,922] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-26 18:45:57,932] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,932] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,942] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-26 18:45:57,952] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,952] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,952] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-26 18:45:57,972] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,972] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,972] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-26 18:45:57,982] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:57,982] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:57,982] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-26 18:45:58,005] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,007] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,007] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-26 18:45:58,027] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,027] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,027] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-26 18:45:58,047] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,047] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,047] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-26 18:45:58,070] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,072] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,074] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-26 18:45:58,099] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,101] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,102] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-26 18:45:58,113] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,115] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,119] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-26 18:45:58,129] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,129] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,129] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-26 18:45:58,149] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,149] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,149] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-26 18:45:58,169] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,169] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,169] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-26 18:45:58,201] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,203] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,206] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-26 18:45:58,211] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,211] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,211] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-26 18:45:58,231] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,231] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,231] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-26 18:45:58,241] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,251] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,251] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-26 18:45:58,281] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-26 18:45:58,291] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-26 18:45:58,291] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-26 18:45:58,301] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,311] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,311] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,324] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 13 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,333] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,338] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,342] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,343] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,343] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,343] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,343] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,343] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,343] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,353] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,353] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,353] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,353] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,363] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,363] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,363] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,363] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,373] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,373] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,383] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,383] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,383] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,393] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,403] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,403] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,403] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,403] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,413] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,413] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,413] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,413] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,430] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,430] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,433] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,433] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,437] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,437] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,445] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,445] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,445] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,445] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,455] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,455] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,465] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,465] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,465] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,475] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,475] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,475] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,475] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,485] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,485] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,485] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,495] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,495] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,515] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,525] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,525] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,525] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,535] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,535] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,535] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,535] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,550] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:45:58,554] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,557] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,559] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,562] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,566] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:45:58,570] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,572] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,579] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,582] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,594] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,595] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:45:58,596] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,597] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,602] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,604] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,605] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,606] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,610] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,613] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,616] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,630] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,657] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,674] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,675] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,676] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,676] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,677] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,678] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,679] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,680] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,686] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,687] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,712] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,712] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:45:58,713] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-26 18:49:14,172] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:49:14,176] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:50:10,574] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:50:10,574] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:50:10,584] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:52:14,553] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:52:14,553] INFO [GroupCoordinator 0]: Group connect-elasticsearch-schema-sink generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:52:26,032] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-elasticsearch-schema-sink with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:52:26,032] INFO [GroupCoordinator 0]: Stabilized group connect-elasticsearch-schema-sink generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:52:26,042] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-elasticsearch-schema-sink for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-26 18:55:23,221] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
