[2016-09-19 16:21:16,443] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-19 16:21:16,576] INFO starting (kafka.server.KafkaServer)
[2016-09-19 16:21:16,586] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-19 16:21:16,867] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-19 16:21:16,903] INFO Loading logs. (kafka.log.LogManager)
[2016-09-19 16:21:16,910] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-19 16:21:17,000] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-19 16:21:17,007] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-19 16:21:17,017] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-19 16:21:17,103] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-19 16:21:17,108] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-19 16:21:17,154] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-19 16:21:17,157] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-19 16:21:17,221] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 16:21:17,229] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 16:21:17,230] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-19 16:21:17,303] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-19 16:21:17,305] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-19 16:21:17,318] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-19 16:21:17,320] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-19 16:21:17,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 13 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 16:21:17,344] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-19 16:21:17,347] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-19 16:21:17,357] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-19 16:21:17,386] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 16:21:17,392] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 16:21:17,394] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-19 16:21:17,396] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-19 16:21:17,417] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-19 16:21:17,447] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-19 16:31:17,329] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 16:33:30,571] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-19 16:33:30,581] INFO [KafkaApi-0] Auto creation of topic test with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-19 16:33:30,995] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [test,0] (kafka.server.ReplicaFetcherManager)
[2016-09-19 16:33:31,050] INFO Completed load of log test-0 with log end offset 0 (kafka.log.Log)
[2016-09-19 16:33:31,057] INFO Created log for partition [test,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-19 16:33:31,062] INFO Partition [test,0] on broker 0: No checkpointed highwatermark is found for partition [test,0] (kafka.cluster.Partition)
[2016-09-19 16:35:35,097] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,121] INFO Property auto.offset.reset is overridden to smallest (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,123] INFO Property group.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,124] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,204] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Connecting to zookeeper instance at localhost:2181 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,224] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], starting auto committer every 60000 ms (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,258] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin registering consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,296] INFO Creating /consumers/console-consumer-24287/ids/console-consumer-24287_MSSPAD370-1474283135203-fe030f6c (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 16:35:35,309] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 16:35:35,309] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end registering consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,320] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], starting watcher executor thread for consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,353] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,514] INFO [ConsumerFetcherManager-1474283135221] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 16:35:35,514] INFO [ConsumerFetcherManager-1474283135221] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 16:35:35,516] INFO [ConsumerFetcherManager-1474283135221] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 16:35:35,518] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared all relevant queues for this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,520] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared the data chunks in all the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,521] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Committing all offsets after clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,523] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Releasing partition ownership (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,571] INFO Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c rebalancing the following partitions: ArrayBuffer(0) for topic test with consumers: List(console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0) (kafka.consumer.RangeAssignor)
[2016-09-19 16:35:35,574] INFO console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 attempting to claim partition 0 (kafka.consumer.RangeAssignor)
[2016-09-19 16:35:35,621] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 successfully owned partition 0 for topic test (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,662] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c selected partitions : test:0: fetched offset = -1: consumed offset = -1 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,664] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Starting  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-19 16:35:35,666] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,671] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Creating topic event watcher for topics test (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,700] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topics to consume = List(test) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:35:35,701] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,704] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,705] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,706] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 16:35:35,759] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 0 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 16:35:35,771] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 16:35:35,825] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 16:35:35,859] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Starting  (kafka.consumer.ConsumerFetcherThread)
[2016-09-19 16:35:35,925] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer([[test,0], initOffset -1 to broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] ) (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 16:41:17,347] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 16:47:10,084] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-19 16:47:10,097] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topics to consume = List(test) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:47:10,464] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [TextLinesTopic,0] (kafka.server.ReplicaFetcherManager)
[2016-09-19 16:47:10,472] INFO Completed load of log TextLinesTopic-0 with log end offset 0 (kafka.log.Log)
[2016-09-19 16:47:10,474] INFO Created log for partition [TextLinesTopic,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-19 16:47:10,475] INFO Partition [TextLinesTopic,0] on broker 0: No checkpointed highwatermark is found for partition [TextLinesTopic,0] (kafka.cluster.Partition)
[2016-09-19 16:47:32,275] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-19 16:47:32,295] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topics to consume = List(test) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:47:32,326] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [RekeyedIntermediateTopic,0] (kafka.server.ReplicaFetcherManager)
[2016-09-19 16:47:32,333] INFO Completed load of log RekeyedIntermediateTopic-0 with log end offset 0 (kafka.log.Log)
[2016-09-19 16:47:32,335] INFO Created log for partition [RekeyedIntermediateTopic,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-19 16:47:32,337] INFO Partition [RekeyedIntermediateTopic,0] on broker 0: No checkpointed highwatermark is found for partition [RekeyedIntermediateTopic,0] (kafka.cluster.Partition)
[2016-09-19 16:47:59,975] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-19 16:47:59,986] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topics to consume = List(test) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 16:48:00,010] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [WordsWithCountsTopic,0] (kafka.server.ReplicaFetcherManager)
[2016-09-19 16:48:00,037] INFO Completed load of log WordsWithCountsTopic-0 with log end offset 0 (kafka.log.Log)
[2016-09-19 16:48:00,038] INFO Created log for partition [WordsWithCountsTopic,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-19 16:48:00,039] INFO Partition [WordsWithCountsTopic,0] on broker 0: No checkpointed highwatermark is found for partition [WordsWithCountsTopic,0] (kafka.cluster.Partition)
[2016-09-19 16:51:17,367] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 17:01:17,389] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 17:11:17,400] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:14,530] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:14,650] WARN Attempting to send response via channel for which there is no open connection, connection id 2 (kafka.network.Processor)
[2016-09-19 23:21:15,156] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,252] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,253] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,261] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,360] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,361] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,363] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,364] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,365] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,368] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,369] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,370] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,372] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,375] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,376] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,377] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,379] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,380] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,381] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,382] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,384] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,385] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,386] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,388] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,389] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,390] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,391] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,393] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,394] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,395] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,396] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,398] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,399] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,400] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:15,401] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:19,072] INFO Reconnect due to error: (kafka.consumer.SimpleConsumer)
java.net.SocketTimeoutException
	at sun.nio.ch.SocketAdaptor$SocketInputStream.read(SocketAdaptor.java:211)
	at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:81)
	at kafka.network.BlockingChannel.readCompletely(BlockingChannel.scala:129)
	at kafka.network.BlockingChannel.receive(BlockingChannel.scala:120)
	at kafka.consumer.SimpleConsumer.liftedTree1$1(SimpleConsumer.scala:86)
	at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:83)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SimpleConsumer.scala:132)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:132)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:132)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply$mcV$sp(SimpleConsumer.scala:131)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:131)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:131)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:130)
	at kafka.consumer.ConsumerFetcherThread.fetch(ConsumerFetcherThread.scala:108)
	at kafka.consumer.ConsumerFetcherThread.fetch(ConsumerFetcherThread.scala:29)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:19,092] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], ZK expired; release old broker parition ownership; re-register consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:19,112] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin registering consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:19,112] INFO Creating /consumers/console-consumer-24287/ids/console-consumer-24287_MSSPAD370-1474283135203-fe030f6c (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 23:21:19,122] WARN [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Error in fetch kafka.consumer.ConsumerFetcherThread$FetchRequest@5a9e18a6 (kafka.consumer.ConsumerFetcherThread)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.consumer.SimpleConsumer.liftedTree1$1(SimpleConsumer.scala:98)
	at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:83)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SimpleConsumer.scala:132)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:132)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:132)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply$mcV$sp(SimpleConsumer.scala:131)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:131)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:131)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:130)
	at kafka.consumer.ConsumerFetcherThread.fetch(ConsumerFetcherThread.scala:108)
	at kafka.consumer.ConsumerFetcherThread.fetch(ConsumerFetcherThread.scala:29)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:19,902] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 23:21:19,902] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 23:21:19,902] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end registering consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:19,902] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:19,902] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:19,902] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:19,912] INFO Property metadata.broker.list is overridden to  (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:19,912] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:19,912] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer()] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:19,912] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:19,912] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutting down (kafka.consumer.ConsumerFetcherThread)
[2016-09-19 23:21:19,912] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Stopped  (kafka.consumer.ConsumerFetcherThread)
[2016-09-19 23:21:19,912] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutdown completed (kafka.consumer.ConsumerFetcherThread)
[2016-09-19 23:21:20,242] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], no brokers found when trying to rebalance. (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,242] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,242] INFO ZK expired: resubscribing topic event listener to topic registry (kafka.consumer.ZookeeperTopicEventWatcher)
[2016-09-19 23:21:20,242] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 23:21:20,242] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-19 23:21:20,272] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,272] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,272] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,272] INFO Property metadata.broker.list is overridden to  (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,272] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,272] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer()] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:20,282] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:20,292] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topics to consume = List(test) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,302] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topic info for path /brokers/topics/test changed to {"version":1,"partitions":{"0":[0]}}, triggering rebalance (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,302] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], no brokers found when trying to rebalance. (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,302] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,312] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,322] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], no brokers found when trying to rebalance. (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,322] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,424] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-19 23:21:20,424] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 23:21:20,544] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-19 23:21:20,544] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-19 23:21:20,554] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-19 23:21:20,554] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:20,554] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,564] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,574] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,584] INFO [ConsumerFetcherManager-1474283135221] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:20,594] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutting down (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-19 23:21:20,594] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:20,594] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 3 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:20,594] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:20,594] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:21,719] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-19 23:21:21,779] WARN Fetching topic metadata with correlation id 3 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:21,779] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:21,779] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Stopped  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-19 23:21:21,779] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutdown completed (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-19 23:21:21,779] INFO [ConsumerFetcherManager-1474283135221] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:21,779] INFO [ConsumerFetcherManager-1474283135221] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:21,779] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared all relevant queues for this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:21,789] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared the data chunks in all the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:21,789] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Committing all offsets after clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:21,789] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Releasing partition ownership (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:21,819] INFO Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c rebalancing the following partitions: ArrayBuffer(0) for topic test with consumers: List(console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0) (kafka.consumer.RangeAssignor)
[2016-09-19 23:21:21,819] INFO console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 attempting to claim partition 0 (kafka.consumer.RangeAssignor)
[2016-09-19 23:21:22,399] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 successfully owned partition 0 for topic test (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:22,559] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c selected partitions : test:0: fetched offset = 9: consumed offset = 9 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:22,579] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-19 23:21:22,579] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Starting  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-19 23:21:22,589] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,589] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,589] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,589] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,589] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 4 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:22,599] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:22,599] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:22,599] WARN Fetching topic metadata with correlation id 4 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:22,599] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:22,599] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:22,599] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:22,815] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,820] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,822] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,824] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:22,831] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 5 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:22,842] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:22,842] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:22,844] WARN Fetching topic metadata with correlation id 5 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:22,845] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:22,847] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:22,853] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:23,061] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,062] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,063] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,063] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,064] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 6 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:23,075] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,075] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,076] WARN Fetching topic metadata with correlation id 6 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:23,077] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,078] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:23,079] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:23,103] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-19 23:21:23,286] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,286] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,287] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,289] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,289] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 7 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:23,290] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,291] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,292] WARN Fetching topic metadata with correlation id 7 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:23,292] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,293] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:23,294] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:23,500] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,507] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,508] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,509] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,510] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 8 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:23,510] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,511] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,512] WARN Fetching topic metadata with correlation id 8 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:23,513] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,513] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:23,515] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:23,721] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,731] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,731] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,732] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,733] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 9 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:23,734] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,735] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,736] WARN Fetching topic metadata with correlation id 9 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:23,737] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,738] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:23,740] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:23,946] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,947] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,948] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,948] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:23,948] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 10 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:23,959] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,959] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,960] WARN Fetching topic metadata with correlation id 10 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:23,961] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:23,962] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:23,963] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:24,174] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,176] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,177] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,178] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,179] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 11 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:24,181] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,181] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,184] WARN Fetching topic metadata with correlation id 11 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:24,184] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,186] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:24,187] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:24,394] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,395] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,396] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,397] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,398] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 12 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:24,399] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,400] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,401] WARN Fetching topic metadata with correlation id 12 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:24,402] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,403] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:24,404] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:24,611] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,611] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,612] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,612] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,613] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 13 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:24,614] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,615] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,615] WARN Fetching topic metadata with correlation id 13 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:24,617] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,618] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:24,619] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:24,824] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,824] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,825] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,826] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:24,827] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 14 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:24,828] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,828] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,829] WARN Fetching topic metadata with correlation id 14 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:24,829] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:24,830] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:24,832] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:25,039] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,041] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,041] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,043] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,044] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 15 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:25,055] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,055] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,056] WARN Fetching topic metadata with correlation id 15 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:25,057] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,058] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:25,059] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:25,265] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,319] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,323] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,325] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,328] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 16 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:25,331] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,335] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,341] WARN Fetching topic metadata with correlation id 16 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:25,346] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,347] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:25,348] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:25,466] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-19 23:21:25,555] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,555] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,556] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,557] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,558] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 17 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:25,559] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,560] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,560] WARN Fetching topic metadata with correlation id 17 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:25,561] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,562] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:25,563] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:25,769] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,769] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,770] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,771] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,772] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 18 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:25,783] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,783] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,784] WARN Fetching topic metadata with correlation id 18 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:25,785] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:25,786] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:25,787] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:25,998] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:25,999] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,000] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,000] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,000] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 19 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:26,002] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,003] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,005] WARN Fetching topic metadata with correlation id 19 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:26,008] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,010] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:26,014] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:26,224] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,226] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,227] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,229] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,231] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 20 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:26,234] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,235] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,237] WARN Fetching topic metadata with correlation id 20 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:26,241] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,242] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:26,244] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:26,450] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,457] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,458] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,459] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,460] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 21 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:26,474] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,476] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,477] WARN Fetching topic metadata with correlation id 21 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:26,479] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,481] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:26,483] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:26,692] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,693] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,693] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,696] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,698] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 22 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:26,709] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,709] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,710] WARN Fetching topic metadata with correlation id 22 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:26,711] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,712] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:26,713] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:26,930] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,931] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,932] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,934] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:26,940] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 23 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:26,951] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,951] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,954] WARN Fetching topic metadata with correlation id 23 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:26,955] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:26,956] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:26,957] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:27,285] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:27,292] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:27,293] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:27,295] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:27,298] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 24 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:48,287] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:48,287] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:48,288] WARN Fetching topic metadata with correlation id 24 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-19 23:21:48,289] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:48,290] WARN [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Failed to find leader for Set([test,0]) (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092))] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:73)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	... 3 more
[2016-09-19 23:21:48,291] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer() (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:48,509] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:48,510] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:48,512] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:48,512] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-19 23:21:48,513] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 25 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-19 23:21:48,515] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-19 23:21:48,518] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-19 23:21:48,523] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer([[test,0], initOffset 9 to broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] ) (kafka.consumer.ConsumerFetcherManager)
[2016-09-19 23:21:48,526] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Starting  (kafka.consumer.ConsumerFetcherThread)
[2016-09-19 23:21:48,722] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [TextLinesTopic,0],[test,0],[RekeyedIntermediateTopic,0],[WordsWithCountsTopic,0] (kafka.server.ReplicaFetcherManager)
[2016-09-20 10:12:00,731] WARN Attempting to send response via channel for which there is no open connection, connection id 0 (kafka.network.Processor)
[2016-09-20 10:12:00,747] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,077] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,079] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,079] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,079] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,080] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,080] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,080] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,080] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,081] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,082] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,091] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,092] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,093] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,094] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,094] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,095] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,096] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,097] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,097] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,098] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,099] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,100] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,100] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,101] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,102] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,104] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,104] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,105] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,108] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,110] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,110] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,110] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,119] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,119] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,119] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,119] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,119] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,119] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,119] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:01,121] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:12:02,694] INFO Reconnect due to error: (kafka.consumer.SimpleConsumer)
java.net.SocketTimeoutException
	at sun.nio.ch.SocketAdaptor$SocketInputStream.read(SocketAdaptor.java:211)
	at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:81)
	at kafka.network.BlockingChannel.readCompletely(BlockingChannel.scala:129)
	at kafka.network.BlockingChannel.receive(BlockingChannel.scala:120)
	at kafka.consumer.SimpleConsumer.liftedTree1$1(SimpleConsumer.scala:86)
	at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:83)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SimpleConsumer.scala:132)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:132)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:132)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply$mcV$sp(SimpleConsumer.scala:131)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:131)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:131)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:130)
	at kafka.consumer.ConsumerFetcherThread.fetch(ConsumerFetcherThread.scala:108)
	at kafka.consumer.ConsumerFetcherThread.fetch(ConsumerFetcherThread.scala:29)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-20 10:12:07,297] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-20 10:12:07,318] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-20 10:12:07,319] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-20 10:12:07,560] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-20 10:12:07,561] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-20 10:12:07,599] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-20 10:12:07,601] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-20 10:12:07,601] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-20 10:12:07,602] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-20 10:12:07,784] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [TextLinesTopic,0],[test,0],[RekeyedIntermediateTopic,0],[WordsWithCountsTopic,0] (kafka.server.ReplicaFetcherManager)
[2016-09-20 10:12:07,792] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-20 10:12:09,793] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], ZK expired; release old broker parition ownership; re-register consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,801] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin registering consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,802] INFO Creating /consumers/console-consumer-24287/ids/console-consumer-24287_MSSPAD370-1474283135203-fe030f6c (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-20 10:12:09,913] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-20 10:12:09,914] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end registering consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,916] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,935] INFO [ConsumerFetcherManager-1474283135221] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:09,935] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutting down (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:09,936] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Stopped  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:09,936] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutdown completed (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:09,937] INFO [ConsumerFetcherManager-1474283135221] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:09,938] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutting down (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:12:09,939] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Stopped  (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:12:09,939] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutdown completed (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:12:09,941] INFO [ConsumerFetcherManager-1474283135221] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:09,941] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared all relevant queues for this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,942] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared the data chunks in all the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,943] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Committing all offsets after clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,943] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Releasing partition ownership (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:09,958] INFO Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c rebalancing the following partitions: ArrayBuffer(0) for topic test with consumers: List(console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0) (kafka.consumer.RangeAssignor)
[2016-09-20 10:12:09,960] INFO console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 attempting to claim partition 0 (kafka.consumer.RangeAssignor)
[2016-09-20 10:12:10,271] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 successfully owned partition 0 for topic test (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,272] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c selected partitions : test:0: fetched offset = 9: consumed offset = 9 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,273] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,274] INFO ZK expired: resubscribing topic event listener to topic registry (kafka.consumer.ZookeeperTopicEventWatcher)
[2016-09-20 10:12:10,274] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Starting  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:10,283] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,289] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:10,291] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:10,292] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topics to consume = List(test) (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,292] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:10,293] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:10,296] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 26 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-20 10:12:10,298] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Topic info for path /brokers/topics/test changed to {"version":1,"partitions":{"0":[0]}}, triggering rebalance (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,299] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-20 10:12:10,303] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-20 10:12:10,306] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer([[test,0], initOffset 9 to broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] ) (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:10,309] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Starting  (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:12:10,311] INFO [ConsumerFetcherManager-1474283135221] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:10,313] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutting down (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:10,316] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Stopped  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:10,316] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutdown completed (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:10,318] INFO [ConsumerFetcherManager-1474283135221] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:10,319] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutting down (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:12:10,321] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Stopped  (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:12:10,321] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutdown completed (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:12:10,324] INFO [ConsumerFetcherManager-1474283135221] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:10,325] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared all relevant queues for this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,326] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared the data chunks in all the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,330] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Committing all offsets after clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:10,331] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Releasing partition ownership (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,449] INFO Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c rebalancing the following partitions: ArrayBuffer(0) for topic test with consumers: List(console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0) (kafka.consumer.RangeAssignor)
[2016-09-20 10:12:11,449] INFO console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 attempting to claim partition 0 (kafka.consumer.RangeAssignor)
[2016-09-20 10:12:11,459] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 successfully owned partition 0 for topic test (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,460] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c selected partitions : test:0: fetched offset = 9: consumed offset = 9 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,462] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,464] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Starting  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:11,464] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], begin rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,478] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,479] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,480] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,481] INFO [ConsumerFetcherManager-1474283135221] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:11,481] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,482] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 27 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-20 10:12:11,482] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutting down (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:11,483] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-20 10:12:11,484] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-20 10:12:11,485] WARN Fetching topic metadata with correlation id 27 for topics [Set(test)] from broker [BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] failed (kafka.client.ClientUtils$)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:110)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:80)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:79)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:124)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:59)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:94)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-20 10:12:11,485] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-20 10:12:11,486] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Stopped  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:11,486] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutdown completed (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:11,487] INFO [ConsumerFetcherManager-1474283135221] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:11,488] INFO [ConsumerFetcherManager-1474283135221] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:11,488] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared all relevant queues for this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,489] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Cleared the data chunks in all the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,489] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Committing all offsets after clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,490] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Releasing partition ownership (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,521] INFO Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c rebalancing the following partitions: ArrayBuffer(0) for topic test with consumers: List(console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0) (kafka.consumer.RangeAssignor)
[2016-09-20 10:12:11,521] INFO console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 attempting to claim partition 0 (kafka.consumer.RangeAssignor)
[2016-09-20 10:12:11,527] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0 successfully owned partition 0 for topic test (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,528] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], Consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c selected partitions : test:0: fetched offset = 9: consumed offset = 9 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,528] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], end rebalancing consumer console-consumer-24287_MSSPAD370-1474283135203-fe030f6c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:12:11,529] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Starting  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:12:11,534] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,538] INFO Property client.id is overridden to console-consumer-24287 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,539] INFO Property metadata.broker.list is overridden to MSSPAD370.manthansystems.com:9092 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,540] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProperties)
[2016-09-20 10:12:11,540] INFO Fetching metadata from broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092) with correlation id 28 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2016-09-20 10:12:11,541] INFO Connected to MSSPAD370.manthansystems.com:9092 for producing (kafka.producer.SyncProducer)
[2016-09-20 10:12:11,543] INFO Disconnecting from MSSPAD370.manthansystems.com:9092 (kafka.producer.SyncProducer)
[2016-09-20 10:12:11,546] INFO [ConsumerFetcherManager-1474283135221] Added fetcher for partitions ArrayBuffer([[test,0], initOffset 9 to broker BrokerEndPoint(0,MSSPAD370.manthansystems.com,9092)] ) (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:12:11,548] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Starting  (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:21:33,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:31:33,336] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:41:33,353] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-20 10:42:46,843] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], ZKConsumerConnector shutting down (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:42:47,038] INFO Shutting down topic event watcher. (kafka.consumer.ZookeeperTopicEventWatcher)
[2016-09-20 10:42:47,062] INFO [ConsumerFetcherManager-1474283135221] Stopping leader finder thread (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:42:47,063] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutting down (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:42:47,065] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Stopped  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:42:47,066] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-leader-finder-thread], Shutdown completed (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2016-09-20 10:42:47,082] INFO [ConsumerFetcherManager-1474283135221] Stopping all fetchers (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:42:47,084] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutting down (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:42:47,087] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Shutdown completed (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:42:47,087] INFO [ConsumerFetcherThread-console-consumer-24287_MSSPAD370-1474283135203-fe030f6c-0-0], Stopped  (kafka.consumer.ConsumerFetcherThread)
[2016-09-20 10:42:47,102] INFO [ConsumerFetcherManager-1474283135221] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2016-09-20 10:42:47,204] INFO [console-consumer-24287_MSSPAD370-1474283135203-fe030f6c], ZKConsumerConnector shutdown completed in 322 ms (kafka.consumer.ZookeeperConsumerConnector)
[2016-09-20 10:43:01,393] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-20 10:43:01,399] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-20 10:43:01,449] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-20 10:43:06,474] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 16:09:04,488] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-21 16:09:04,598] INFO starting (kafka.server.KafkaServer)
[2016-09-21 16:09:04,608] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-21 16:09:04,998] INFO Loading logs. (kafka.log.LogManager)
[2016-09-21 16:09:05,048] WARN Found a corrupted index file, D:\tmp\kafka-logs\RekeyedIntermediateTopic-0\00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[2016-09-21 16:09:05,068] INFO Recovering unflushed segment 0 in log RekeyedIntermediateTopic-0. (kafka.log.Log)
[2016-09-21 16:09:05,068] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.LogSegment.recover(LogSegment.scala:174)
	at kafka.log.Log.recoverLog(Log.scala:268)
	at kafka.log.Log.loadSegments(Log.scala:243)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,068] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.Log.loadSegments(Log.scala:245)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,078] INFO Completed load of log RekeyedIntermediateTopic-0 with log end offset 0 (kafka.log.Log)
[2016-09-21 16:09:05,088] WARN Found a corrupted index file, D:\tmp\kafka-logs\test-0\00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[2016-09-21 16:09:05,098] INFO Recovering unflushed segment 0 in log test-0. (kafka.log.Log)
[2016-09-21 16:09:05,098] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.LogSegment.recover(LogSegment.scala:174)
	at kafka.log.Log.recoverLog(Log.scala:268)
	at kafka.log.Log.loadSegments(Log.scala:243)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,098] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.Log.loadSegments(Log.scala:245)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,108] INFO Completed load of log test-0 with log end offset 9 (kafka.log.Log)
[2016-09-21 16:09:05,108] WARN Found a corrupted index file, D:\tmp\kafka-logs\TextLinesTopic-0\00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[2016-09-21 16:09:05,118] INFO Recovering unflushed segment 0 in log TextLinesTopic-0. (kafka.log.Log)
[2016-09-21 16:09:05,118] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.LogSegment.recover(LogSegment.scala:174)
	at kafka.log.Log.recoverLog(Log.scala:268)
	at kafka.log.Log.loadSegments(Log.scala:243)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,128] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.Log.loadSegments(Log.scala:245)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,128] INFO Completed load of log TextLinesTopic-0 with log end offset 0 (kafka.log.Log)
[2016-09-21 16:09:05,138] WARN Found a corrupted index file, D:\tmp\kafka-logs\WordsWithCountsTopic-0\00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[2016-09-21 16:09:05,138] INFO Recovering unflushed segment 0 in log WordsWithCountsTopic-0. (kafka.log.Log)
[2016-09-21 16:09:05,138] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.LogSegment.recover(LogSegment.scala:174)
	at kafka.log.Log.recoverLog(Log.scala:268)
	at kafka.log.Log.loadSegments(Log.scala:243)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,148] WARN Error when freeing index buffer (kafka.log.OffsetIndex)
java.lang.NullPointerException
	at kafka.log.OffsetIndex.kafka$log$OffsetIndex$$forceUnmap(OffsetIndex.scala:310)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:292)
	at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:285)
	at kafka.log.Log.loadSegments(Log.scala:245)
	at kafka.log.Log.<init>(Log.scala:101)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:152)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:56)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:09:05,148] INFO Completed load of log WordsWithCountsTopic-0 with log end offset 0 (kafka.log.Log)
[2016-09-21 16:09:05,158] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-21 16:09:05,258] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-21 16:09:05,258] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-21 16:09:05,318] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-21 16:09:05,328] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-21 16:09:05,358] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:09:05,358] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:09:05,408] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:09:05,428] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:09:05,428] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-21 16:09:05,758] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:09:05,758] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-21 16:09:05,758] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:09:05,778] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:09:05,778] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:09:05,788] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 20 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 16:09:05,828] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:09:05,828] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:09:05,838] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-21 16:09:05,878] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:09:05,898] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:09:05,898] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-21 16:09:05,938] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-21 16:09:50,309] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-21 16:09:50,319] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-21 16:09:50,359] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 16:09:55,363] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 16:09:55,373] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 16:10:00,404] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 16:10:00,414] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 16:10:05,453] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 16:10:05,453] WARN [Kafka Server 0], Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2016-09-21 16:10:05,453] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2016-09-21 16:10:05,483] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2016-09-21 16:10:05,483] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2016-09-21 16:10:05,503] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2016-09-21 16:10:05,523] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:06,243] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:06,243] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:06,243] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:06,383] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:06,383] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:06,383] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2016-09-21 16:10:06,383] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2016-09-21 16:10:06,383] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2016-09-21 16:10:06,383] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2016-09-21 16:10:06,383] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:06,593] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:06,593] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:06,593] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:06,803] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:06,803] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:06,803] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2016-09-21 16:10:06,803] INFO Shutting down. (kafka.log.LogManager)
[2016-09-21 16:10:06,853] INFO Shutdown complete. (kafka.log.LogManager)
[2016-09-21 16:10:06,853] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:10:06,853] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:07,063] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:07,063] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:07,063] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:07,183] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:07,183] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:07,183] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:10:07,203] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2016-09-21 16:10:29,736] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-21 16:10:29,868] INFO starting (kafka.server.KafkaServer)
[2016-09-21 16:10:29,878] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-21 16:10:30,362] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-21 16:10:30,372] INFO Loading logs. (kafka.log.LogManager)
[2016-09-21 16:10:30,372] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-21 16:10:30,432] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-21 16:10:30,442] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-21 16:10:30,442] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-21 16:10:30,492] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-21 16:10:30,502] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-21 16:10:30,522] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:30,522] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:30,562] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:10:30,582] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:10:30,582] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-21 16:10:30,852] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-21 16:10:30,852] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:30,852] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:10:30,872] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:10:30,872] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:10:30,883] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 21 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 16:10:30,904] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:30,904] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:10:30,904] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-21 16:10:30,954] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:10:30,964] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:10:30,974] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-21 16:10:30,974] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-21 16:10:31,004] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-21 16:20:30,884] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 16:20:57,727] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-21 16:20:57,748] INFO [KafkaApi-0] Auto creation of topic source-topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-21 16:20:57,861] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:23:40,933] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:29:43,922] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:30:30,895] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 16:32:19,569] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-21 16:32:19,586] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-21 16:32:19,612] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 16:32:24,614] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 16:32:24,621] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 16:32:29,622] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 16:34:07,650] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-21 16:34:07,749] INFO starting (kafka.server.KafkaServer)
[2016-09-21 16:34:07,782] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-21 16:34:08,072] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-21 16:34:08,082] INFO Loading logs. (kafka.log.LogManager)
[2016-09-21 16:34:08,092] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-21 16:34:08,155] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-21 16:34:08,158] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-21 16:34:08,166] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-21 16:34:08,261] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-21 16:34:08,266] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-21 16:34:08,295] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:34:08,297] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:34:08,366] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:34:08,375] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:34:08,378] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-21 16:34:08,456] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:34:08,458] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 16:34:08,489] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:34:08,492] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-21 16:34:08,502] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 17 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 16:34:08,545] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:34:08,546] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 16:34:08,553] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-21 16:34:08,583] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-21 16:34:08,585] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:34:08,590] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 16:34:08,594] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-21 16:34:08,595] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-21 16:34:08,639] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-21 16:36:01,649] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-21 16:36:01,655] INFO [KafkaApi-0] Auto creation of topic source-topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-21 16:36:01,940] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:44:08,495] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 16:46:20,759] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-21 16:46:20,761] INFO [KafkaApi-0] Auto creation of topic source-test1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-21 16:46:20,789] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 16:54:08,508] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 16:54:32,649] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-21 16:56:08,257] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 17:04:08,520] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 17:05:10,620] ERROR kafka.admin.AdminOperationException: replication factor must be larger than 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:115)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.admin.TopicCommand$.createTopic(TopicCommand.scala:110)
	at kafka.admin.TopicCommand$.main(TopicCommand.scala:61)
	at kafka.admin.TopicCommand.main(TopicCommand.scala)
 (kafka.admin.TopicCommand$)
[2016-09-21 17:05:22,346] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-21 17:10:24,659] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-21 17:10:24,670] INFO [KafkaApi-0] Auto creation of topic Text2 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-21 17:10:24,689] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application1} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 17:11:21,497] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-21 17:11:21,503] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-21 17:11:21,519] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 17:11:26,521] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 17:11:26,531] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 17:11:31,532] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 17:11:31,540] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-21 17:11:36,541] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-21 17:11:36,546] WARN [Kafka Server 0], Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2016-09-21 17:11:36,549] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2016-09-21 17:11:36,576] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2016-09-21 17:11:36,579] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2016-09-21 17:11:36,586] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2016-09-21 17:11:36,613] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:11:37,509] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:11:37,509] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:11:37,509] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:11:38,465] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:11:38,465] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:11:38,467] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2016-09-21 17:11:38,470] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2016-09-21 17:11:38,471] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2016-09-21 17:11:38,474] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2016-09-21 17:11:38,474] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,547] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,547] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,548] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,748] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,748] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,754] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2016-09-21 17:11:38,780] INFO Shutting down. (kafka.log.LogManager)
[2016-09-21 17:11:38,814] INFO Shutdown complete. (kafka.log.LogManager)
[2016-09-21 17:11:38,816] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[2016-09-21 17:11:38,817] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,947] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,947] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,947] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,957] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,957] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:11:38,966] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[2016-09-21 17:11:39,045] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2016-09-21 17:16:19,154] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-21 17:16:19,344] INFO starting (kafka.server.KafkaServer)
[2016-09-21 17:16:19,374] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-21 17:16:19,674] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-21 17:16:19,684] INFO Loading logs. (kafka.log.LogManager)
[2016-09-21 17:16:19,694] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-21 17:16:19,764] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-21 17:16:19,769] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-21 17:16:19,779] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-21 17:16:19,880] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-21 17:16:19,886] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-21 17:16:19,917] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:16:19,919] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:16:19,989] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 17:16:19,999] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 17:16:20,001] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-21 17:16:20,092] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:16:20,094] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-21 17:16:20,114] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-21 17:16:20,115] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-21 17:16:20,192] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 82 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 17:16:20,206] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:16:20,207] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-21 17:16:20,213] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-21 17:16:20,253] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 17:16:20,272] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-21 17:16:20,277] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-21 17:16:20,279] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-21 17:16:20,288] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-21 17:16:20,346] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-21 17:20:08,688] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-21 17:20:08,807] INFO [KafkaApi-0] Auto creation of topic Text4 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-21 17:20:09,436] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application1} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-21 17:26:20,120] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 17:36:20,133] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 17:46:20,145] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 17:56:20,157] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 18:06:20,172] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 18:16:20,184] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 18:26:20,196] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 18:36:20,207] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 18:46:20,222] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 18:56:20,231] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 19:06:20,246] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 19:16:20,256] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-21 19:23:05,852] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text4,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 01:23:25,462] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,602] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,603] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,603] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,604] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,604] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,604] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,605] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,605] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,606] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,606] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,607] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,676] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,676] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,676] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,696] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,860] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,865] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,885] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:25,914] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:26,021] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:26,021] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:26,022] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:26,022] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,850] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,850] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,850] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,850] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,950] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,950] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,950] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,960] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:27,960] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:28,030] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:28,080] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:28,080] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 01:23:29,810] INFO Completed load of log Text4-0 with log end offset 0 (kafka.log.Log)
[2016-09-22 01:23:31,130] INFO Created log for partition [Text4,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 01:23:33,530] INFO Partition [Text4,0] on broker 0: No checkpointed highwatermark is found for partition [Text4,0] (kafka.cluster.Partition)
[2016-09-22 01:23:38,730] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 01:23:38,760] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 01:23:38,830] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 01:23:45,660] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 01:23:45,670] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 01:23:45,870] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 01:23:45,870] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(127.0.0.1,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 01:23:47,640] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 01:23:51,020] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 01:23:54,410] WARN Attempting to send response via channel for which there is no open connection, connection id 2 (kafka.network.Processor)
[2016-09-22 01:24:14,848] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text4,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 01:24:14,858] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 10:39:36,510] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:41,568] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:41,568] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:41,568] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:41,568] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:42,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:42,128] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:42,458] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:42,458] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:42,458] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:42,598] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:42,598] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,038] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,038] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,038] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,058] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,058] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,058] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,058] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,078] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,088] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,118] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,138] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,138] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,138] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,138] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 10:39:43,148] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,148] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,148] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,148] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,288] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,288] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,288] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,658] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,658] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,658] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,658] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,678] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,678] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,678] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,708] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 10:39:43,988] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,988] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,988] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:43,988] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,008] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,008] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,008] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,008] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,048] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,048] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,408] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:39:44,468] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 10:39:45,648] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 10:39:45,678] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 10:39:45,728] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 10:39:45,728] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 10:39:45,728] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 10:39:45,888] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 10:39:47,618] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text4,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 10:39:47,648] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 10:46:34,237] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:42,867] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-22 10:53:42,937] INFO [KafkaApi-0] Auto creation of topic Text5 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-22 10:53:43,327] INFO Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}} (kafka.admin.AdminUtils$)
[2016-09-22 10:53:43,407] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-22 10:53:43,537] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [Text5,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 10:53:43,587] INFO Completed load of log Text5-0 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:43,587] INFO Created log for partition [Text5,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:43,597] INFO Partition [Text5,0] on broker 0: No checkpointed highwatermark is found for partition [Text5,0] (kafka.cluster.Partition)
[2016-09-22 10:53:49,395] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-22 10:53:49,615] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:49,615] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:49,615] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-22 10:53:49,635] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:49,665] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:49,665] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-22 10:53:49,675] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:49,675] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:49,715] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-22 10:53:49,765] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:49,765] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:49,765] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-22 10:53:49,805] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:49,805] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:49,805] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-22 10:53:50,025] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,035] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,045] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-22 10:53:50,055] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,055] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,075] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-22 10:53:50,095] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,095] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,105] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-22 10:53:50,175] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,175] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,175] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-22 10:53:50,195] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,225] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,225] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-22 10:53:50,245] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,245] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,325] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-22 10:53:50,335] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,335] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,335] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-22 10:53:50,365] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,365] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,365] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-22 10:53:50,425] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,455] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,455] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-22 10:53:50,485] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,485] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,495] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-22 10:53:50,555] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,555] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,555] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-22 10:53:50,605] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,645] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,645] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-22 10:53:50,675] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,675] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,695] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-22 10:53:50,765] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,775] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,775] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-22 10:53:50,855] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,855] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,855] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-22 10:53:50,885] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:50,935] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:50,945] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-22 10:53:51,085] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,085] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,125] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-22 10:53:51,185] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,185] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,185] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-22 10:53:51,225] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,225] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,225] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-22 10:53:51,235] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,275] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,275] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-22 10:53:51,275] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,285] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,335] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-22 10:53:51,375] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,375] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,375] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-22 10:53:51,395] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,395] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,405] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-22 10:53:51,485] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,485] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,495] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-22 10:53:51,495] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,515] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,515] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-22 10:53:51,565] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,565] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,625] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-22 10:53:51,635] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,635] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,635] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-22 10:53:51,665] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,665] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,665] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-22 10:53:51,675] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,695] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,695] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-22 10:53:51,705] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,715] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,735] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-22 10:53:51,745] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,755] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,755] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-22 10:53:51,775] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,775] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,775] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-22 10:53:51,785] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,815] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,815] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-22 10:53:51,825] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,825] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,865] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-22 10:53:51,875] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,875] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,875] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-22 10:53:51,945] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:51,945] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:51,955] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-22 10:53:51,955] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,035] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,035] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-22 10:53:52,045] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,045] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,085] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-22 10:53:52,095] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,095] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,095] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-22 10:53:52,155] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,155] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,165] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-22 10:53:52,165] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,195] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,195] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-22 10:53:52,205] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,205] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,245] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-22 10:53:52,245] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,245] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,255] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-22 10:53:52,305] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,305] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,305] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-22 10:53:52,315] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-22 10:53:52,335] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 10:53:52,335] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-22 10:53:52,835] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,665] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 830 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,685] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,705] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,735] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,735] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,735] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,735] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,775] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,775] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,775] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,815] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 30 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,835] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,875] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,875] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,885] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,905] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,905] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,945] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,945] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:53,985] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,005] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,005] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,015] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,075] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,085] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,085] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,095] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,145] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,155] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,165] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,165] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,205] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,215] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,215] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,275] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,315] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,325] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,335] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,415] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,455] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,465] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,465] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,515] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,525] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,555] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 30 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,555] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,585] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,585] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,595] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,595] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,645] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,655] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,655] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,655] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,705] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 10:53:54,715] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,725] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,745] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,785] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,785] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,795] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,795] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,855] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,865] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,865] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,875] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:54,965] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,015] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 30 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,015] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,045] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,065] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,075] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,075] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,085] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:55,125] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,003] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 878 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,003] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,013] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,073] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,073] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,083] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,083] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,183] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,183] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,193] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,193] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,333] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,343] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,343] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,343] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,363] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,363] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,363] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,373] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,403] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,413] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,413] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,413] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,473] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,483] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:53:56,853] INFO [GroupCoordinator 0]: Stabilized group my-first-streams-application1 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 10:54:00,013] INFO [GroupCoordinator 0]: Assignment received from leader for group my-first-streams-application1 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 10:56:34,242] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 10:58:04,222] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 10:58:04,226] INFO [GroupCoordinator 0]: Group my-first-streams-application1 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:06:34,254] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 11:11:31,898] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:11:31,899] INFO [GroupCoordinator 0]: Stabilized group my-first-streams-application1 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:11:31,938] INFO [GroupCoordinator 0]: Assignment received from leader for group my-first-streams-application1 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:13:01,973] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:13:02,002] INFO [GroupCoordinator 0]: Group my-first-streams-application1 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:16:34,268] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 11:18:01,436] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:18:01,437] INFO [GroupCoordinator 0]: Stabilized group my-first-streams-application1 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:18:01,477] INFO [GroupCoordinator 0]: Assignment received from leader for group my-first-streams-application1 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:18:52,533] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:18:52,535] INFO [GroupCoordinator 0]: Group my-first-streams-application1 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:26:34,279] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 11:31:21,597] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:31:21,627] INFO [GroupCoordinator 0]: Stabilized group my-first-streams-application1 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:31:21,664] INFO [GroupCoordinator 0]: Assignment received from leader for group my-first-streams-application1 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:32:18,724] INFO [GroupCoordinator 0]: Preparing to restabilize group my-first-streams-application1 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:32:18,725] INFO [GroupCoordinator 0]: Group my-first-streams-application1 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 11:36:34,291] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 11:46:34,311] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 11:56:34,317] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 12:06:34,333] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 12:16:34,341] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 12:26:34,356] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 12:36:34,365] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 12:42:18,699] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-22 12:42:18,789] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-22 12:44:10,721] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-22 12:44:10,811] INFO starting (kafka.server.KafkaServer)
[2016-09-22 12:44:10,821] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-22 12:44:11,141] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-22 12:44:11,151] INFO Loading logs. (kafka.log.LogManager)
[2016-09-22 12:44:11,161] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-22 12:44:11,221] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-22 12:44:11,221] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-22 12:44:11,231] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 12:44:11,291] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-22 12:44:11,301] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-22 12:44:11,321] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:44:11,331] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:44:11,421] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:44:11,431] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:44:11,431] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 12:44:11,521] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:44:11,521] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:44:11,531] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-22 12:44:11,531] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 12:44:11,541] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 12:44:11,581] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:44:11,581] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:44:11,591] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-22 12:44:11,621] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:44:11,631] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:44:11,631] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 12:44:11,641] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 12:44:11,661] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 12:44:11,691] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-22 12:45:15,759] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-22 12:46:23,426] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application1} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-22 12:47:17,241] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-22 12:47:17,241] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-22 12:47:17,271] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-22 12:47:22,274] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-22 12:47:22,274] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-22 12:47:27,292] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-22 12:47:27,292] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-22 12:47:32,299] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-22 12:47:32,299] WARN [Kafka Server 0], Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2016-09-22 12:47:32,299] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2016-09-22 12:47:32,309] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2016-09-22 12:47:32,329] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2016-09-22 12:47:32,329] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2016-09-22 12:47:32,329] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:47:32,756] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:47:32,756] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:47:32,756] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:47:33,766] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:47:33,766] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:47:33,766] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2016-09-22 12:47:33,766] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2016-09-22 12:47:33,766] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2016-09-22 12:47:33,766] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2016-09-22 12:47:33,766] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:33,956] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:33,956] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:33,956] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,046] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,046] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,056] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2016-09-22 12:47:34,076] INFO Shutting down. (kafka.log.LogManager)
[2016-09-22 12:47:34,096] INFO Shutdown complete. (kafka.log.LogManager)
[2016-09-22 12:47:34,096] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[2016-09-22 12:47:34,096] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,296] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,296] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,296] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,406] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,406] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:47:34,406] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 12:47:34,436] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2016-09-22 12:50:37,263] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-22 12:50:37,403] INFO starting (kafka.server.KafkaServer)
[2016-09-22 12:50:37,413] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-22 12:50:37,823] INFO Loading logs. (kafka.log.LogManager)
[2016-09-22 12:50:37,833] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-22 12:50:37,893] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-22 12:50:37,893] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-22 12:50:37,953] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-22 12:50:37,963] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-22 12:50:37,983] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:50:37,983] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:50:38,023] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:50:38,043] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:50:38,053] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 12:50:38,193] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:50:38,193] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 12:50:38,193] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 12:50:38,203] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-22 12:50:38,203] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 12:50:38,213] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 12:50:38,223] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:50:38,223] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 12:50:38,233] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-22 12:50:38,253] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:50:38,263] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 12:50:38,263] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 12:50:38,283] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-22 12:51:03,850] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-22 12:51:03,853] INFO [KafkaApi-0] Auto creation of topic Text9 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-22 12:51:04,035] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application2} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-22 12:54:28,270] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application2} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-22 13:00:38,217] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:03:27,826] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application2} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-22 13:04:38,572] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-22 13:04:38,572] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-22 13:04:38,612] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-22 13:04:43,613] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-22 13:05:50,013] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-22 13:05:50,163] INFO starting (kafka.server.KafkaServer)
[2016-09-22 13:05:50,173] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-22 13:05:50,443] INFO Log directory 'D:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-09-22 13:05:50,453] INFO Loading logs. (kafka.log.LogManager)
[2016-09-22 13:05:50,463] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-22 13:05:50,523] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-22 13:05:50,523] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-22 13:05:50,533] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:05:50,593] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-22 13:05:50,593] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-22 13:05:50,623] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:05:50,623] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:05:50,683] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:05:50,693] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:05:50,693] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 13:05:50,773] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:05:50,783] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:05:50,813] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:05:50,823] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:05:50,823] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:05:50,843] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:05:50,853] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:05:50,853] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-22 13:05:50,883] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 13:05:50,893] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:05:50,893] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:05:50,903] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 13:05:50,903] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:05:50,923] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-22 13:08:15,131] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-22 13:08:15,131] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-22 13:12:55,090] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = 
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-22 13:12:55,152] INFO starting (kafka.server.KafkaServer)
[2016-09-22 13:12:55,168] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-22 13:12:55,370] INFO Loading logs. (kafka.log.LogManager)
[2016-09-22 13:12:55,370] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-22 13:12:55,433] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-22 13:12:55,433] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-22 13:12:55,495] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-09-22 13:12:55,495] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-22 13:12:55,526] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:12:55,526] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:12:55,589] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:12:55,604] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:12:55,604] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 13:12:55,698] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:12:55,714] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:12:55,745] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:12:55,745] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 16 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:12:55,745] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:12:55,776] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:12:55,776] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:12:55,776] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-22 13:12:55,807] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 13:12:55,807] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:12:55,823] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:12:55,823] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(MSSPAD370.manthansystems.com,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 13:12:55,838] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-22 13:14:30,465] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-09-22 13:14:30,465] INFO [KafkaApi-0] Auto creation of topic Text9 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-22 13:14:30,574] ERROR [KafkaApi-0] Error when handling request {group_id=my-first-streams-application2} (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:117)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:403)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createTopic(KafkaApis.scala:629)
	at kafka.server.KafkaApis.kafka$server$KafkaApis$$createGroupMetadataTopic(KafkaApis.scala:651)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at kafka.server.KafkaApis$$anonfun$getOrCreateGroupMetadataTopic$1.apply(KafkaApis.scala:657)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.server.KafkaApis.getOrCreateGroupMetadataTopic(KafkaApis.scala:657)
	at kafka.server.KafkaApis.handleGroupCoordinatorRequest(KafkaApis.scala:818)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:86)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-09-22 13:17:08,296] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-22 13:17:08,316] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-22 13:17:08,336] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-22 13:17:13,336] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-22 13:17:13,336] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-22 13:17:18,336] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-22 13:17:18,358] WARN [Kafka Server 0], Error during controlled shutdown, possibly because leader movement took longer than the configured socket.timeout.ms: Connection to MSSPAD370.manthansystems.com:9092 (id: 0 rack: null) failed (kafka.server.KafkaServer)
[2016-09-22 13:17:23,360] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2016-09-22 13:17:23,360] WARN [Kafka Server 0], Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2016-09-22 13:17:23,360] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2016-09-22 13:17:23,370] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2016-09-22 13:17:23,370] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2016-09-22 13:17:23,370] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2016-09-22 13:17:23,380] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:17:23,510] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:17:23,510] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:17:23,510] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:17:23,550] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:17:23,550] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:17:23,550] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2016-09-22 13:17:23,550] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2016-09-22 13:17:23,550] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:17:23,550] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:17:23,550] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,580] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,580] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,580] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,780] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,780] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,780] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2016-09-22 13:17:23,780] INFO Shutting down. (kafka.log.LogManager)
[2016-09-22 13:17:23,790] INFO Shutdown complete. (kafka.log.LogManager)
[2016-09-22 13:17:23,790] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:17:23,790] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,981] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,981] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:23,983] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:24,184] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:24,184] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:17:24,184] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:17:24,214] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2016-09-22 13:20:00,780] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9092
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs0
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 0
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-22 13:20:00,900] INFO starting (kafka.server.KafkaServer)
[2016-09-22 13:20:00,910] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-22 13:20:01,190] INFO Log directory 'D:\tmp\kafka-logs0' not found, creating it. (kafka.log.LogManager)
[2016-09-22 13:20:01,200] INFO Loading logs. (kafka.log.LogManager)
[2016-09-22 13:20:01,210] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-22 13:20:01,270] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-22 13:20:01,270] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-22 13:20:01,280] WARN No meta.properties file under dir D:\tmp\kafka-logs0\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:20:01,350] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2016-09-22 13:20:01,350] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-22 13:20:01,380] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:01,390] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:01,450] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:20:01,460] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:20:01,460] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 13:20:01,530] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:01,530] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:01,550] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:20:01,550] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:20:01,560] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:20:01,590] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:20:01,590] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:20:01,600] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-22 13:20:01,620] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:20:01,630] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:20:01,630] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 13:20:01,640] WARN No meta.properties file under dir D:\tmp\kafka-logs0\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:20:01,640] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 13:20:01,660] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-09-22 13:20:44,573] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9093
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs1
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 1
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-22 13:20:44,703] INFO starting (kafka.server.KafkaServer)
[2016-09-22 13:20:44,703] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-22 13:20:44,903] INFO Log directory 'D:\tmp\kafka-logs1' not found, creating it. (kafka.log.LogManager)
[2016-09-22 13:20:44,913] INFO Loading logs. (kafka.log.LogManager)
[2016-09-22 13:20:44,923] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-22 13:20:44,983] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-22 13:20:44,983] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-22 13:20:44,993] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:20:45,053] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2016-09-22 13:20:45,063] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-22 13:20:45,083] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:45,083] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:45,243] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:45,243] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:20:45,263] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:20:45,273] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:20:45,273] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:20:45,293] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:20:45,293] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:20:45,303] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-22 13:20:45,333] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:20:45,343] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:20:45,343] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 13:20:45,353] WARN No meta.properties file under dir D:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:20:45,393] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2016-09-22 13:21:19,916] INFO KafkaConfig values: 
	advertised.host.name = null
	metric.reporters = []
	quota.producer.default = 9223372036854775807
	offsets.topic.num.partitions = 50
	log.flush.interval.messages = 9223372036854775807
	auto.create.topics.enable = true
	controller.socket.timeout.ms = 30000
	log.flush.interval.ms = null
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	replica.socket.receive.buffer.bytes = 65536
	min.insync.replicas = 1
	replica.fetch.wait.max.ms = 500
	num.recovery.threads.per.data.dir = 1
	ssl.keystore.type = JKS
	sasl.mechanism.inter.broker.protocol = GSSAPI
	default.replication.factor = 1
	ssl.truststore.password = null
	log.preallocate = false
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	fetch.purgatory.purge.interval.requests = 1000
	ssl.endpoint.identification.algorithm = null
	replica.socket.timeout.ms = 30000
	message.max.bytes = 1000012
	num.io.threads = 8
	offsets.commit.required.acks = -1
	log.flush.offset.checkpoint.interval.ms = 60000
	delete.topic.enable = false
	quota.window.size.seconds = 1
	ssl.truststore.type = JKS
	offsets.commit.timeout.ms = 5000
	quota.window.num = 11
	zookeeper.connect = localhost:2181
	authorizer.class.name = 
	num.replica.fetchers = 1
	log.retention.ms = null
	log.roll.jitter.hours = 0
	log.cleaner.enable = true
	offsets.load.buffer.size = 5242880
	log.cleaner.delete.retention.ms = 86400000
	ssl.client.auth = none
	controlled.shutdown.max.retries = 3
	queued.max.requests = 500
	offsets.topic.replication.factor = 3
	log.cleaner.threads = 1
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	socket.request.max.bytes = 104857600
	ssl.trustmanager.algorithm = PKIX
	zookeeper.session.timeout.ms = 6000
	log.retention.bytes = -1
	log.message.timestamp.type = CreateTime
	sasl.kerberos.min.time.before.relogin = 60000
	zookeeper.set.acl = false
	connections.max.idle.ms = 600000
	offsets.retention.minutes = 1440
	replica.fetch.backoff.ms = 1000
	inter.broker.protocol.version = 0.10.0-IV1
	log.retention.hours = 168
	num.partitions = 1
	broker.id.generation.enable = true
	listeners = null
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	log.roll.ms = null
	log.flush.scheduler.interval.ms = 9223372036854775807
	ssl.cipher.suites = null
	log.index.size.max.bytes = 10485760
	ssl.keymanager.algorithm = SunX509
	security.inter.broker.protocol = PLAINTEXT
	replica.fetch.max.bytes = 1048576
	advertised.port = null
	log.cleaner.dedupe.buffer.size = 134217728
	replica.high.watermark.checkpoint.interval.ms = 5000
	log.cleaner.io.buffer.size = 524288
	sasl.kerberos.ticket.renew.window.factor = 0.8
	zookeeper.connection.timeout.ms = 6000
	controlled.shutdown.retry.backoff.ms = 5000
	log.roll.hours = 168
	log.cleanup.policy = delete
	host.name = localhost
	log.roll.jitter.ms = null
	max.connections.per.ip = 2147483647
	offsets.topic.segment.bytes = 104857600
	background.threads = 10
	quota.consumer.default = 9223372036854775807
	request.timeout.ms = 30000
	log.message.format.version = 0.10.0-IV1
	log.index.interval.bytes = 4096
	log.dir = /tmp/kafka-logs
	log.segment.bytes = 1073741824
	log.cleaner.backoff.ms = 15000
	offset.metadata.max.bytes = 4096
	ssl.truststore.location = null
	group.max.session.timeout.ms = 300000
	ssl.keystore.password = null
	zookeeper.sync.time.ms = 2000
	port = 9094
	log.retention.minutes = null
	log.segment.delete.delay.ms = 60000
	log.dirs = /tmp/kafka-logs2
	controlled.shutdown.enable = true
	compression.type = producer
	max.connections.per.ip.overrides = 
	log.message.timestamp.difference.max.ms = 9223372036854775807
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	auto.leader.rebalance.enable = true
	leader.imbalance.check.interval.seconds = 300
	log.cleaner.min.cleanable.ratio = 0.5
	replica.lag.time.max.ms = 10000
	num.network.threads = 3
	ssl.key.password = null
	reserved.broker.max.id = 1000
	metrics.num.samples = 2
	socket.send.buffer.bytes = 102400
	ssl.protocol = TLS
	socket.receive.buffer.bytes = 102400
	ssl.keystore.location = null
	replica.fetch.min.bytes = 1
	broker.rack = null
	unclean.leader.election.enable = true
	sasl.enabled.mechanisms = [GSSAPI]
	group.min.session.timeout.ms = 6000
	log.cleaner.io.buffer.load.factor = 0.9
	offsets.retention.check.interval.ms = 600000
	producer.purgatory.purge.interval.requests = 1000
	metrics.sample.window.ms = 30000
	broker.id = 2
	offsets.topic.compression.codec = 0
	log.retention.check.interval.ms = 300000
	advertised.listeners = null
	leader.imbalance.per.broker.percentage = 10
 (kafka.server.KafkaConfig)
[2016-09-22 13:21:19,986] INFO starting (kafka.server.KafkaServer)
[2016-09-22 13:21:19,996] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-09-22 13:21:20,186] INFO Log directory 'D:\tmp\kafka-logs2' not found, creating it. (kafka.log.LogManager)
[2016-09-22 13:21:20,206] INFO Loading logs. (kafka.log.LogManager)
[2016-09-22 13:21:20,206] INFO Logs loading complete. (kafka.log.LogManager)
[2016-09-22 13:21:20,286] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-09-22 13:21:20,286] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-09-22 13:21:20,296] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:21:20,356] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2016-09-22 13:21:20,356] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2016-09-22 13:21:20,376] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:21:20,376] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:21:20,526] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:21:20,536] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2016-09-22 13:21:20,546] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:21:20,556] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:21:20,556] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:21:20,566] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:21:20,576] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2016-09-22 13:21:20,576] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-09-22 13:21:20,606] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:21:20,616] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 13:21:20,626] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9094,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 13:21:20,626] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2016-09-22 13:21:20,686] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2016-09-22 13:22:48,290] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[2016-09-22 13:22:48,339] INFO [KafkaApi-0] Auto creation of topic Text9 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2016-09-22 13:22:48,471] INFO Topic creation {"version":1,"partitions":{"45":[2,1,0],"34":[0,2,1],"12":[2,0,1],"8":[1,2,0],"19":[0,1,2],"23":[1,0,2],"4":[0,2,1],"40":[0,2,1],"15":[2,1,0],"11":[1,0,2],"9":[2,1,0],"44":[1,2,0],"33":[2,1,0],"22":[0,2,1],"26":[1,2,0],"37":[0,1,2],"13":[0,1,2],"46":[0,2,1],"24":[2,0,1],"35":[1,0,2],"16":[0,2,1],"5":[1,0,2],"10":[0,2,1],"48":[2,0,1],"21":[2,1,0],"43":[0,1,2],"32":[1,2,0],"49":[0,1,2],"6":[2,0,1],"36":[2,0,1],"1":[0,1,2],"39":[2,1,0],"17":[1,0,2],"25":[0,1,2],"14":[1,2,0],"47":[1,0,2],"31":[0,1,2],"42":[2,0,1],"0":[2,0,1],"20":[1,2,0],"27":[2,1,0],"2":[1,2,0],"38":[1,2,0],"18":[2,0,1],"30":[2,0,1],"7":[0,1,2],"29":[1,0,2],"41":[1,0,2],"3":[2,1,0],"28":[0,2,1]}} (kafka.admin.AdminUtils$)
[2016-09-22 13:22:48,511] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 3 is successful (kafka.server.KafkaApis)
[2016-09-22 13:22:48,594] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [Text9,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:48,769] INFO Completed load of log Text9-0 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:48,776] INFO Created log for partition [Text9,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:48,786] INFO Partition [Text9,0] on broker 2: No checkpointed highwatermark is found for partition [Text9,0] (kafka.cluster.Partition)
[2016-09-22 13:22:51,896] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,28],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,13],[__consumer_offsets,40],[__consumer_offsets,37],[__consumer_offsets,34],[__consumer_offsets,22],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:51,966] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,0],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,9],[__consumer_offsets,42],[__consumer_offsets,48],[__consumer_offsets,18],[__consumer_offsets,12],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:52,048] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:52,111] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,120] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,123] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,127] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,129] INFO Partition [__consumer_offsets,0] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-22 13:22:52,135] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-22 13:22:52,223] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,235] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,243] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,247] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,249] INFO Partition [__consumer_offsets,48] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-22 13:22:52,254] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,257] INFO Partition [__consumer_offsets,29] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-22 13:22:52,304] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,312] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,315] INFO Partition [__consumer_offsets,45] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-22 13:22:52,358] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,360] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-22 13:22:52,375] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,377] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,387] INFO Partition [__consumer_offsets,42] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-22 13:22:52,430] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,438] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,439] INFO Partition [__consumer_offsets,26] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-22 13:22:52,478] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,481] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,482] INFO Partition [__consumer_offsets,23] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-22 13:22:52,495] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,501] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,506] INFO Partition [__consumer_offsets,39] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-22 13:22:52,698] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,704] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,751] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,833] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,836] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,838] INFO Partition [__consumer_offsets,20] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-22 13:22:52,839] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-22 13:22:52,847] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,867] INFO Partition [__consumer_offsets,36] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-22 13:22:52,950] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,959] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:52,964] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:52,966] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,004] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,009] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,010] INFO Partition [__consumer_offsets,33] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-22 13:22:53,011] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-22 13:22:53,018] INFO Partition [__consumer_offsets,17] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-22 13:22:53,172] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,208] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,215] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,217] INFO Partition [__consumer_offsets,30] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-22 13:22:53,220] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,224] INFO Partition [__consumer_offsets,14] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-22 13:22:53,238] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,253] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,255] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-22 13:22:53,286] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,289] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,294] INFO Partition [__consumer_offsets,11] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-22 13:22:53,303] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,309] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,330] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,334] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,334] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-22 13:22:53,335] INFO Partition [__consumer_offsets,27] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-22 13:22:53,354] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,360] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,362] INFO Partition [__consumer_offsets,24] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-22 13:22:53,373] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,377] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,385] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,391] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,394] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,414] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-22 13:22:53,412] INFO Partition [__consumer_offsets,21] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-22 13:22:53,418] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,422] INFO Partition [__consumer_offsets,8] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-22 13:22:53,434] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,438] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,438] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,440] INFO Partition [__consumer_offsets,18] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-22 13:22:53,441] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,442] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-22 13:22:53,449] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,463] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,467] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,468] INFO Partition [__consumer_offsets,5] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-22 13:22:53,471] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,480] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,480] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-22 13:22:53,485] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,492] INFO Partition [__consumer_offsets,15] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-22 13:22:53,498] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,501] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,507] INFO Partition [__consumer_offsets,2] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-22 13:22:53,519] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,524] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,530] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-22 13:22:53,546] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,548] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,552] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,555] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,557] INFO Partition [__consumer_offsets,12] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-22 13:22:53,560] INFO Partition [__consumer_offsets,47] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-22 13:22:53,590] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,596] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,606] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,608] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,612] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,618] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-22 13:22:53,623] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,624] INFO Partition [__consumer_offsets,9] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-22 13:22:53,629] INFO Partition [__consumer_offsets,38] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-22 13:22:53,632] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,642] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,642] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-22 13:22:53,652] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,652] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,662] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,675] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,676] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,677] INFO Partition [__consumer_offsets,35] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-22 13:22:53,678] INFO Partition [__consumer_offsets,6] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-22 13:22:53,684] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,687] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-22 13:22:53,698] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,707] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,708] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,710] INFO Partition [__consumer_offsets,44] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-22 13:22:53,715] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,717] INFO Partition [__consumer_offsets,3] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-22 13:22:53,717] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,723] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,730] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-22 13:22:53,741] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,743] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,745] INFO Partition [__consumer_offsets,32] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-22 13:22:53,756] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,761] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,765] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-22 13:22:53,768] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,775] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,776] INFO Partition [__consumer_offsets,41] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-22 13:22:53,782] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,788] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,794] INFO Partition [__consumer_offsets,29] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-22 13:22:53,800] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,808] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,812] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-22 13:22:53,820] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,824] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,826] INFO Partition [__consumer_offsets,10] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-22 13:22:53,836] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,836] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,838] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,844] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,846] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-22 13:22:53,851] INFO Partition [__consumer_offsets,0] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-22 13:22:53,864] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,868] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,870] INFO Partition [__consumer_offsets,48] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-22 13:22:53,880] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,883] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,885] INFO Partition [__consumer_offsets,26] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-22 13:22:53,886] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,889] INFO Created log for partition [__consumer_offsets,0] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,902] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-09-22 13:22:53,909] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,921] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,925] INFO Partition [__consumer_offsets,7] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-22 13:22:53,927] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,933] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,939] INFO Created log for partition [__consumer_offsets,29] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,940] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-09-22 13:22:53,948] INFO Created log for partition [__consumer_offsets,10] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,950] INFO Partition [__consumer_offsets,10] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-09-22 13:22:53,966] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,968] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,972] INFO Created log for partition [__consumer_offsets,48] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,972] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,976] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-09-22 13:22:53,974] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,978] INFO Partition [__consumer_offsets,45] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-22 13:22:53,992] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:53,994] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:53,995] INFO Partition [__consumer_offsets,4] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-22 13:22:54,002] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,004] INFO Created log for partition [__consumer_offsets,7] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,006] INFO Created log for partition [__consumer_offsets,45] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,007] INFO Partition [__consumer_offsets,7] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-09-22 13:22:54,008] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-09-22 13:22:54,019] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,030] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,034] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,037] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,039] INFO Partition [__consumer_offsets,42] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-22 13:22:54,040] INFO Partition [__consumer_offsets,23] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-22 13:22:54,050] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,052] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,054] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,054] INFO Created log for partition [__consumer_offsets,26] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,054] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,054] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-09-22 13:22:54,054] INFO Created log for partition [__consumer_offsets,4] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,054] INFO Partition [__consumer_offsets,1] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-22 13:22:54,064] INFO Partition [__consumer_offsets,4] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-09-22 13:22:54,074] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,074] INFO Created log for partition [__consumer_offsets,42] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,084] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,084] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-09-22 13:22:54,084] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,094] INFO Partition [__consumer_offsets,20] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-22 13:22:54,104] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,104] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,114] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,116] INFO Partition [__consumer_offsets,17] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-22 13:22:54,118] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,120] INFO Created log for partition [__consumer_offsets,23] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,125] INFO Created log for partition [__consumer_offsets,1] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,126] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-09-22 13:22:54,129] INFO Partition [__consumer_offsets,1] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-09-22 13:22:54,132] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,137] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,141] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,141] INFO Partition [__consumer_offsets,14] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-22 13:22:54,146] INFO Created log for partition [__consumer_offsets,20] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,147] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-09-22 13:22:54,153] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,156] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,156] INFO Partition [__consumer_offsets,39] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-22 13:22:54,166] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,166] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,166] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,166] INFO Created log for partition [__consumer_offsets,39] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,166] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,176] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-09-22 13:22:54,176] INFO Partition [__consumer_offsets,36] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-22 13:22:54,176] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,186] INFO Partition [__consumer_offsets,49] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-22 13:22:54,196] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,206] INFO Created log for partition [__consumer_offsets,17] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,206] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-09-22 13:22:54,206] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,216] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,216] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,216] INFO Partition [__consumer_offsets,33] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-22 13:22:54,226] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,236] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,239] INFO Created log for partition [__consumer_offsets,36] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,243] INFO Created log for partition [__consumer_offsets,49] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,245] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,247] INFO Partition [__consumer_offsets,11] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-22 13:22:54,248] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-09-22 13:22:54,253] INFO Partition [__consumer_offsets,49] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-09-22 13:22:54,265] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,268] INFO Created log for partition [__consumer_offsets,14] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,276] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-09-22 13:22:54,278] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,279] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,283] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,286] INFO Partition [__consumer_offsets,46] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-22 13:22:54,298] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,305] INFO Partition [__consumer_offsets,30] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-22 13:22:54,314] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,323] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,326] INFO Created log for partition [__consumer_offsets,33] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,328] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-09-22 13:22:54,343] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,346] INFO Partition [__consumer_offsets,8] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-22 13:22:54,362] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,364] INFO Created log for partition [__consumer_offsets,46] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,365] INFO Partition [__consumer_offsets,46] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-09-22 13:22:54,383] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,384] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,386] INFO Created log for partition [__consumer_offsets,11] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,389] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,392] INFO Partition [__consumer_offsets,27] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-22 13:22:54,393] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-09-22 13:22:54,400] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,404] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,409] INFO Partition [__consumer_offsets,43] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-22 13:22:54,413] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,416] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,419] INFO Partition [__consumer_offsets,24] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-22 13:22:54,423] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,429] INFO Created log for partition [__consumer_offsets,30] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,431] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-09-22 13:22:54,440] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,440] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,444] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,444] INFO Created log for partition [__consumer_offsets,43] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,447] INFO Partition [__consumer_offsets,43] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-09-22 13:22:54,450] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,446] INFO Partition [__consumer_offsets,5] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-22 13:22:54,454] INFO Created log for partition [__consumer_offsets,27] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,457] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-09-22 13:22:54,466] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,469] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,470] INFO Partition [__consumer_offsets,21] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-22 13:22:54,479] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,484] INFO Created log for partition [__consumer_offsets,8] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,486] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-09-22 13:22:54,488] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,488] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,488] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,488] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,488] INFO Partition [__consumer_offsets,2] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-22 13:22:54,498] INFO Partition [__consumer_offsets,40] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-22 13:22:54,498] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,508] INFO Created log for partition [__consumer_offsets,24] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,508] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-09-22 13:22:54,508] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,518] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,518] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,518] INFO Created log for partition [__consumer_offsets,40] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,518] INFO Partition [__consumer_offsets,37] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-22 13:22:54,528] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,529] INFO Partition [__consumer_offsets,40] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-09-22 13:22:54,538] INFO Created log for partition [__consumer_offsets,5] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,539] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-09-22 13:22:54,548] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,550] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,550] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,550] INFO Partition [__consumer_offsets,18] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-22 13:22:54,550] INFO Created log for partition [__consumer_offsets,37] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,560] INFO Partition [__consumer_offsets,37] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-09-22 13:22:54,560] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,560] INFO Created log for partition [__consumer_offsets,21] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,560] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-09-22 13:22:54,570] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,570] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,580] INFO Partition [__consumer_offsets,34] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-22 13:22:54,580] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,580] INFO Created log for partition [__consumer_offsets,34] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,590] INFO Partition [__consumer_offsets,34] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-09-22 13:22:54,600] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,610] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,610] INFO Partition [__consumer_offsets,15] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-22 13:22:54,620] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,622] INFO Created log for partition [__consumer_offsets,2] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,623] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-09-22 13:22:54,634] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,640] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,644] INFO Partition [__consumer_offsets,31] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-22 13:22:54,646] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,647] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,648] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,650] INFO Partition [__consumer_offsets,12] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-22 13:22:54,653] INFO Created log for partition [__consumer_offsets,18] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,654] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-09-22 13:22:54,670] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,673] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,675] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,679] INFO Partition [__consumer_offsets,47] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-22 13:22:54,688] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,693] INFO Created log for partition [__consumer_offsets,31] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,694] INFO Created log for partition [__consumer_offsets,15] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,703] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,734] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-09-22 13:22:54,735] INFO Partition [__consumer_offsets,31] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-09-22 13:22:54,737] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,746] INFO Partition [__consumer_offsets,19] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-22 13:22:54,775] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,780] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,785] INFO Created log for partition [__consumer_offsets,12] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,789] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-09-22 13:22:54,795] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,800] INFO Partition [__consumer_offsets,28] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-22 13:22:54,802] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,804] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,808] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-22 13:22:54,813] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,818] INFO Created log for partition [__consumer_offsets,9] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,823] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,827] INFO Partition [__consumer_offsets,9] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-09-22 13:22:54,827] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,833] INFO Partition [__consumer_offsets,38] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-22 13:22:54,839] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,844] INFO Created log for partition [__consumer_offsets,47] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,848] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,849] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-09-22 13:22:54,854] INFO Created log for partition [__consumer_offsets,19] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,855] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,857] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,859] INFO Partition [__consumer_offsets,19] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-09-22 13:22:54,860] INFO Partition [__consumer_offsets,35] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-22 13:22:54,882] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,882] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,884] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,884] INFO Created log for partition [__consumer_offsets,28] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,886] INFO Partition [__consumer_offsets,28] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-09-22 13:22:54,887] INFO Partition [__consumer_offsets,44] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-22 13:22:54,892] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,892] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,902] INFO Partition [__consumer_offsets,6] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-22 13:22:54,912] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,912] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,912] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,922] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,922] INFO Created log for partition [__consumer_offsets,38] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,922] INFO Partition [__consumer_offsets,25] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-22 13:22:54,922] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-09-22 13:22:54,932] INFO Created log for partition [__consumer_offsets,25] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,932] INFO Partition [__consumer_offsets,25] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-09-22 13:22:54,952] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,952] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,952] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,952] INFO Partition [__consumer_offsets,16] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-22 13:22:54,952] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,952] INFO Created log for partition [__consumer_offsets,35] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,962] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-09-22 13:22:54,962] INFO Created log for partition [__consumer_offsets,16] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,962] INFO Partition [__consumer_offsets,16] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-09-22 13:22:54,982] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,988] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:54,991] INFO Created log for partition [__consumer_offsets,44] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:54,994] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-09-22 13:22:54,996] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,016] INFO Partition [__consumer_offsets,22] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-22 13:22:55,033] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,037] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,038] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,040] INFO Partition [__consumer_offsets,41] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-22 13:22:55,046] INFO Created log for partition [__consumer_offsets,22] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,047] INFO Partition [__consumer_offsets,22] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-09-22 13:22:55,052] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,055] INFO Created log for partition [__consumer_offsets,6] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,065] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,065] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,068] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-09-22 13:22:55,071] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,073] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,074] INFO Partition [__consumer_offsets,32] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-22 13:22:55,078] INFO Partition [__consumer_offsets,3] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-22 13:22:55,098] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,104] INFO Created log for partition [__consumer_offsets,41] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,105] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-09-22 13:22:55,123] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,126] INFO Created log for partition [__consumer_offsets,32] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,128] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,135] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-09-22 13:22:55,137] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs2 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,146] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,148] INFO Created log for partition [__consumer_offsets,13] in D:\tmp\kafka-logs1 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,149] INFO Partition [__consumer_offsets,13] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-22 13:22:55,152] INFO Partition [__consumer_offsets,13] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-09-22 13:22:55,155] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,31],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,19],[__consumer_offsets,22],[__consumer_offsets,10],[__consumer_offsets,36],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,40],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,3],[__consumer_offsets,18],[__consumer_offsets,42],[__consumer_offsets,4],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,1],[__consumer_offsets,13],[__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:55,164] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,2],[__consumer_offsets,7],[__consumer_offsets,38],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,11],[__consumer_offsets,22],[__consumer_offsets,26],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,34],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,40],[__consumer_offsets,47],[__consumer_offsets,43],[__consumer_offsets,25],[__consumer_offsets,46],[__consumer_offsets,28],[__consumer_offsets,37],[__consumer_offsets,5],[__consumer_offsets,14],[__consumer_offsets,41],[__consumer_offsets,4],[__consumer_offsets,1],[__consumer_offsets,32],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:55,182] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,194] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,224] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,224] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,224] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,234] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,234] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,234] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-09-22 13:22:55,234] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,234] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,234] INFO Created log for partition [__consumer_offsets,3] in D:\tmp\kafka-logs0 with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-09-22 13:22:55,234] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,234] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-09-22 13:22:55,244] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,244] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,244] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,2],[__consumer_offsets,39],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,38],[__consumer_offsets,9],[__consumer_offsets,48],[__consumer_offsets,24],[__consumer_offsets,11],[__consumer_offsets,26],[__consumer_offsets,17],[__consumer_offsets,35],[__consumer_offsets,36],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,47],[__consumer_offsets,27],[__consumer_offsets,45],[__consumer_offsets,6],[__consumer_offsets,5],[__consumer_offsets,3],[__consumer_offsets,14],[__consumer_offsets,18],[__consumer_offsets,41],[__consumer_offsets,42],[__consumer_offsets,12],[__consumer_offsets,21],[__consumer_offsets,30],[__consumer_offsets,32],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,0],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:55,244] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,244] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,254] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,254] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,254] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,254] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,264] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,264] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,264] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,264] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,264] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,264] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,274] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,274] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,274] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,274] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,274] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,284] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,294] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,294] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,294] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,294] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,294] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,294] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,304] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,304] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,304] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,304] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,314] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,314] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,314] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,324] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,324] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,324] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,324] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,324] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,324] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,324] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,334] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,334] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,334] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,334] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,334] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,334] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,334] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,344] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,344] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,344] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,344] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,344] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,354] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,354] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,354] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,364] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,374] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,374] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,384] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,384] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,384] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,384] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,384] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,384] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,384] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,394] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,394] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,394] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,404] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,404] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,404] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,404] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,454] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,454] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,454] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 13:22:55,454] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-09-22 13:22:55,494] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 13:22:55,534] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 13:22:55,554] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 13:22:55,564] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:55,584] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,584] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:55,596] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 12 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,601] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,610] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,614] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,621] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] , [[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,26], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 13:22:55,623] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,627] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,630] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,631] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,642] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,643] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,647] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,648] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,630] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 13:22:55,651] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,681] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,684] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,681] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 13:22:55,702] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,716] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,715] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,722] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,739] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 15 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,740] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,754] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,759] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,759] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,779] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,785] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,790] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,790] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,803] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,0] in 21 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,805] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,2] in 19 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,806] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,807] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,810] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,3] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,810] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,812] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,818] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,830] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,840] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 29 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,841] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,844] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,845] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,851] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,853] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,6] in 11 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,856] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,861] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,862] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,865] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,866] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,868] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,870] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,12] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,873] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,876] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,11] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,877] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,15] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,879] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,880] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,883] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,14] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,886] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,886] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,18] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,886] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,886] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,17] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,886] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,886] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,21] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,896] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,896] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,20] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,896] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,896] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,24] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,896] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,906] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,23] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,906] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,906] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,27] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,906] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,916] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,26] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,916] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,30] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,916] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,916] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,916] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,33] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,916] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,29] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,926] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,926] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,926] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,36] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,926] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,32] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,936] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,936] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,936] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,39] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,936] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,35] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,936] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,936] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,946] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,42] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,946] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,38] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,946] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,946] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,956] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,45] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,956] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,41] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,956] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,956] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,956] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,44] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,966] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,48] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,966] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,966] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,47] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:22:55,986] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:22:55,996] INFO [GroupCoordinator 1]: Stabilized group my-first-streams-application2 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:22:56,026] INFO [GroupCoordinator 1]: Assignment received from leader for group my-first-streams-application2 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:23:59,464] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:23:59,484] INFO [GroupCoordinator 1]: Group my-first-streams-application2 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:25:18,980] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:25:18,981] INFO [GroupCoordinator 1]: Stabilized group my-first-streams-application2 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:25:19,025] INFO [GroupCoordinator 1]: Assignment received from leader for group my-first-streams-application2 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 13:30:01,561] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:30:45,280] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:31:20,568] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:40:01,581] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:40:45,291] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:41:20,581] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:50:01,587] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:50:45,313] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 13:51:20,589] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:00:01,606] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:00:45,318] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:01:20,604] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:10:01,612] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:10:45,331] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:11:20,620] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:20:01,625] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:20:45,346] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:21:20,626] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:30:01,635] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:30:45,353] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:31:20,638] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:40:01,647] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:40:45,367] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:41:20,651] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:50:01,659] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:50:45,378] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 14:51:20,663] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:00:01,672] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:00:45,390] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:01:20,675] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:10:01,684] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:10:45,403] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:11:20,688] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:20:01,696] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:20:45,414] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:21:20,700] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:30:01,709] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:30:45,427] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:31:20,712] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:40:01,721] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:40:45,440] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:41:20,725] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:50:01,733] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:50:45,452] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 15:51:20,737] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:00:01,746] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:00:45,464] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:01:20,749] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:10:01,758] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:10:45,477] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:11:20,762] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:20:01,770] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:20:45,489] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:21:20,774] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:28:09,378] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:28:09,383] INFO [GroupCoordinator 1]: Group my-first-streams-application2 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:28:32,114] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:28:32,115] INFO [GroupCoordinator 1]: Stabilized group my-first-streams-application2 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:28:32,169] INFO [GroupCoordinator 1]: Assignment received from leader for group my-first-streams-application2 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:30:01,783] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:30:45,501] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:31:20,791] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:32:59,255] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:32:59,255] INFO [GroupCoordinator 1]: Group my-first-streams-application2 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:40:01,802] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:40:17,813] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:40:17,813] INFO [GroupCoordinator 1]: Stabilized group my-first-streams-application2 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:40:17,860] INFO [GroupCoordinator 1]: Assignment received from leader for group my-first-streams-application2 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 16:40:45,519] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:41:20,807] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:50:01,808] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:50:45,526] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 16:51:20,810] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:20,510] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:23,874] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:23,874] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:23,874] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:23,884] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:23,884] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:24,287] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:24,287] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:24,549] INFO [GroupCoordinator 1]: Group my-first-streams-application2 generation 1 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:24,557] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:24,585] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:24,585] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:24,585] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:24,585] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:20,600] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:27,186] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:27,186] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:27,186] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:27,186] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:27,186] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:52:28,215] WARN Attempting to send response via channel for which there is no open connection, connection id 1 (kafka.network.Processor)
[2016-09-22 17:52:28,485] WARN Attempting to send response via channel for which there is no open connection, connection id 2 (kafka.network.Processor)
[2016-09-22 17:52:28,495] WARN Attempting to send response via channel for which there is no open connection, connection id 1 (kafka.network.Processor)
[2016-09-22 17:52:30,345] WARN Attempting to send response via channel for which there is no open connection, connection id 1 (kafka.network.Processor)
[2016-09-22 17:52:28,995] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@b758a89 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 17:52:29,015] INFO Partition [__consumer_offsets,33] on broker 2: Shrinking ISR for partition [__consumer_offsets,33] from 2,1,0 to 2 (kafka.cluster.Partition)
[2016-09-22 17:52:28,995] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@250369c0 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 17:52:30,665] INFO Partition [__consumer_offsets,14] on broker 1: Shrinking ISR for partition [__consumer_offsets,14] from 1,2,0 to 1 (kafka.cluster.Partition)
[2016-09-22 17:52:31,025] WARN [ReplicaFetcherThread-0-2], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@25a038c5 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 17:52:31,025] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@6bf16112 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 17:52:34,635] WARN Attempting to send response via channel for which there is no open connection, connection id 0 (kafka.network.Processor)
[2016-09-22 17:52:34,745] WARN Attempting to send response via channel for which there is no open connection, connection id 1 (kafka.network.Processor)
[2016-09-22 17:52:36,085] INFO Partition [__consumer_offsets,37] on broker 0: Shrinking ISR for partition [__consumer_offsets,37] from 0,1,2 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:37,925] WARN [ReplicaFetcherThread-0-2], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@d6dde25 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 17:52:37,965] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@2df8a978 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 17:52:38,765] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 0 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:38,765] INFO [GroupCoordinator 1]: Stabilized group my-first-streams-application2 generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:38,785] INFO [GroupCoordinator 1]: Assignment received from leader for group my-first-streams-application2 for generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:40,487] INFO Partition [__consumer_offsets,2] on broker 1: Shrinking ISR for partition [__consumer_offsets,2] from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:40,527] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:52:40,547] INFO Partition [__consumer_offsets,32] on broker 1: Shrinking ISR for partition [__consumer_offsets,32] from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:40,587] INFO Partition [__consumer_offsets,29] on broker 1: Shrinking ISR for partition [__consumer_offsets,29] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:40,617] INFO Partition [__consumer_offsets,5] on broker 1: Shrinking ISR for partition [__consumer_offsets,5] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:40,637] INFO Partition [__consumer_offsets,11] on broker 1: Shrinking ISR for partition [__consumer_offsets,11] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:40,687] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:52:40,687] INFO Partition [__consumer_offsets,47] on broker 1: Shrinking ISR for partition [__consumer_offsets,47] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:40,727] INFO Partition [__consumer_offsets,44] on broker 1: Shrinking ISR for partition [__consumer_offsets,44] from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:41,017] INFO Partition [__consumer_offsets,0] on broker 2: Shrinking ISR for partition [__consumer_offsets,0] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:41,027] INFO Partition [__consumer_offsets,17] on broker 1: Shrinking ISR for partition [__consumer_offsets,17] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:41,057] INFO Partition [__consumer_offsets,12] on broker 2: Shrinking ISR for partition [__consumer_offsets,12] from 2,0,1 to 2 (kafka.cluster.Partition)
[2016-09-22 17:52:41,087] INFO Partition [__consumer_offsets,20] on broker 1: Shrinking ISR for partition [__consumer_offsets,20] from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:41,127] INFO Partition [__consumer_offsets,24] on broker 2: Shrinking ISR for partition [__consumer_offsets,24] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:41,147] INFO Partition [__consumer_offsets,23] on broker 1: Shrinking ISR for partition [__consumer_offsets,23] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:41,797] INFO 1 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 17:52:41,797] INFO Partition [__consumer_offsets,14] on broker 1: Expanding ISR for partition [__consumer_offsets,14] from 1 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:41,977] INFO Partition [__consumer_offsets,33] on broker 2: Expanding ISR for partition [__consumer_offsets,33] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:42,877] INFO Partition [__consumer_offsets,32] on broker 1: Expanding ISR for partition [__consumer_offsets,32] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:44,109] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 1 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:44,189] INFO [GroupCoordinator 1]: Stabilized group my-first-streams-application2 generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:44,339] INFO [GroupCoordinator 1]: Assignment received from leader for group my-first-streams-application2 for generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:52:45,213] INFO Partition [__consumer_offsets,48] on broker 2: Shrinking ISR for partition [__consumer_offsets,48] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,213] INFO Partition [__consumer_offsets,12] on broker 2: Expanding ISR for partition [__consumer_offsets,12] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,213] INFO Partition [__consumer_offsets,24] on broker 2: Expanding ISR for partition [__consumer_offsets,24] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,213] INFO Partition [__consumer_offsets,44] on broker 1: Expanding ISR for partition [__consumer_offsets,44] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,223] INFO Partition [__consumer_offsets,15] on broker 2: Shrinking ISR for partition [__consumer_offsets,15] from 2,1,0 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,233] INFO Partition [__consumer_offsets,0] on broker 2: Expanding ISR for partition [__consumer_offsets,0] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,263] INFO Partition [__consumer_offsets,26] on broker 1: Shrinking ISR for partition [__consumer_offsets,26] from 1,2,0 to 1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,413] INFO Partition [__consumer_offsets,42] on broker 2: Shrinking ISR for partition [__consumer_offsets,42] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,423] INFO Partition [__consumer_offsets,15] on broker 2: Expanding ISR for partition [__consumer_offsets,15] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,433] INFO Partition [__consumer_offsets,18] on broker 2: Shrinking ISR for partition [__consumer_offsets,18] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,503] INFO Partition [__consumer_offsets,33] on broker 2: Expanding ISR for partition [__consumer_offsets,33] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,523] INFO Partition [__consumer_offsets,17] on broker 1: Expanding ISR for partition [__consumer_offsets,17] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,523] INFO Partition [__consumer_offsets,38] on broker 1: Shrinking ISR for partition [__consumer_offsets,38] from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:45,533] INFO Partition [__consumer_offsets,6] on broker 2: Shrinking ISR for partition [__consumer_offsets,6] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,563] INFO Partition [__consumer_offsets,35] on broker 1: Shrinking ISR for partition [__consumer_offsets,35] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:45,563] INFO Partition [__consumer_offsets,9] on broker 2: Shrinking ISR for partition [__consumer_offsets,9] from 2,1,0 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,573] INFO Partition [__consumer_offsets,6] on broker 2: Expanding ISR for partition [__consumer_offsets,6] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,583] INFO Partition [__consumer_offsets,23] on broker 1: Expanding ISR for partition [__consumer_offsets,23] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,589] INFO Partition [__consumer_offsets,41] on broker 1: Shrinking ISR for partition [__consumer_offsets,41] from 1,0,2 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:45,615] INFO Partition [__consumer_offsets,27] on broker 2: Shrinking ISR for partition [__consumer_offsets,27] from 2,1,0 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:45,615] INFO Partition [__consumer_offsets,29] on broker 1: Expanding ISR for partition [__consumer_offsets,29] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,675] INFO Partition [__consumer_offsets,8] on broker 1: Shrinking ISR for partition [__consumer_offsets,8] from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:45,695] INFO Partition [__consumer_offsets,35] on broker 1: Expanding ISR for partition [__consumer_offsets,35] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:45,915] INFO Partition [__consumer_offsets,41] on broker 1: Expanding ISR for partition [__consumer_offsets,41] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,015] INFO Partition [__consumer_offsets,38] on broker 1: Expanding ISR for partition [__consumer_offsets,38] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,055] INFO Partition [__consumer_offsets,8] on broker 1: Expanding ISR for partition [__consumer_offsets,8] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,285] INFO Partition [__consumer_offsets,5] on broker 1: Expanding ISR for partition [__consumer_offsets,5] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,305] INFO Partition [__consumer_offsets,11] on broker 1: Expanding ISR for partition [__consumer_offsets,11] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,345] INFO Partition [__consumer_offsets,46] on broker 0: Shrinking ISR for partition [__consumer_offsets,46] from 0,2,1 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,345] INFO Partition [__consumer_offsets,37] on broker 0: Expanding ISR for partition [__consumer_offsets,37] from 0 to 0,2 (kafka.cluster.Partition)
[2016-09-22 17:52:46,355] INFO Partition [__consumer_offsets,20] on broker 1: Expanding ISR for partition [__consumer_offsets,20] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,445] INFO Partition [__consumer_offsets,31] on broker 0: Shrinking ISR for partition [__consumer_offsets,31] from 0,1,2 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,445] INFO Partition [__consumer_offsets,37] on broker 0: Expanding ISR for partition [__consumer_offsets,37] from 0,2 to 0,2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:46,575] INFO Partition [__consumer_offsets,47] on broker 1: Expanding ISR for partition [__consumer_offsets,47] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,595] INFO Partition [__consumer_offsets,2] on broker 1: Expanding ISR for partition [__consumer_offsets,2] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,615] INFO Partition [__consumer_offsets,1] on broker 0: Shrinking ISR for partition [__consumer_offsets,1] from 0,1,2 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,615] INFO Partition [__consumer_offsets,31] on broker 0: Expanding ISR for partition [__consumer_offsets,31] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:46,645] INFO Partition [__consumer_offsets,14] on broker 1: Expanding ISR for partition [__consumer_offsets,14] from 1,2 to 1,2,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,645] INFO Partition [__consumer_offsets,30] on broker 2: Shrinking ISR for partition [__consumer_offsets,30] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 17:52:46,645] INFO Partition [__consumer_offsets,27] on broker 2: Expanding ISR for partition [__consumer_offsets,27] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,885] INFO Partition [__consumer_offsets,43] on broker 0: Shrinking ISR for partition [__consumer_offsets,43] from 0,1,2 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,895] INFO Partition [__consumer_offsets,46] on broker 0: Expanding ISR for partition [__consumer_offsets,46] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:46,895] INFO Partition [__consumer_offsets,31] on broker 0: Expanding ISR for partition [__consumer_offsets,31] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:46,915] INFO Partition [__consumer_offsets,26] on broker 1: Expanding ISR for partition [__consumer_offsets,26] from 1 to 1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:46,925] INFO Partition [__consumer_offsets,9] on broker 2: Expanding ISR for partition [__consumer_offsets,9] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:47,075] INFO Partition [__consumer_offsets,19] on broker 0: Shrinking ISR for partition [__consumer_offsets,19] from 0,1,2 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:47,125] INFO Partition [__consumer_offsets,26] on broker 1: Expanding ISR for partition [__consumer_offsets,26] from 1,0 to 1,0,2 (kafka.cluster.Partition)
[2016-09-22 17:52:47,475] INFO Partition [__consumer_offsets,42] on broker 2: Expanding ISR for partition [__consumer_offsets,42] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:47,545] INFO Partition [__consumer_offsets,48] on broker 2: Expanding ISR for partition [__consumer_offsets,48] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:47,585] INFO Partition [__consumer_offsets,18] on broker 2: Expanding ISR for partition [__consumer_offsets,18] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:47,805] INFO Partition [__consumer_offsets,12] on broker 2: Expanding ISR for partition [__consumer_offsets,12] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:47,825] INFO Partition [__consumer_offsets,30] on broker 2: Expanding ISR for partition [__consumer_offsets,30] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 17:52:48,385] INFO re-registering broker info in ZK for broker 2 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:52:48,455] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:52:48,915] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:52:49,125] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9094,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 17:52:49,938] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:52:49,957] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:52:51,077] INFO New leader is 1 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 17:52:51,187] INFO Partition [__consumer_offsets,43] on broker 0: Expanding ISR for partition [__consumer_offsets,43] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:53,163] INFO Partition [__consumer_offsets,37] on broker 0: Shrinking ISR for partition [__consumer_offsets,37] from 0,2,1 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,163] INFO Partition [__consumer_offsets,19] on broker 0: Expanding ISR for partition [__consumer_offsets,19] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:53,167] INFO Partition [__consumer_offsets,1] on broker 0: Expanding ISR for partition [__consumer_offsets,1] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:53,193] INFO Partition [__consumer_offsets,40] on broker 0: Shrinking ISR for partition [__consumer_offsets,40] from 0,2,1 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,194] INFO Partition [__consumer_offsets,46] on broker 0: Expanding ISR for partition [__consumer_offsets,46] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:53,274] INFO Partition [__consumer_offsets,43] on broker 0: Expanding ISR for partition [__consumer_offsets,43] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:53,274] INFO Partition [__consumer_offsets,16] on broker 0: Shrinking ISR for partition [__consumer_offsets,16] from 0,2,1 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,385] INFO Partition [__consumer_offsets,1] on broker 0: Expanding ISR for partition [__consumer_offsets,1] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:53,385] INFO Partition [__consumer_offsets,49] on broker 0: Shrinking ISR for partition [__consumer_offsets,49] from 0,1,2 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,437] INFO Partition [__consumer_offsets,13] on broker 0: Shrinking ISR for partition [__consumer_offsets,13] from 0,1,2 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,461] INFO Partition [__consumer_offsets,7] on broker 0: Shrinking ISR for partition [__consumer_offsets,7] from 0,1,2 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,530] INFO Partition [__consumer_offsets,4] on broker 0: Shrinking ISR for partition [__consumer_offsets,4] from 0,2,1 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,540] INFO Partition [__consumer_offsets,28] on broker 0: Shrinking ISR for partition [__consumer_offsets,28] from 0,2,1 to 0 (kafka.cluster.Partition)
[2016-09-22 17:52:53,735] INFO Partition [__consumer_offsets,16] on broker 0: Expanding ISR for partition [__consumer_offsets,16] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:53,890] INFO Partition [__consumer_offsets,49] on broker 0: Expanding ISR for partition [__consumer_offsets,49] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:53,895] INFO Partition [__consumer_offsets,28] on broker 0: Expanding ISR for partition [__consumer_offsets,28] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:53,904] INFO Partition [__consumer_offsets,16] on broker 0: Expanding ISR for partition [__consumer_offsets,16] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:53,906] INFO Partition [__consumer_offsets,7] on broker 0: Expanding ISR for partition [__consumer_offsets,7] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:53,922] INFO Partition [__consumer_offsets,49] on broker 0: Expanding ISR for partition [__consumer_offsets,49] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:53,948] INFO Partition [__consumer_offsets,4] on broker 0: Expanding ISR for partition [__consumer_offsets,4] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:53,980] INFO Partition [__consumer_offsets,28] on broker 0: Expanding ISR for partition [__consumer_offsets,28] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:54,042] INFO Partition [__consumer_offsets,13] on broker 0: Expanding ISR for partition [__consumer_offsets,13] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:54,144] INFO Partition [__consumer_offsets,7] on broker 0: Expanding ISR for partition [__consumer_offsets,7] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:54,156] INFO Partition [__consumer_offsets,40] on broker 0: Expanding ISR for partition [__consumer_offsets,40] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:54,189] INFO Partition [__consumer_offsets,4] on broker 0: Expanding ISR for partition [__consumer_offsets,4] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:54,728] INFO Partition [__consumer_offsets,37] on broker 0: Expanding ISR for partition [__consumer_offsets,37] from 0 to 0,1 (kafka.cluster.Partition)
[2016-09-22 17:52:54,880] INFO Partition [__consumer_offsets,13] on broker 0: Expanding ISR for partition [__consumer_offsets,13] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:54,881] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:52:55,050] INFO Partition [__consumer_offsets,40] on broker 0: Expanding ISR for partition [__consumer_offsets,40] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:55,147] INFO Partition [__consumer_offsets,37] on broker 0: Expanding ISR for partition [__consumer_offsets,37] from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2016-09-22 17:52:55,974] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:52:56,885] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:52:56,888] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 17:52:56,890] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:52:56,891] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:53:01,772] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:53:01,812] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:53:01,813] INFO 2 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 17:53:02,443] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 17:53:02,599] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 17:53:06,138] INFO re-registering broker info in ZK for broker 1 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:53:06,138] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:53:06,178] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 17:53:06,178] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 17:53:06,188] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:53:06,188] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 17:53:06,208] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 17:53:06,588] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,5],[__consumer_offsets,11],[__consumer_offsets,47] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:06,648] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,2],[__consumer_offsets,38],[__consumer_offsets,44],[__consumer_offsets,32],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:06,668] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,688] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,688] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,708] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,708] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,708] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,708] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,688] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,44],[__consumer_offsets,38],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:06,718] INFO Truncating log __consumer_offsets-26 to offset 14. (kafka.log.Log)
[2016-09-22 17:53:06,728] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 17:53:06,738] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,35],[__consumer_offsets,23],[__consumer_offsets,47],[__consumer_offsets,11],[__consumer_offsets,5],[__consumer_offsets,17],[__consumer_offsets,41],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:06,738] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,738] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,738] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,748] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,26], initOffset 14 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:06,748] INFO [ReplicaFetcherThread-0-1], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:06,758] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,758] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,758] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,758] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,768] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:06,798] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:07,008] INFO [ReplicaFetcherThread-0-1], Stopped  (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:07,008] INFO [ReplicaFetcherThread-0-1], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:07,068] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,078] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,078] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,088] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,088] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,118] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 30 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,118] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,118] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,118] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,128] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,128] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,128] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,128] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,138] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,138] INFO [ReplicaFetcherThread-0-1], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:07,138] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,138] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,178] INFO [ReplicaFetcherThread-0-1], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:07,178] INFO [ReplicaFetcherThread-0-1], Stopped  (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:07,468] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,498] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,44] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,498] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,498] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,2] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,508] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,518] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,2],[__consumer_offsets,35],[__consumer_offsets,44],[__consumer_offsets,23],[__consumer_offsets,47],[__consumer_offsets,5],[__consumer_offsets,14],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,32],[__consumer_offsets,11],[__consumer_offsets,8],[__consumer_offsets,20],[__consumer_offsets,26],[__consumer_offsets,17],[__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:07,518] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,518] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,518] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,518] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,518] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,8] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,518] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,528] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,528] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,528] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,14] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,538] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,538] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,538] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,538] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,20] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,538] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,548] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,548] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,558] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,558] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,558] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,558] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,558] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:07,558] INFO Truncating log __consumer_offsets-26 to offset 14. (kafka.log.Log)
[2016-09-22 17:53:07,588] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(0,localhost,9092)] , [[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,26], initOffset 14 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:07,588] INFO [GroupCoordinator 1]: Unloading group metadata for my-first-streams-application2 with generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:53:07,618] INFO [Group Metadata Manager on Broker 1]: Removed 1 cached offsets for [__consumer_offsets,26] on follower transition. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,618] INFO [Group Metadata Manager on Broker 1]: Removed 1 cached groups for [__consumer_offsets,26] on follower transition. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,745] INFO [GroupCoordinator 2]: Loading group metadata for my-first-streams-application2 with generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:53:07,805] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,26] in 257 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,805] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,820] INFO Partition [__consumer_offsets,32] on broker 2: Expanding ISR for partition [__consumer_offsets,32] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:07,837] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,32] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,847] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,857] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,38] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:07,867] INFO Partition [__consumer_offsets,44] on broker 2: Expanding ISR for partition [__consumer_offsets,44] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:07,937] INFO Partition [__consumer_offsets,38] on broker 2: Expanding ISR for partition [__consumer_offsets,38] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:07,957] INFO Partition [__consumer_offsets,8] on broker 2: Expanding ISR for partition [__consumer_offsets,8] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,027] INFO Partition [__consumer_offsets,17] on broker 0: Expanding ISR for partition [__consumer_offsets,17] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,037] INFO Partition [__consumer_offsets,20] on broker 2: Expanding ISR for partition [__consumer_offsets,20] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,037] INFO Partition [__consumer_offsets,23] on broker 0: Expanding ISR for partition [__consumer_offsets,23] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,047] INFO Partition [__consumer_offsets,2] on broker 2: Expanding ISR for partition [__consumer_offsets,2] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,057] INFO Partition [__consumer_offsets,14] on broker 2: Expanding ISR for partition [__consumer_offsets,14] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,057] INFO Partition [__consumer_offsets,29] on broker 0: Expanding ISR for partition [__consumer_offsets,29] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,067] INFO Partition [__consumer_offsets,26] on broker 2: Expanding ISR for partition [__consumer_offsets,26] from 0,2 to 0,2,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,087] INFO Partition [__consumer_offsets,35] on broker 0: Expanding ISR for partition [__consumer_offsets,35] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,107] INFO Partition [__consumer_offsets,41] on broker 0: Expanding ISR for partition [__consumer_offsets,41] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,167] INFO Partition [__consumer_offsets,5] on broker 0: Expanding ISR for partition [__consumer_offsets,5] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,187] INFO Partition [__consumer_offsets,11] on broker 0: Expanding ISR for partition [__consumer_offsets,11] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:08,197] INFO Partition [__consumer_offsets,47] on broker 0: Expanding ISR for partition [__consumer_offsets,47] from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2016-09-22 17:53:11,770] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,47] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:11,770] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,47] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:11,780] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:11,790] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,47] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:11,790] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:11,800] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:11,930] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,47] in 140 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:11,940] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:11,940] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:11,950] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,29] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:11,960] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:11,960] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:11,970] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:11,970] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,000] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,010] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,41] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,010] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,030] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,41] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,030] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,040] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,47], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,040] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-09-22 17:53:12,040] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,040] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,140] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,140] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,17] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,140] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,150] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,17] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,160] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,29], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,170] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,41] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,170] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,180] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,190] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,41] in 130 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,190] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,190] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,14] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,210] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,41], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,210] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,17] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,220] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,220] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,14] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,230] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,17] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,230] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,230] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,240] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,14] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,240] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,20] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,240] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,250] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,260] INFO [GroupCoordinator 1]: Loading group metadata for my-first-streams-application2 with generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:53:12,260] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,26] in 20 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,260] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,280] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,20] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,290] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,17], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,290] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,5] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,290] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,290] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,14] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,290] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,300] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,5] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,310] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,8] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,310] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,310] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,330] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,14], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,340] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,340] INFO Truncating log __consumer_offsets-26 to offset 14. (kafka.log.Log)
[2016-09-22 17:53:12,370] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,8] in 30 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,380] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,26], initOffset 14 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,380] INFO [GroupCoordinator 2]: Unloading group metadata for my-first-streams-application2 with generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-22 17:53:12,380] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,20] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,380] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,23] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,380] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,380] INFO Truncating log __consumer_offsets-26 to offset 14. (kafka.log.Log)
[2016-09-22 17:53:12,390] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,390] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,23] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,410] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,420] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,26], initOffset 14 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,420] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,11] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,430] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,430] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,20] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,430] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,440] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,480] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,5] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,480] INFO [Group Metadata Manager on Broker 2]: Removed 1 cached offsets for [__consumer_offsets,26] on follower transition. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,490] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,20], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,490] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,5] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,490] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,500] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,11] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,500] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,44] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,500] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,500] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,520] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,44] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,530] INFO [Group Metadata Manager on Broker 2]: Removed 1 cached groups for [__consumer_offsets,26] on follower transition. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,530] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,32] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,540] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,540] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,550] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,32] in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,550] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,5], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,560] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,8] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,560] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,590] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,8] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,590] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,600] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,620] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,23] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,630] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,8], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,630] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,650] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,23] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,750] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,760] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,35] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,760] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,780] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,790] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,35] in 20 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,790] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,11] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,818] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,23], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,827] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,830] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,11] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,831] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,874] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,38] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,884] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,894] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,894] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,11], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,904] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,2] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,904] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,38] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,904] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,914] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,44] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,914] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,914] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,2] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 17:53:12,914] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,44] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,914] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:12,934] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,954] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,44], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,954] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:12,954] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,014] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,034] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,32] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,064] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,067] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,35] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,072] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,32], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,072] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,082] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,35] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,082] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,129] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,129] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,35], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,139] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,38] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,139] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,139] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,38] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,139] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,149] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,159] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,38], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,169] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,2] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,179] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,179] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,2] (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,179] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[2016-09-22 17:53:13,210] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 17:53:13,210] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,2], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:00:02,670] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:00:46,389] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:01:21,674] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:10:02,682] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:10:46,401] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:11:21,686] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:20:02,695] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:20:46,413] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:21:21,703] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:30:02,707] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:30:46,425] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:31:21,710] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:40:02,719] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:40:46,437] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:41:21,722] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:50:02,731] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:50:46,450] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:51:21,736] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:54:58,641] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:54:59,006] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:54:59,007] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 18:55:02,427] INFO re-registering broker info in ZK for broker 2 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:02,706] INFO re-registering broker info in ZK for broker 1 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:03,028] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:55:03,128] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:55:06,106] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:55:06,108] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:55:06,108] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9094,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 18:55:06,109] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 18:55:06,109] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:06,112] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:06,121] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:06,123] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:06,243] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 18:55:06,958] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 18:55:15,090] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:15,108] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:55:16,068] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:55:16,070] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 18:55:16,070] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:16,071] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:55:16,098] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 18:55:22,457] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [Text9,0],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,0],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,9],[__consumer_offsets,42],[__consumer_offsets,48],[__consumer_offsets,18],[__consumer_offsets,12],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:22,495] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,28],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,13],[__consumer_offsets,40],[__consumer_offsets,37],[__consumer_offsets,34],[__consumer_offsets,22],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:22,596] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:24,418] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:24,419] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:24,453] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:24,748] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:25,211] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:25,213] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-09-22 18:55:29,021] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-09-22 18:55:40,185] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,43] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:40,333] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:40,417] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,43] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:40,437] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:40,736] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,43], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:40,995] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,43] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:41,986] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:44,448] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,43] in 2461 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:44,987] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,14] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:45,008] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,43] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:47,056] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,14] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,112] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,28] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,113] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:47,144] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,28], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,155] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,4] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,157] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:47,174] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,4], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,178] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,514] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,594] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,610] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,615] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,645] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,657] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,670] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,28] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,674] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:47,686] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,4] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,697] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,811] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,4] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:47,826] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,28] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:47,830] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,23] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,836] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,868] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,875] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,38] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,881] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,16] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,881] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:47,920] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,16], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,926] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,975] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,986] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:47,999] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,36] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,007] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,6] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,014] INFO Partition [__consumer_offsets,36] on broker 2: Expanding ISR for partition [__consumer_offsets,36] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 18:55:48,016] INFO Partition [__consumer_offsets,23] on broker 1: Expanding ISR for partition [__consumer_offsets,23] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 18:55:48,016] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,017] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,39] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,069] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,10] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,070] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:48,109] INFO Partition [__consumer_offsets,38] on broker 1: Expanding ISR for partition [__consumer_offsets,38] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 18:55:48,109] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,10], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,115] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,40] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,116] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:48,126] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,40], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,130] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,34] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,135] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:48,158] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,34], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,320] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,337] INFO Partition [__consumer_offsets,6] on broker 2: Expanding ISR for partition [__consumer_offsets,6] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-09-22 18:55:48,451] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,757] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,25] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:48,761] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:48,771] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,25] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:48,773] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,162] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,14] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,166] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,28] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,168] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:49,355] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,362] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,370] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,4] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,370] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:49,397] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,399] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,36] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,399] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,11] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,499] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,36] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,500] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,7] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,501] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,6] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,502] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:49,505] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,47] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,505] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,6] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,508] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,39] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,510] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,513] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,39] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,515] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,23] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,517] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,23] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,519] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,24] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,523] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,24] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,527] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,38] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,530] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,38] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,533] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,16] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,533] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:49,563] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,566] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,3] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,568] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,3] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,570] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,21] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,574] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,21] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,576] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,10] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,576] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:49,598] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,40] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,599] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:49,634] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,34] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,635] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:49,666] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,25] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,666] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:49,680] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,27] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,683] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,27] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,685] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,42] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,688] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,42] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,695] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,11] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,698] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,11] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,701] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,7] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:49,702] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:50,359] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,47] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:50,368] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,47] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:50,578] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,9] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:50,962] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,9] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:50,965] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,13] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:50,967] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:51,057] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,059] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,29] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,062] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,8] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,066] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,8] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,068] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,22] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,069] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:51,138] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,31] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,138] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:51,153] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,18] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,157] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,18] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,159] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,20] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,163] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,20] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,165] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,37] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,166] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:51,177] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,49] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,177] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:51,879] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,12] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,882] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,12] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,884] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,5] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,889] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,5] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,891] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,895] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,897] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,2] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,900] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,2] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,989] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:51,991] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:52,294] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,306] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,337] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,15] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,400] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,15] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,405] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,44] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,552] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,28] in 4764 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:52,559] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:52,587] INFO Partition [__consumer_offsets,4] on broker 2: Shrinking ISR for partition [__consumer_offsets,4] from 1,2 to 2 (kafka.cluster.Partition)
[2016-09-22 18:55:52,629] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,4] in 68 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:52,663] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,24] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,666] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,44] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,683] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,17] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,694] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,747] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,17] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,772] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,780] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,16] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,873] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:52,877] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,3] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:52,881] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,21] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:53,716] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,16] in 842 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:54,071] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,10] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,084] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:54,167] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,48] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,170] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,40] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,174] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,48] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,179] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,34] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,179] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,183] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,185] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,33] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,188] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,33] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,190] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,41] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,194] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,41] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,196] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,45] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,199] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,45] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,201] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,35] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:54,202] INFO [ReplicaFetcherThread-0-1], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:54,271] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,10] in 185 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:54,327] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:55,086] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,25] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:55,088] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,40] in 758 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:55,592] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:55,594] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:55,828] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,25], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:55,828] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,34] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:55,830] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,27] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:55,835] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,42] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:55,851] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:55,888] ERROR [ReplicaFetcherThread-0-0], Error for partition [__consumer_offsets,22] to broker 0:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:55,889] ERROR [ReplicaFetcherThread-0-0], Error for partition [__consumer_offsets,13] to broker 0:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:55,889] ERROR [ReplicaFetcherThread-0-0], Error for partition [__consumer_offsets,49] to broker 0:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:56,006] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,137] ERROR [ReplicaFetcherThread-0-0], Error for partition [__consumer_offsets,31] to broker 0:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:56,138] ERROR [ReplicaFetcherThread-0-0], Error for partition [__consumer_offsets,37] to broker 0:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:56,141] ERROR [ReplicaFetcherThread-0-0], Error for partition [__consumer_offsets,7] to broker 0:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:56,161] ERROR [ReplicaFetcherThread-0-0], Error for partition [__consumer_offsets,1] to broker 0:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:56,167] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,7] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,184] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:56,219] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,7], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,223] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,294] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,298] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,9] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,311] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,13] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,313] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:56,416] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,13], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,421] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,484] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,488] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,493] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,499] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,22] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,500] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:56,506] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,22] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:56,510] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,31] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,510] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:56,547] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,31], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,551] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,18] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,556] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,594] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,599] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,37] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,600] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:56,628] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,37], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,634] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,49] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:56,635] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:56,640] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,49], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,267] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,12] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,278] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,317] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,324] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,358] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,362] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,391] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,394] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,1] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,394] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[2016-09-22 18:55:57,426] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,1], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,429] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,433] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,15] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,436] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,462] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,465] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:57,490] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:58,564] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,10] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:58,565] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@6e63ed08 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 18:55:58,572] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,7] in 9070 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:55:58,565] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,40] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:58,565] INFO Partition [__consumer_offsets,14] on broker 1: Shrinking ISR for partition [__consumer_offsets,14] from 2,1 to 1 (kafka.cluster.Partition)
[2016-09-22 18:55:58,725] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,34] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:58,725] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,16] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:55:58,727] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,13] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:55:58,728] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:00,013] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,13] in 1284 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:01,608] INFO Partition [__consumer_offsets,14] on broker 1: Expanding ISR for partition [__consumer_offsets,14] from 1 to 1,2 (kafka.cluster.Partition)
[2016-09-22 18:56:01,608] INFO Partition [__consumer_offsets,2] on broker 1: Shrinking ISR for partition [__consumer_offsets,2] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:01,704] INFO re-registering broker info in ZK for broker 1 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:56:01,705] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:56:01,835] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:56:01,837] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(localhost,9093,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-09-22 18:56:01,838] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:56:01,838] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2016-09-22 18:56:01,885] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 18:56:02,065] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@3f9e786e (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 0 rack: null) failed
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:63)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:59)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$1(NetworkClientBlockingOps.scala:112)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntil$extension(NetworkClientBlockingOps.scala:120)
	at kafka.utils.NetworkClientBlockingOps$.blockingReady$extension(NetworkClientBlockingOps.scala:59)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:239)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 18:56:02,074] INFO Partition [__consumer_offsets,22] on broker 2: Shrinking ISR for partition [__consumer_offsets,22] from 2,1 to 2 (kafka.cluster.Partition)
[2016-09-22 18:56:02,074] INFO Partition [__consumer_offsets,4] on broker 2: Expanding ISR for partition [__consumer_offsets,4] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,089] INFO Partition [__consumer_offsets,34] on broker 2: Shrinking ISR for partition [__consumer_offsets,34] from 2,1 to 2 (kafka.cluster.Partition)
[2016-09-22 18:56:02,133] INFO Partition [__consumer_offsets,40] on broker 2: Shrinking ISR for partition [__consumer_offsets,40] from 1,2 to 2 (kafka.cluster.Partition)
[2016-09-22 18:56:02,188] INFO Partition [__consumer_offsets,16] on broker 2: Shrinking ISR for partition [__consumer_offsets,16] from 1,2 to 2 (kafka.cluster.Partition)
[2016-09-22 18:56:02,226] INFO Partition [__consumer_offsets,36] on broker 2: Shrinking ISR for partition [__consumer_offsets,36] from 2,1,0 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,435] INFO Partition [__consumer_offsets,6] on broker 2: Shrinking ISR for partition [__consumer_offsets,6] from 2,1,0 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,457] INFO Partition [__consumer_offsets,10] on broker 2: Shrinking ISR for partition [__consumer_offsets,10] from 2,1 to 2 (kafka.cluster.Partition)
[2016-09-22 18:56:02,618] INFO Partition [__consumer_offsets,16] on broker 2: Expanding ISR for partition [__consumer_offsets,16] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,647] INFO Partition [__consumer_offsets,40] on broker 2: Expanding ISR for partition [__consumer_offsets,40] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,705] INFO Partition [__consumer_offsets,34] on broker 2: Expanding ISR for partition [__consumer_offsets,34] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,752] INFO Partition [__consumer_offsets,10] on broker 2: Expanding ISR for partition [__consumer_offsets,10] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,872] INFO Partition [__consumer_offsets,2] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:02,873] INFO Partition [__consumer_offsets,32] on broker 1: Shrinking ISR for partition [__consumer_offsets,32] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:02,878] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,49] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:02,879] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,37] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:02,883] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,31] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:02,894] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,1] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:02,997] INFO Partition [__consumer_offsets,32] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:02,997] INFO Partition [__consumer_offsets,29] on broker 1: Shrinking ISR for partition [__consumer_offsets,29] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,024] INFO Partition [__consumer_offsets,29] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,024] INFO Partition [__consumer_offsets,5] on broker 1: Shrinking ISR for partition [__consumer_offsets,5] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,069] INFO Partition [__consumer_offsets,5] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,116] INFO Partition [__consumer_offsets,44] on broker 1: Shrinking ISR for partition [__consumer_offsets,44] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,202] INFO Partition [__consumer_offsets,44] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,203] INFO Partition [__consumer_offsets,17] on broker 1: Shrinking ISR for partition [__consumer_offsets,17] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,517] INFO Partition [__consumer_offsets,17] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,518] INFO Partition [__consumer_offsets,20] on broker 1: Shrinking ISR for partition [__consumer_offsets,20] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,553] INFO Partition [__consumer_offsets,20] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,554] INFO Partition [__consumer_offsets,23] on broker 1: Shrinking ISR for partition [__consumer_offsets,23] from 2,1,0 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,567] INFO Partition [__consumer_offsets,26] on broker 1: Shrinking ISR for partition [__consumer_offsets,26] from 0,2,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,678] INFO Partition [__consumer_offsets,26] on broker 1: Cached zkVersion [7] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,678] INFO Partition [__consumer_offsets,38] on broker 1: Shrinking ISR for partition [__consumer_offsets,38] from 2,1,0 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,756] INFO Partition [__consumer_offsets,35] on broker 1: Shrinking ISR for partition [__consumer_offsets,35] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,798] INFO Partition [__consumer_offsets,35] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,864] INFO Partition [__consumer_offsets,41] on broker 1: Shrinking ISR for partition [__consumer_offsets,41] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:03,926] INFO Partition [__consumer_offsets,41] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:03,926] INFO Partition [__consumer_offsets,8] on broker 1: Shrinking ISR for partition [__consumer_offsets,8] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:04,247] INFO Partition [__consumer_offsets,8] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:04,478] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,49] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:04,478] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,37] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:04,479] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,31] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:04,479] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,1] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:05,101] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@3f2ca045 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 0 rack: null) failed
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:63)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:59)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$1(NetworkClientBlockingOps.scala:112)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntil$extension(NetworkClientBlockingOps.scala:120)
	at kafka.utils.NetworkClientBlockingOps$.blockingReady$extension(NetworkClientBlockingOps.scala:59)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:239)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 18:56:05,694] INFO [GroupCoordinator 1]: Preparing to restabilize group my-first-streams-application2 with old generation 2 (kafka.coordinator.GroupCoordinator)
[2016-09-22 18:56:05,710] INFO [GroupCoordinator 1]: Group my-first-streams-application2 generation 2 is dead and removed (kafka.coordinator.GroupCoordinator)
[2016-09-22 18:56:06,280] INFO Partition [__consumer_offsets,2] on broker 1: Shrinking ISR for partition [__consumer_offsets,2] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:06,322] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:56:06,465] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-09-22 18:56:06,466] INFO 2 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-09-22 18:56:06,798] INFO Partition [__consumer_offsets,2] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:06,800] INFO Partition [__consumer_offsets,32] on broker 1: Shrinking ISR for partition [__consumer_offsets,32] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:06,817] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,49] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:06,858] INFO Partition [__consumer_offsets,32] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:06,859] INFO Partition [__consumer_offsets,29] on broker 1: Shrinking ISR for partition [__consumer_offsets,29] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:06,862] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,37] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:06,862] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,31] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:06,863] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,1] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:06,941] INFO Partition [__consumer_offsets,29] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:06,942] INFO Partition [__consumer_offsets,5] on broker 1: Shrinking ISR for partition [__consumer_offsets,5] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:06,974] INFO Partition [__consumer_offsets,5] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:06,975] INFO Partition [__consumer_offsets,44] on broker 1: Shrinking ISR for partition [__consumer_offsets,44] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:07,043] INFO Partition [__consumer_offsets,44] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:07,044] INFO Partition [__consumer_offsets,17] on broker 1: Shrinking ISR for partition [__consumer_offsets,17] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:07,073] INFO Partition [__consumer_offsets,17] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:07,073] INFO Partition [__consumer_offsets,20] on broker 1: Shrinking ISR for partition [__consumer_offsets,20] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:07,286] INFO Partition [__consumer_offsets,20] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:07,287] INFO Partition [__consumer_offsets,26] on broker 1: Shrinking ISR for partition [__consumer_offsets,26] from 0,2,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:07,333] INFO Partition [__consumer_offsets,26] on broker 1: Cached zkVersion [7] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:07,334] INFO Partition [__consumer_offsets,35] on broker 1: Shrinking ISR for partition [__consumer_offsets,35] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:07,468] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 18:56:07,712] INFO Partition [__consumer_offsets,35] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:07,713] INFO Partition [__consumer_offsets,41] on broker 1: Shrinking ISR for partition [__consumer_offsets,41] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:07,846] INFO Partition [__consumer_offsets,41] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:07,874] INFO Partition [__consumer_offsets,8] on broker 1: Shrinking ISR for partition [__consumer_offsets,8] from 2,0,1 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:07,945] INFO Partition [__consumer_offsets,8] on broker 1: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-09-22 18:56:08,493] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,49] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:08,541] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,37] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:08,543] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,31] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:08,544] ERROR [ReplicaFetcherThread-0-1], Error for partition [__consumer_offsets,1] to broker 1:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:08,749] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@41b7d3d4 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 0 rack: null) failed
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:63)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:59)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$1(NetworkClientBlockingOps.scala:112)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntil$extension(NetworkClientBlockingOps.scala:120)
	at kafka.utils.NetworkClientBlockingOps$.blockingReady$extension(NetworkClientBlockingOps.scala:59)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:239)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 18:56:09,118] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,37],[__consumer_offsets,20],[__consumer_offsets,2],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,1],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:09,141] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,45],[__consumer_offsets,33],[__consumer_offsets,48],[__consumer_offsets,46],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:09,349] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions [__consumer_offsets,46],[__consumer_offsets,22] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:09,349] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[2016-09-22 18:56:09,350] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[2016-09-22 18:56:09,661] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,19] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:09,666] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[2016-09-22 18:56:09,756] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-09-22 18:56:10,495] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([[__consumer_offsets,46], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] , [[__consumer_offsets,22], initOffset 0 to broker BrokerEndPoint(2,localhost,9094)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:10,496] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,19], initOffset 0 to broker BrokerEndPoint(1,localhost,9093)] ) (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:10,547] INFO [ReplicaFetcherThread-0-0], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:10,564] INFO Partition [__consumer_offsets,22] on broker 2: Expanding ISR for partition [__consumer_offsets,22] from 2 to 2,1 (kafka.cluster.Partition)
[2016-09-22 18:56:10,635] INFO [ReplicaFetcherThread-0-0], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:10,978] INFO [ReplicaFetcherThread-0-0], Stopped  (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:11,296] INFO [ReplicaFetcherThread-0-0], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:11,999] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,002] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,31] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,044] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,045] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,37] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,047] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,049] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,49] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,079] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,082] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,083] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,086] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,19] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,889] INFO [ReplicaFetcherThread-0-0], Stopped  (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:12,889] INFO [ReplicaFetcherThread-0-0], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:12,969] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:12,973] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,46] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:19,521] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@428e50b0 (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:87)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:84)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:84)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:80)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$2(NetworkClientBlockingOps.scala:137)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:143)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:80)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:244)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 18:56:22,551] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@29f790b (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9093 (id: 1 rack: null) failed
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:63)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:59)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$1(NetworkClientBlockingOps.scala:112)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntil$extension(NetworkClientBlockingOps.scala:120)
	at kafka.utils.NetworkClientBlockingOps$.blockingReady$extension(NetworkClientBlockingOps.scala:59)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:239)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 18:56:25,623] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@4fc41add (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9093 (id: 1 rack: null) failed
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:63)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:59)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$1(NetworkClientBlockingOps.scala:112)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntil$extension(NetworkClientBlockingOps.scala:120)
	at kafka.utils.NetworkClientBlockingOps$.blockingReady$extension(NetworkClientBlockingOps.scala:59)
	at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:239)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:229)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:107)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-09-22 18:56:27,916] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,41],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,37],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,31],[__consumer_offsets,19],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:27,956] INFO [ReplicaFetcherThread-0-1], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:28,686] INFO [ReplicaFetcherThread-0-1], Stopped  (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:28,687] INFO [ReplicaFetcherThread-0-1], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2016-09-22 18:56:28,703] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,754] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,25] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,755] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,758] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,31] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,758] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,860] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,37] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,860] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,863] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,2] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,863] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,884] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,884] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,886] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,887] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,906] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,49] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,907] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,972] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,14] in 65 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:28,973] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:29,206] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,17] in 225 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:29,206] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:29,295] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,20] in 88 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:29,296] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:29,313] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,23] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:29,313] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:29,933] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,16],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,0],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,18],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-09-22 18:56:30,826] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,26] in 1512 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:30,847] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:30,853] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,29] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:30,879] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,223] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,11] in 343 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,223] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,227] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,5] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,313] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,317] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,38] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,319] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,324] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,35] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,356] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,361] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,32] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,361] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,364] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,382] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,387] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,44] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,387] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,389] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,670] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,673] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,1] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,674] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,675] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,7] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,693] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,695] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,696] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[2016-09-22 18:56:31,698] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,19] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
